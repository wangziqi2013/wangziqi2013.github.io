---
layout: paper-summary
title:  "FlatFS: Flatten Hierarchical File System Namespace on Non-volatile Memories"
date:   2023-01-17 23:59:00 -0500
categories: paper
paper_title: "FlatFS: Flatten Hierarchical File System Namespace on Non-volatile Memories"
paper_link: https://www.usenix.org/conference/atc22/presentation/cai
paper_keyword: NVM; FlatFS; File System
paper_year: USENIX ATC 2022
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---



This paper presents FlatFS, a file system designed for Byte-Addressable Non-Volatile Memory (NVM) that adopts 
a flat namespace to replace the hierarchical directory tree. The paper is motivated by the high overhead of component
resolution and file tree walking in the existing hierarchical file systems when they are deployed on fast NVM as 
external storage. The paper addresses the issue by replacing the hierarchical organization of the file system with
a flat namespace organization while preserving the conventional hierarchical view. Compared with conventional
file systems, FlatFS demonstrates better performance and scalability when the operations are metadata-intensive.

In conventional file systems, files and directories are organized as a directory tree (if we ignore hard links), 
where the intermediate nodes are directories that can contain files and other directories, while the leaf nodes
are regular files or soft links. However, this tree model comes at a cost as a file path needs to be internally 
resolved into an inode number by the file system before it can be used by other file system calls. On conventional
systems using HDDs or SSDs, the cost of path resolution is relatively cheap due to the high overhead of performing 
I/Os. However, with the introduction of NVM, whose read and write latencies are comparable to those of DRAM and 
are much faster than even the fastest SSDs, I/O has largely ceased to be the slowest component on the critical path,
whose latency now is even comparable to those of the software. As a result, the existing hierarchical file model
can eventually become the bottleneck of file operations. 

To confirm the above claim, the authors of the paper conducted two sets of experiments. First, the authors measured
the overhead of resolving a component name to the corresponding dentry object. Results show that even with a warm
dcache, where the name is hashed and used to look up a hash table, the overhead is non-negligible, constituting 
around 30% of the total execution time. The overhead is almost doubled if the dcache is cold, i.e., the entry is not
in the cache and hence must be read from the underlying storage. Besides, the authors also conducted experiments with
a varying number of components on the path. Results show that component resolution time scales with the number of 
components, but somehow it is sub-linear and no explanation is given in the paper.
