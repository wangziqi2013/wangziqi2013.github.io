---
layout: paper-summary
title:  "FlatFS: Flatten Hierarchical File System Namespace on Non-volatile Memories"
date:   2023-01-17 23:59:00 -0500
categories: paper
paper_title: "FlatFS: Flatten Hierarchical File System Namespace on Non-volatile Memories"
paper_link: https://www.usenix.org/conference/atc22/presentation/cai
paper_keyword: NVM; FlatFS; File System
paper_year: USENIX ATC 2022
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Comments:**

1. The paper indicates that in the experiment, resolving 50 components takes 14x more time than resolving a single 
   component. Why is this non-scalable? It seems perfectly scalable to me. The real problem perhaps is that it 
   is not constant time.

This paper presents FlatFS, a file system designed for Byte-Addressable Non-Volatile Memory (NVM) that adopts 
a flat namespace to replace the hierarchical directory tree. The paper is motivated by the high overhead of component
resolution and file tree walking in the existing hierarchical file systems when they are deployed on fast NVM as 
external storage. The paper addresses the issue by replacing the hierarchical organization of the file system with
a flat namespace organization while preserving the conventional hierarchical view. Compared with conventional
file systems, FlatFS demonstrates better performance and scalability when the operations are metadata-intensive.

In conventional file systems, files and directories are organized as a directory tree (if we ignore hard links), 
where the intermediate nodes are directories that can contain files and other directories, while the leaf nodes
are regular files or soft links. However, this tree model comes at a cost as a file path needs to be internally 
resolved into an inode number by the file system before it can be used by other file system calls. On conventional
systems using HDDs or SSDs, the cost of path resolution is relatively cheap due to the high overhead of performing 
I/Os. However, with the introduction of NVM, whose read and write latencies are comparable to those of DRAM and 
are much faster than even the fastest SSDs, I/O has largely ceased to be the slowest component on the critical path,
whose latency now is even comparable to those of the software. As a result, the existing hierarchical file model
can eventually become the bottleneck of file operations. 

To confirm the above claim, the authors of the paper conducted two sets of experiments. First, the authors measured
the overhead of resolving a component name to the corresponding dentry object. Results show that even with a warm
dcache (a hash table that stores recently resolved paths and maps them to dentry objects) the overhead is 
non-negligible, constituting around 30% of the total execution time. The overhead is almost doubled if the dcache 
is cold, i.e., the entry is not in the cache and hence must be read from the underlying storage. 
Besides, the authors also conducted experiments with a varying number of components on the path. Results show that 
component resolution time scales with the number of components, but somehow it is sub-linear and no explanation is 
given in the paper.
The second experiment measures the overall cost of path walking and name resolution during metadata operations.
Results show that when executing `ls -R` command to list all directories and files recursively in a directory tree of
depth 11, the overhead of directory tree walking can constitute up to 80% of total execution time, again demonstrating
the high overhead of directory tree walking.

FlatFS addresses the above issues by organizing the entire file system as a flat namespace. In FlatFS, files and 
directories are still uniquely identified by the full absolute path as in a regular file system, but instead of 
resolving each component of the full path as a separate component by searching the component name in a directory
structure, FlatFS directly maps the full path to the file or directory's inode number using a B+Tree index structure, 
hence achieving faster lookups while avoiding the time-costing level-by-level component name resolution. Furthermore, 
since B+Tree traversals mostly involve sequential memory accesses within nodes with only indirections between nodes,
the access pattern of the index search is also more suitable for NVM.

We next present FlatFS's index structure, the Range-Optimized Index Tree or Br-Tree. The Br-Tree is essentially a 
B+Tree indexed by path strings, with the node size being 256 bytes which aligns with the size of NVM's internal 
read and write buffers. As with all B+Trees, keys stored in leaf nodes are sorted in lexicographical order, meaning
that files or directories that share the same common prefix (i.e., they are under the same directory) will be stored 
together. To reduce storage overhead, all keys stored in the same node are compressed by the common prefix.
As a result, a key in a node is stored as a triple: the shred prefix, the suffix, and the size of the suffix.
Concurrent tree operations are synchronized between different threads using top-down lock coupling. The integrity
of the tree is also protected against system failures using undo logging.

Metadata operations on FlatFS start by querying the index. Regular file lookups use the full path and simply perform
point queries. Relative paths should be converted to full paths using the current working directory environmental 
variable before being used. Directory lists use the full path of the directory. To delimit a directory, FlatFS
maintains two hidden entries in the index for every directory, with one denoting the beginning of the 
directory content, whose 

