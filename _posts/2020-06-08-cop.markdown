---
layout: paper-summary
title:  "COP: To Compress and Protect Main Memory"
date:   2020-06-08 17:17:00 -0500
categories: paper
paper_title: "COP: To Compress and Protect Main Memory"
paper_link: https://dl.acm.org/doi/10.1145/2872887.2750377
paper_keyword: COP; Memory Compression; ECC
paper_year: ISCA 2015
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes COP, a memory ECC design which delivers protection without the extra hardware overhead. 
Conventional ECC-protected memory module often has an extra chip on a rank, enabling an extra 8 bytes of data to be read
in parallel with 64 byte cache line data. Such dedicated ECC hardware not only cost more than a regular non-ECC memory,
but also consumes substantially more power during operation, due to the extra read on the ECC chip.
Prior publications also seek to implement hardware ECC check for non-ECC memory modules. A dedicated ECC region is 
allocated from the physical memory, which stores the ECC bits for each memory block in the rest of the address space.
These schemes, however, suffer from various problems. First, the extra ECC region significantly reduces the amount of 
usable memory, which can take up to 12.5% of total storage. Second, even if ECC is only sparsely maintained as in 
some designs, the mapping structures needed for locating the ECC data given a line address is also a non-negligible 
cost in both performance and storage. The last problem is that ECC data is accessed for each memory request, which
adds to DRAM latency, which degrades performance.

COP, on the other hand, conbines compression with ECC such that ECC is stored in-line with compressed data, given that
the compression ratio is high enough to allow small ECC to be fitted in. By using compression, COP has three obvious
advantages compared with previous schemes. First, no extra storage is required for maintaining ECC, since DRAM data
is compressed in cache line granularity. Second, one DRAM access can fetch both data and ECC, which will not affect
performance as in designs in which data and ECC accesses are serialized. The last advantage is that no extra indirections
or mapping tables are maintained in order to access ECC, featuring zero metadata overhead. 

We next discuss COP design as follows. The paper assumes a low-cost compression and decompression algorithm that can 
reduce the size of a 64 byte line by at least 34 bits. We will see below how these 34 bits are arranged within the line
to provide single-erro correction and double-error detection (SECDEC) capabilities. COP does not pursue high compression
ratio, and the design trades off compression ratio with possibilities of applying compression. In other works, compression
algorithms that provide more than 34 bits of storage saving makes little sense in COP, but it is important that most
cache lines should be compressible to at least 478 bits to allow ECC in-lining.
