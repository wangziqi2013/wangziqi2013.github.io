---
layout: paper-summary
title:  "Cerebros: Evading the RPC Tax in Datacenters"
date:   2021-10-29 20:19:00 -0500
categories: paper
paper_title: "Cerebros: Evading the RPC Tax in Datacenters"
paper_link: https://dl.acm.org/doi/10.1145/3466752.3480055
paper_keyword: RPC Tax; Accelerator; Cerebros
paper_year: MICRO 2021
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Cerebros, a hardware accelerator that offloads the responsibility of RPC handling from the CPU
to an NIC-attached module. The paper is motivated by the high performance overhead and ill-suited nature of RPC
handling, and it proposes to offload part of the RPC handling, i.e., header parsing, function dispatch, and 
argument deserialization, to the network layer with an interface featuring hardware-software interplay.

As the microservice architecture becomes a major software engineering trend, the efficiency of Remote Procedure Call 
(RPC) has reemerged as an important factor in the overall performance of microservices, since the architecture 
divides software components into simple, standalone modules, each running in their own process address space as 
an independent unit, hence achieving functional and failure isolation. Function calls between modules, which was 
done with a single call instruction, is now replaced with more heavyweight RPC invocations. The paper points out
that the overhead of performing RPCs in datacenters, dubbed as the "RPC tax", can be as much as 40% - 90% of the 
total execution cycles. This situation can only become worse, because: (1) Microservices can also perform recursive RPC
calls, such that the RPC tax will multiply and be propagated at all levels of the recursive call; 
(2) Microservices usually implement simple functions to limit the complexity of a single module. The RPC overhead,
however, is rather static, and does not scale with the complexity of the function. As functions become smaller,
RPC tax will only continue to rise; (3) Existing hardware already optimizes the transportation layer protocols,
which further highlights the RPC overhead as the bottleneck in total execution cycle; and (4) Datacenter applications
already suffer from instruction supply problems due to binary size bloat (which is a result of static library linking).
Adding RPC into the control path will only aggravate this issue as RPC introduces a few more software layers.

The paper further conducts experiments to obtain a detailed decomposition of the overheads. The paper identifies
three major tasks in the RPC handling process (other than executing the function itself, which the paper does not
attempt to optimize): Header parsing, function dispatching, and payload manipulation.
Header parsing refers to the process of identifying the function type, message type, etc. Judging from the figure 
presented in the paper, this part only incurs minor overhead.
Function dispatching refers to the process of resolving the function ID or the string name of the function 
to the actual function pointer on the host machine. Although this process is likely no more than a single table
lookup, the paper mentions that the final function call is an indirect jump that is hard to both prefetch and predict,
which can also cause significant overhead on the microarchitectural level.
In the last step, the function (or the function handler) reads the payload of the RPC message, and deserializes the
function arguments to build the in-memory objects being passed as function arguments.
According to the figure, this stage incurs the most overhead, but mostly due to simple data movement, integer
sign extension, etc., which is ill-suited for CPU, and can be conveniently offloaded to specialized hardware.

Although not pointed out explicitly, there are a few challenges in implementing such an accelerator. First, the 
accelerator must be able to complete the whole process from header parsing to data manipulation, without involving
the CPU. One obvious but sub-optimal design is to only let hardware parse the header, extract the function ID, and then
pass the ID to the CPU. The CPU is responsible for locating the function, and initiate the accelerator for the second 
time for data manipulation. 