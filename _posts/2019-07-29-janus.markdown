---
layout: paper-summary
title:  "Efficient Persist Barriers for Multicores"
date:   2019-07-29 21:44:00 -0500
categories: paper
paper_title: "Janus: Optimizing Memory and Storage Support for Non-Volatile Memory Systems"
paper_link: https://dl.acm.org/citation.cfm?doid=3307650.3322206
paper_keyword: NVM; Encryption; Backend Memory Operation (BMO)
paper_year: ISCA 2019
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper presents Janus, an framework for efficient handling of Backend Memory Operations (BMO) on Non-Volatile Memory 
(NVM) controllers. In the introduction section, the paper identifies a major bottleneck of NVM operations in addition to loads: 
stores and the correspoinding BMOs. Two factors contribute to this conclusition. First, in order to achieve crash 
persistency and recovery, most NVM applications use some form of logging or shadowing. These techniques enforce write ordering
between the log and actual data. For example, in undo logging scheme, the undo image is generated before the data
is written into the cache line, and then written to the NVM to avoid the unrecoverable case in which a dirty cache line
is evicted to the NVM before the corresponding undo image does. Write ordering incurs extra latency on store operations, 
which also blocks the processor pipeline, constituting a critical path. Second, most NVM devices also provide capabilities 
beyond persistence. For example, encryption, data compression, and deduplication are all important features for NVM
device. These features require that the NVM device perform computations such as hashing, table lookup, key generation, etc. 
on the backend (i.e. BMOs) when a cache line is evicted or flushed from the processor, which can further add to the latency 
of store operations, aggravating the store bottleneck.  

This paper employs two techniques to reduce the latency of BMO: parallization and pre-computation. With parallelization,
some operations from different tasks can be performed at the same time, as long as they are independent from each other.
This paper identifies four types of dependence: inter-operation dependence, intra-operation dependence, address dependence,
and data dependence. The first two types of dependence dictates which operation within each task can be overlapped without 
affecting the result. In the paper's example, inter-operation dependence exists between every two consecutive steps of 
a task, while intra-operation dependence can be identified by examining the task's workflow. In this example, the table 
lookup operation in deduplication is the pre-requisite of XOR operation in block encryption, because if the block of the 
same content already exists on the NVM, no extra write will be conducted, and hence the encryption is no longer needed. 
Address and data dependence are input dependence resolved by prividing the address of the operation of the data. For example,
during data encryption, the address is needed at the first step (computing the cipher key), but data is only used to 
generate the final output at the last XOR step. In practice, the processor pipeline computes the address of store operations
before the cache line is acquired using cache coherence. The cache may send the address to the NVM controller once it is 
available in the address genetation unit, and only send data when the coherence transaction finishes, essentially overlapping
the coherence transaction and the first two steps of data encryption. 
