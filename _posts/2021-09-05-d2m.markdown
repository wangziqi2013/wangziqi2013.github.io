---
layout: paper-summary
title:  "A Split Cache Hierarchy for Enabling Data-Oriented Optimizations"
date:   2021-09-05 15:07:00 -0500
categories: paper
paper_title: "A Split Cache Hierarchy for Enabling Data-Oriented Optimizations"
paper_link: https://ieeexplore.ieee.org/document/7920820
paper_keyword: D2M Cache; TLB
paper_year: HPCA 2017
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Direct-to-Master (D2M) cache, a tag-less cache architecture in multicore environments.
The D2M proposal is based on a previous Direct-to-Data (D2D) design, in which cache block locations in the private
L1 and L2 caches are tracked with a two-level hierarchy of metadata stores, namely, the eTLB and the Hub.
D2M further extends the architecture to a shared LLC cache with multicore coherence.

We first describe the operations of the baseline D2D design.
In the original D2D work, which can be found [here]({% post_url 2021-09-01-d2d%}), per-block address tags are eliminated
from the private hierarchy. Instead, a centralized repository for tracking cache line locations, including the cache
component and the way number, which is called the Hub, is added to the private hierarchy.
The Hub is essentially a set-associative sector cache tag array that uses super-blocks of 4KB page size.
The Hub uses physical page numbers as tags, and is co-located with the L2 cache. 
Each entry of the Hub stores the valid bit, the component that an address is currently cached in, and the way number
in the cache. Set indices are not stored, as they can be directly generated from the virtual or physical address
(depending on the cache size: for L1 it is fully virtual, while for L2 it also needs a few bits from the physical
page number).
The D2D cache maintains an invariant that all blocks stored in the private hierarchy must have a corresponding 
Hub entry that tracks the block status, and cache lookups must use information stored in the Hub to locate the 
requested cache block.
In addition, to avoid maintaining multiple copies of the same block in the private hierarchy, the D2D design
mandates that L1 and L2 be exclusive, meaning that any block can only be cached by at most one component.

To accelerate cache lookup, and to avoid relatively expensive lookups per memory operation in the Hub, a smaller
but faster cache for the Hub is added to the L1 cache for tracking frequently used Hub entries.
The Hub cache is co-located with the L1 TLB, called the eTLB, which is essentially a virtually tagged super-block 
tag array.
Each entry of the eTLB tracks the same location information as the underlying entry (with the same physical address) 
of the Hub.
Memory operations issued from the pipeline will first perform lookups in the eTLB, and, if misses, in the Hub.
Cache blocks can be accessed, after an entry from either the eTLB or the Hub is located, using the component ID
and the way number stored in the entry.

To facilitate cache block eviction, each data block has a Hub pointer that points to the Hub entry covering the block's
address. Similarly, each Hub entry has an eTLB pointer, which points to the eTLB entry, if one exists.
On block eviction, the Hub and optionally the eTLB (if the eTLB pointer of te Hub entry is valid) will be notified, 
and the location information of the block is updated. This is achieved by following the data block's Hub pointer to
the Hub entry, and optionally also following the Hub entry's eTLB pointer to the eTLB entry.

On Hub entry eviction, all blocks that are currently valid in the private hierarchy will be evicted as well, in order
to maintain the invariance.

Since the eTLB uses virtual page numbers, both homonym and synonym are possible. Homonym is prevented by the 
conventional TLB with the ASID field. Synonym is prevented by checking whether an eTLB entry with the same physical
address in the Hub but a different virtual address than requested, using the Hub entry's eTLB pointer, 
when a new entry is to be inserted into the eTLB. 
The paper argues that since synonyms are relatively infrequent, the eTLB disallows entries that constitute synonyms 
to co-exist. In practice, this is achieved by evicting the previous synonym entry and copying its block location
information to the new entry when the new entry is to be inserted.

We next describe the architecture of D2M.
The D2M design extends D2D to the LLC with multicore cache coherence. The baseline D2D is largely the same in the 
baseline design, except four minor differences.
First, the Hub and the eTLB are renamed to MD2 and MD1 respectively. Second, page-sized super-block tags, now 
called Location Information (LI) entries, are not necessarily of page sizes anymore. The paper uses the term 
"region" to describe the size-aligned range of addresses covered by a single entry. This change only adds extra
flexibility for making design decisions, which does not modify the way that D2D operates.
Third, the paper seems to suggest that the private hierarchy is no longer inclusive. Instead, the 
L2 should be inclusive of all blocks in the L1.

The last difference is that the location indicator for each block is extended to six bits (the number of bits dependes 
on the system configuration. The paper assumes 8 private hierarchies, 32-way LLC, and 8-way L1 and L2).
The indicator in the private hierarchy can thus address a block in the local hierarchy as in D2D (three bits are used
for indicating ways, and the rest three for indicating L1/L2), or a block in another private hierarchy with only the 
node ID (three bits for node ID, and three bits prefix), or a block in the LLC (five bits for indicate ways, and one
bit prefix to indicate LLC), or in the memory (there are lots of code points for this purpose).
