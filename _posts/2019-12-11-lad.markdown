---
layout: paper-summary
title:  "Distributed Logless Atomic Durability with Persistent Memory"
date:   2019-12-11 17:54:00 -0500
categories: paper
paper_title: "Distributed Logless Atomic Durability with Persistent Memory"
paper_link: https://dl.acm.org/citation.cfm?doid=3352460.3358321
paper_keyword: NVM; LAD; Memory Controller
paper_year: MICRO 2019
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Logless Atomic Durability (LAD), a hardware framework for supporting failure atomic transactions in
which no logging is involved for most of the time. The paper identified the problem of software logging as write amplification
and excessive write orderings which require persist barrier to be issued quite often, degrading performance. The paper also 
identifies that hardware schemes, such as Kiln, are making unrealistic assumptions which make the propal less attractive.
For example, Kiln assumes that the LLC is manufactured using STT-RAM and that the LLC can atomically commit a transaction
by performing a battery-backed cache tag walk. Neither of these two assumptions is realistic nowadays. Today's LLC is still
manufactured using SRAM, and is quite unlikely to be replaced by STT-RAM in the near future. Furthermore, Non-uniform
Cache Access (NUCA), which is common on server processors, partitions the LLC into several slices, each maintained by
a separate controller. Atomicity of operations, such as flash-clearing all "speculative" bits, as proposed by Kiln, is
not guaranteed. 

The paper makes the following observation about implementing failure atomicity. First, in a distributed environment 
such as NUCA and/or multi-core, atomicity of operation is not guaranteed, since devices act on their own, and only
communicate through pre-defined interfaces. In order to ensure that all of these devices make the same decision, Two-Phase
Commit (2PC) must be employed to determine the final state of the operation. Second, software logging is expensive, making
hardware assisted failure atomicity an attractive option. Among popular hardware logging designs, the paper points out 
that undo logging fits current NVDIMM the best for the following reasons: (1) For dynamic workloads (i.e. the write set
is only known at the end of the transaction, not before the transaction), undo logging supports in-place update, which 
eliminates the remapping table in order for a transaction to read its own dirty data; (2) Although both redo and undo
logging suffer from write amplification problem, undo logging has better access locality than redo logging. In undo
logging, we need two row activations to write the undo log and the data, while in redo logging, we need one row activation
to write redo data, and another two to read the log and to update data in-place after log commit; (3) Undo log entries 
are never read except for recovery. The log can be trivially removed after the transaction has committed, while in redo
logging the log has to be replayed for in-place updates. Based on the above reasons, LAD uses undo logging whenever the 
write set of a durable transaction exceeds what the hardware could support. The last observation is that the memory hierarchy
naturally serves as an intermediate buffer for pending updates that are supposed to be atomic. Part of the hierarchy is 
even made persistent using battery-backed SRAM to decrease latency of certain operations. The paper proposes that instead
of letting these buffers drain as quickly as possible, we only clear these buffers lazily, taking advantage of the non-volatility
of the buffers to implement a small "shadow page" for the write set. In this paper, the write pending queue (WPQ) is 
considered as non-volatile, which has been implemented on recent commercial products. 
