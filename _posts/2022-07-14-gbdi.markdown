---
layout: paper-summary
title:  "GBDI: Going Beyond Base-Delta-Immediate Compression with Global Bases"
date:   2022-07-14 02:48:00 -0500
categories: paper
paper_title: "GBDI: Going Beyond Base-Delta-Immediate Compression with Global Bases"
paper_link: https://ieeexplore.ieee.org/document/9773255/
paper_keyword: Memory Compression; BDI; GBDI
paper_year: HPCA 2022
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Comments:**

1. The paper did not evaluate recompression. Instead, it only shows that for a single workload, compressibility
does not change much. The problem is that recompression is inevitable, if the workload consists of many
different applications on a multicore system.

In addition, context switch may be problematic, because the global bases are not part of any context. 
As a result, the more applications there are in the system, the more likely the number of global bases will be larger.
The paper did not evaluate mixtures of different workloads. Instead, only the same workload is simulated.

Broadly speaking, all designs that leverage inter-block compression have the same problem: The global bases 
(clusteroid for Thesaurus, pattern table for EPC, and the global base for GBDI) are not scalable, and
are heavily bound to the execution context.
This is an inherent trade-off of inter-block designs: The larger the search space is, the potential better 
compression you can get. But as the search space becomes larger, you need to keep more metadata for each context.

2. The algorithm is actually nowhere close to BDI. For example, immediate number compression is not used (because
you can always have an explicit zero in the base table). The fixed-width code word design of BDI is also not there.
The compression and decompression latency is much higher than original BDI which makes global BDI quite 
heavy-weight. None of these is fundamental problem, though.

3. I find it hard to understand what is "bin ranges" and how it relates to the number of bins. Does "15 bin ranges"
mean 2^15 (i.e., 32K) bins for sampling? Are bins evenly divided across the 32-bit value domain?
The paper should have done a better job describing the binning algorithm.

This paper proposes Global Base-Delta-Immediate (GBDI), a main memory compression architecture leveraging 
inter-block compression with global bases.
The paper is motivated by two limitations of intra-block BDI. First, BDI only leverages redundancy between
similar code words within a 64 byte block, without looking into other blocks for redundancy.
The restricted search space limits compressibility since a single block may not contain all the possible 
base values for efficient compression.
Second, the paper also observes that floating point numbers are difficult to be compressed under BDI, because
BDI interprets compression inputs as integers, and hence computes the arithmetic difference.
For floating point numbers, however, this approach can be rather unreliable, because floating point numbers that
are numerically close to each other may appear radically different on the integer value domain.
This further reduces the effectiveness of intra-block base value searching for floating point numbers.

The GBDI design consists of two parts. The first part is the main memory architecture, which is only briefly
described in the paper. The goal of main memory compression is to reduce bandwidth consumption of fetching 
data from DRAM and reduce the latency of data access.
This is achieved by compressing four consecutive blocks on the physical address space into a sector, which is stored
on the physical location of the first block.


