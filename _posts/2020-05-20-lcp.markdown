---
layout: paper-summary
title:  "Linear Compressed Pages: A Low Complexity, Low-Latency Main Memory Compression Framework"
date:   2020-05-20 22:40:00 -0500
categories: paper
paper_title: "Linear Compressed Pages: A Low Complexity, Low-Latency Main Memory Compression Framework"
paper_link: https://ieeexplore.ieee.org/document/7847624/
paper_keyword: Memory Compression; LCP
paper_year: MICRO 2013
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Linearly Compressed Pages (LCP), a main memory compression framework featuring easy algorithm design,
low-cost deployment, and memory management. Broadly speaking, main memory compression schemes exist to satisfy one or both 
of the two goals.
The first goal is to reduce memory usage by allowing cache lines or pages to be packed in a more compact form after 
compression. This way less physical memory can be allocated to a full 4KB page frame, and hence more pages can be mapped
into virtual memory at the same time. The second goal is to save bandwidth when fetching cache lines into the cache 
hierarchy. Memory designs either employ compression as a prefetching scheme, allowing adjacent cache lines to be brought 
into the LLC in the same transaction to fulfill a cache miss, or redesign memory bus protocol such that less data can be 
fetched per-transaction, increasing bus transaction throughput. 

The paper points out that both commercial memory compression schemes or proposals face several challenges that make
the above two goals difficult to achieve. First, memory compression changes one of the most fundamental abstraction
abstration that the physical address space is linearly mapped to the virtual address space. The linear map not only
simplifies physical address computation, but also simplifies memory management, since the OS can conveniently divide the 
physical address space into uniformly sized pages, and manage it as a page buffer pool.