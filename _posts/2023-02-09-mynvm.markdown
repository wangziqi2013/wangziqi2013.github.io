---
layout: paper-summary
title:  "Reducing DRAM Footprint with NVM in Facebook"
date:   2023-02-09 14:02:00 -0500
categories: paper
paper_title: "Reducing DRAM Footprint with NVM in Facebook"
paper_link: https://dl.acm.org/doi/10.1145/3190508.3190524
paper_keyword: NVM; RockDB; NVM Cache
paper_year: EuroSys 2018
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents MyNVM, a caching layer design for RocksDB that leverages NVM as a fast alternative to DRAM.
To goal of MyNVM is to maintain an acceptable latency with RocksDB key-value store while replacing the DRAM caching
layer with cheaper but slower block-NVM storage. MyNVM achieves the goal by carefully tuning the engineering 
aspects of RocksDB storage layer in order to match the performance characteristics of NVM devices. 
Consequently, MyNVM suffers only marginal slowdowns compared with systems using only DRAM as the caching layer
while offering a significant reduction in storage device expenses.
In addition, compared with the unmodified RocksDB using NVM as the caching layer, MyNVM demonstrates a clear 
performance advantage in both average latency and P99 latency.

MyNVM is built upon RocksDB, a key-value store engine that features high-performance writes by using log-structured
merge trees. RocksDB consists of two levels of storage. The first level is the in-memory index mapping keys
to values, which is implemented as a high-performance skip list. Most requests are satisfied by the in-memory index 
and hence do not need to query the next level. The second storage level consists of multiple layers of sorted 
key-value pairs stored on the disk (e.g., flash drives). Each layer consists of multiple files. Each file contains
a subset of sorted keys that reside in the layer. A file consists of a metadata header, an array of data blocks, a 
bloom filter encoding the keys in the file, and finally an index. 
Data blocks within a file are 16KB in size and they just contain key-value pairs in sorted order.
The bloom filter enables quick searches of the file. The index is constructed using the first key of each block
and is the entry point of key lookups within the file.

Key insertions in RocksDB are performed directly on the main memory level and are hence very fast. 
Key lookups will first query the in-memory index structure. If the query misses, then lookups will
turn to the second level. For each layer in the level, the procedure first performs a binary search
across the files in the layer. After locating the file, the per-file index is then queried to locate the
block after checking with the bloom filter. Finally, the procedure performs another binary search within the block.
This process can repeat multiple times as the lookup process misses in the previous layer and proceeds to
the next. The lookup fails if the key is not found in any of the layers. 

As the in-memory index structure is becoming larger, key-value entries will be gradually migrated to the second level
by generating a new file containing the entries from the memory index. Similarly, when a layer becomes overly large,
at least one file is picked from that layer and then merged into the next layer just like how LSM trees are merged. 
RocksDB strives to keep the size of each layer within a certain threshold, and smaller layers (closer to the main 
memory) have smaller sizes than bigger layers to facilitate fast searches.
Key-value entries, once they migrate to the disk, become immutable. Future updates on these entries will be committed
in a log-structured manner.
