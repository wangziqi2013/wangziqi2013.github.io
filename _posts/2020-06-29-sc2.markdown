---
layout: paper-summary
title:  "SC2: A Statistical Cache Compression Scheme"
date:   2020-06-29 13:49:00 -0500
categories: paper
paper_title: "SC2: A Statistical Cache Compression Scheme"
paper_link: https://dl.acm.org/doi/10.5555/2665671.2665696
paper_keyword: Cache; Compression; Huffman Encoding
paper_year: ISCA 2014
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes SC2, a cache compression design taking advantage of Huffman encoding to achieve both high compression
ratio and low decompression latency. The paper observes that most conventional cache compression schemes suffer from low
compression ratio, since they typically trade-off decompression latency with the efficiency of the compression algorithm.
This paper, however, proposes that Huffman encoding be used as the compression and decompression algorithm, despite
the common knowledge that decompression with Huffman encoding is unsiutable for hardware compression.

The paper identifies two major challenges of using Huffman encoding with hardware cache compression. First, unlike dictionary
based encoding where the dictionary is derived from data that has already been decompressed, Huffman encoding requires 
a codebook be used as the reference during both encoding and decoding. The generation, maintenance and switching of the 
codebook pose a challenge, since the complexity of these operations just grows as the number of symbols become large.
Second, Huffman encoding, if not generally carefully, may require traversing a Huffman encoding tree for decoding a code 
word, since code words are variable sized. Tree traversal operations are resource hungry because they involve random walks
on a Huffman tree structure. 

The paper solves both issues with Canonical Huffman encoding and software managed codebook, as we discuss below. 
Canonical Huffman encoding is generated by first building a Huffman encoding tree with conventional methods. For example,
thie paper suggests that a heap be used to extract the next-minimum subtree in terms of frequency. After building 
the encoding tree, the codeword for each symbol is obtained by counting the number of pointer jumps from the root
to the leaf of the symbol, and then sorted based on the codeword bit length. The actual bit pattern is unimportant.
After sorting codewords, a transform is applied to each subset of symbols of the same codeword length as follows.
The first set of symbols, which contains the shortest of the codewords, are assigned codewords 00..00, 00..01, 00..10
in which the number of bits are identical to the size of their non-canonical codewords. 


