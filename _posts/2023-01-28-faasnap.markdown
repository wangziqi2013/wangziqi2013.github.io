---
layout: paper-summary
title:  "FaaSnap: FaaS made fast using snapshot-based VMs"
date:   2023-01-28 21:29:00 -0500
categories: paper
paper_title: "FaaSnap: FaaS made fast using snapshot-based VMs"
paper_link: https://dl.acm.org/doi/10.1145/3492321.3524270
paper_keyword: Serverless; Cold-Start Latency; Snapshotting; Virtual Machine; Firecracker
paper_year: EuroSys 2022
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents FaaSnap, a serverless (Function-as-a-Service, FaaS) framework that enables fast function invocation
by using efficient snapshotting. The paper is motivated by the high cold-start latency of function invocation in
production environments. While prior works have already explored the idea of leveraging memory snapshots for fast
startups, FaaSnap further optimizes the snapshotting algorithm such that both the I/O cost and the latency penalty 
for loading the snapshot is minimized. When evaluated on a variety of serverless workloads, FaaSnap achieves nearly 
ideal performance compared with warm startups which also outperforms prior works in general.

The paper begins with a review of prior techniques for reducing the cold-start latency, which is a phenomenon observed
in serverless functions that inhibits efficient function invocation if the function is "cold", i.e., its working set 
has not been loaded into the main memory yet. These techniques can be classified into three different types.
The first is called Keep-Alive policy, which caches an existing function instance in the main memory for a 
while after it has completed execution. Both the process image and the accessed files are hence "warm" in the 
main memory or the page cache, enabling future execution to be started with low latency. However, the paper noted
that function Keep-Alive has limited benefits because it consumes main memory resources for an extended period of time
which may prevent useful work from being done on the host. The situation is further aggravated by the fact that
most functions are not repeatedly called, meaning that future invocations will likely still be cold starts.
