---
layout: paper-summary
title:  "FaaSnap: FaaS made fast using snapshot-based VMs"
date:   2023-01-28 21:29:00 -0500
categories: paper
paper_title: "FaaSnap: FaaS made fast using snapshot-based VMs"
paper_link: https://dl.acm.org/doi/10.1145/3492321.3524270
paper_keyword: Serverless; Cold-Start Latency; Snapshotting; Virtual Machine; Firecracker
paper_year: EuroSys 2022
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents FaaSnap, a serverless (Function-as-a-Service, FaaS) framework that enables fast function invocation
by using efficient snapshotting. The paper is motivated by the high cold-start latency of function invocation in
production environments. While prior works have already explored the idea of leveraging memory snapshots for fast
startups, FaaSnap further optimizes the snapshotting algorithm such that both the I/O cost and the latency penalty 
for loading the snapshot is minimized. When evaluated on a variety of serverless workloads, FaaSnap achieves nearly 
ideal performance compared with warm startups which also outperforms prior works in general.

The paper begins with a review of prior techniques for reducing the cold-start latency, which is a phenomenon observed
in serverless functions that inhibits efficient function invocation if the function is "cold", i.e., its working set 
has not been loaded into the main memory yet. These techniques can be classified into three different types.
The first is called Keep-Alive policy, which caches an existing function instance in the main memory for a 
while after it has completed execution. Both the process image and the accessed files are hence "warm" in the 
main memory or the page cache, enabling future execution to be started with low latency. However, the paper noted
that function Keep-Alive has limited benefits because it consumes main memory resources for an extended period of time
which may prevent useful work from being done on the host. The situation is further aggravated by the fact that
most functions are not repeatedly called, meaning that future invocations will likely still be cold starts.

The second technique is to leverage unikernels and lightweight virtual machines to reduce the amount of work during 
function startup, hence enabling millisecond-level function invocation latency, as exemplified by Firecracker. 
Furthermore, Firecracker also supports taking the memory snapshot of a virtual machine by mapping the guest memory
into a disk file on the host system. In this scenario, when a page fault is raised to the host kernel, if the 
page belongs to a VM instance whose memory state is mapped to a file, the page fault will be handled as a major page
fault, and the corresponding disk file is mapped to the guest physical memory by the kernel. Changes made to the 
guest physical address space can then be committed back to the file.
While this approach lowers startup latency compared with the regular VMs, the paper observes that Firecracker 
still suffers unnecessarily higher latency due to small and random DISK I/Os on the snapshot file due to
demand paging. In addition, anonymous memory in the guest system 
is mapped to the file as part of the memory snapshot and must be loaded back on snapshot recovery. 
However, unused anonymous memory, in practice, can be directly initialized on the host as anonymous memory rather 
than being read from the snapshot file, which wastes processor cycles and I/O bandwidth to fetch it from the snapshot 
file. 

The last technique is REAP, which adopts prefetching to accelerate the startup process. REAP records the working set
of functions by hooking on the page fault handler function in the user space (or by checking the "Access" bit in the 
guest page table entries). Pages that are accessed during function
execution will then be saved to a disk file as a prefetch set and reloaded back to the main memory the next time
the function is invoked. While this approach can effectively turn major page faults incurred by cold starts into 
minor page faults that only require searching the page cache and establishing address mappings, the paper identifies
two problems. First, REAP only records the first run of a function and uses the working set to generate the prefetch
set. Consequently, the performance benefit of REAP is sensitive to the stability of the working set. If the working set 
changes from run to run, REAP still needs to read from the original memory file as in a cold start. 
Second, REAP loads the prefetch set into the main memory synchronously at the beginning of execution, which 
constitutes part of the startup latency.

To address the issues with prior works, FaaSnap adopts a snapshot approach that captures a more general and more 
precise working set of function execution and stores it as a disk file. The snapshot file can then be loaded back
to the main memory in the background without blocking normal execution. 
FaaSnap is built on Firecracker and extends its snapshotting model.
From a high level, the snapshot process in FaaSnap is controlled by the system daemon running on the host system.
The daemon is very much similar to the existing daemon in Firecracker in that it serves as a gateway to the outsider 
world and coordinates VM's execution and resource. 
When a function is first time invoked, the daemon tracks the working set of the function and saves it to a snapshot 
file. On later invocations of the same function, the daemon will load the snapshot file and start from the snapshot,
hence reducing the startup latency.

We describe the operational details as follows. 
During function execution, the FaaSnap daemon monitors the dynamic memory consumption of the function instance. 
If the memory consumption increases by a certain threshold, it then uses a system call "mincore" to obtain a list 
of virtual page addresses that are currently being mapped into the address space. Note that "mincore" is executed 
by the daemon and hence reflects the host-side view of the function's working set. 
