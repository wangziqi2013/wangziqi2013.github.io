---
layout: paper-summary
title:  "Memory Deduplication for Serverless Computing with Medes"
date:   2023-01-06 20:36:00 -0500
categories: paper
paper_title: "Memory Deduplication for Serverless Computing with Medes"
paper_link: https://dl.acm.org/doi/10.1145/3492321.3524272
paper_keyword: Serverless; Deduplication; Cold-Start Latency
paper_year: EuroSys 2022
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Comments:**

1. My biggest concern is that, as the paper points out, two major sources of redundancy are shared libraries and 
opened files. In the former case, there is nothing to deduplicate as the OS effectively deduplicates them. In the 
latter case, the content of the file may have already been loaded into the OS page cache and is used by another
thread. These two cases seem to involve great complications as they have to be dealt with in the kernel.
I understand that the Medes design uses CRIU for checkpointing and restoration, which may already have solutions
for the above scenarios, but I am still curious to learn how they are done from a high level. 

2. It also seems to me that Medes is most effective for data segment and heap memory since they contain private 
memory that no other process may share. In the case of shared memory (e.g., page cache, shared library), the OS 
already does a good job deduplicating them.

3. The paper mentions that a page's signature consists of five chunks selected from the page. What if the page
only contains fewer than five chunks? Besides, chunks are selected if the last two bytes match a particular
pattern. Assuming an even value distribution, this mechanism will only select a chunk every 2^16 = 64KB, and 
five chunks will require, on average, 320KB of data.

4. In 4.1.2, are the chunks selected based on the last two bytes of chunk data (which is what the text seems to 
suggest -- also there is a typo), or the last two bytes of the hash value (which is more reasonable as with 
Rabin-Karp algorithm)?

5. In Section 2.1, if you sample K bytes at "regular fixed offsets of 2K bytes", then why bother using Rabin hash?
Aren't the K-byte chunks selected at fixed offsets as well?

This paper presents Medes, an in-memory deduplication module that enables fast startups of serverless functions.
Medes is built based on the observation that serverless functions running on a cluster often share identical or 
similar pages, which can then be leveraged for deduplication. The deduplicated function instances consume less 
memory and can hence be preserved in the memory in a warm state for a longer period without causing memory pressure. 
Medes achieves this design goal by using process checkpoints and fingerprint hashing to identify similarities between
their memory images. 

The Medes design is motivated by the classic problem of reducing cold-start latency in serverless computing.
Cold-start latency has become a major problem as serverless functions are typically short in execution time. 
As a result, the relatively heavyweight process of starting the function instance and setting up the execution
environment can occupy a significant part of function execution.
To reduce such latency, prior works proposed using Keep-Alive policies that keep function instances "warm"
in the system after the function completes. A warm function instance can be invoked much faster than a 
newly started "cold" instance, at the cost of higher memory pressure since the warm instances are maintained 
as idle functions containers in the main memory.
The paper points out that Keep-Alive policies hardly work well in practice, due to the unpredictable nature 
of function arrivals.
