---
layout: paper-summary
title:  "Consistent and Durable Data Structures for Non-Volatile Byte-Addressable Memory"
date:   2019-08-28 00:12:00 -0500
categories: paper
paper_title: "Consistent and Durable Data Structures for Non-Volatile Byte-Addressable Memory"
paper_link: https://dl.acm.org/citation.cfm?id=1960480
paper_keyword: B+Tree; NVM; Versioning
paper_year: FAST 2011
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

**Highlight:**

1. Novel adoption of versioning and multiversioned data structure to the realm of persistent data structures.

**Lowlights**

1. The assumption that flush() can only ensure the atomicity of 8 byte stores are overly restrictive and yet incorrect.
   It is overly restrictive because on x86 and most other architectures, cache lines are flushed back to the NVM in
   the granularity of 64 byte blocks (or other granularities), the atomicity of which is implied by the memory controller.
   It is incorrect because the paper did not explicitly mention that even for 8 byte pointers/integers, it is necessary to
   align their addresses to a multiple of 8. If the compiler aligns by multiple of 4, then it is possible that the 
   8 byte memory object is mapped across a cache line boundary.

This paper presents Consistent and Durable Data Structures (CDDS), a software technique for ensuring the consistency
of data structures on Non-Volatile memory (NVM). As NVM devices are directly attached to the memory bus, it is 
difficult to reason about persistence state changes due to the fact that memory writes can be made persistent on the device 
in arbitrary order. Even in the case where certain memory orderings are enforced, performing a data structure operation
often requires several writes on non-continuous locations, making it non-trivial to guarantee atomicity, the lack of 
which can introduce inconsistency to the data structure. 

This paper proposes two levels of abstraction of implementing a CDDS. The first level implements an interface which flushes
a series of cache lines back to the NVM, acting as a persistence barrier. All instructions executed after the persistence
barrier can safely assume that previous writes have made to the NVM. The interface, named flush(), however, only supports
8 byte atomic write to persistent storage. In other words, if system crashes at the moment flush() is being executed 
by the processor, some cache blocks may not reach the NVM before the crash, the content of which will be lost. 

The flush() interface consists of a memory barrier, mfence, a series of cache flushes, and another memory barrier (the
paper does not mention pcommit, largely because when it is written pcommit has not been part of the proposal, which was
later on deprecated). The first memory fence stalls the processor until the write buffer is emptied, which ensures that 
all previous memory writes reach the cache when the cache flush executes. Thie is necessary, because otherwise, the actual 
cache write may be reordered after the cache flush due to relaxed memory consistency. The clflush instructions in the middle
discard cache lines that are currently in the hierarchy, stalling the processor if the cache line is dirty until the 
write back finishes. Note that at the time this paper was written, clflushopt has not been proposed yet as an optimized
version of clflush. The clflush instruction may negatively affect performance because it invalidates cache lines from the 
cache, while in fact what we need is merely a write back (and coherence state change). The last memory fence orders the flush
instruction with instructions that follow to make sure no memory operation will be performed (and then evicted by the cache) 
before the current flush sequence completes. 

The second level of abstraction leverages versioning to guarantee that all changes are made visible atomically even if
the process may involve several memory updates to different cache lines, which we explain as follows. CDDS maintains a 
64 bit integer, mapped to the NVM, as the "current time" timestamp. This timestamp stores the current logical version the 
data structure. Every "object" in a CDDS has two fields, a begin timestamp (bts) stores the minimum timestamp required to 
access the data structure, and an "end timestamp" (ets) which is the highest timestamp that can access the object. Every 
operation on the data structure must first read the current logical timestamp, and then uses this timestamp to determine 
the visibility of objects within the data structure. To elaborate: If the current timestamp is *ts*, then an object is 
accessible to the current operation if and only if *ts* is within the interval [*bts*, *ets*), where *bts* and *ets* are 
the begin and end timestamps of the object to be accessed (in the paper, to represent the "infinitly large" time, we reserve 
timestamp zero as a special timestamp, the usage of which is restrivted to only in *ets*). 

When a new object is being added, we first create a new object with *bts* equals *ts* + 1 and *ets* equals 0. The newly 
created object is hence insivible before we change the current time. After objects are added (there can be more than one), 
we issue a flush() command to force them back to the NVM, and then increment the current time counter, and eventually flush 
the counter back to NVM. The last flush operation is atomic, since is only writes back the 8-byte current time counter,
which is also the persistent point of the newly added objects. Once the last flush() operation completes, all objects 
are visible to later operations since their *bts* is now exactly the logical timestamp. If, on the other hand, the system
crashes before the last flush() completes, then the current logical increment is not successfully reflected on the NVM.
After system reboot, the timestamp read from the NVM is still *bts* - 1, meaning that the newly added object is not 
visible to the post-crash recovery routine.

Similarly, when an object is to be deleted, we sets its end timestamp to *ts* + 1, flushes the object, increments the 
current timestamp counter, and flushes the counter. If the counter made into the NVM, then according to the version 
visibility rule, the object is no longer accessible to later operations, because the timestamp will be larger than or 
equal to the *ets*. If the system crashes, then these objects are still valid, because the current timestamp still
lies in the [*bts*, *ets*) interval.

Objects can be reused if they have been made invisible by a previous 