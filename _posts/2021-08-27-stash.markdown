---
layout: paper-summary
title:  "Stash: Have Your Scratchpad and Cache It Too"
date:   2021-08-27 21:29:00 -0500
categories: paper
paper_title: "Stash: Have Your Scratchpad and Cache It Too"
paper_link: https://dl.acm.org/doi/10.1145/2749469.2750374
paper_keyword: Scratchpad memory; Stash; GPGPU
paper_year: ISCA 2015
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Stash, a globally addressable, cache coherent scratchpad memory architecture for GPGPU. 
The paper is motivated by the fact that existing commercial implementations of scratchpad memory has limited efficiency
and usability due to the private, non-cache coherent address space. Stash addresses these issues by allowing the
scratchpad memory to translate its private address to and from the global virtual address, such that the scratchpad
memory can be loaded like a traditional cache on-demand, while maintaining easy access by retaining the direct 
addressing and fine-grained access capabilities of existing scratchpad memory.

The paper recognizes that both cache and scratchpad memory have limitations. Cache memory, on one hand, requires 
expensive address translation and tag lookups for each operation, which implies extra energy consumption in addition to
data access. Furthermore, cache memory has a fixed size block interface, meaning that data must be transferred between
the cache and the main memory in the unit of blocks, which is sub-optimal in both storage and bandwidth if only
a small potion of the block is used. Such striding pattern is common in certain GPGPU applications, if, for example, a 
single field of an array of structs (AoS) is accessed in parallel.

Scratchpad memory, on the other hand, overcomes the above limitations by allowing direct and fine-grained addressing 
into its storage, entirely getting rid of the tag array and the block interface.
It, however, suffers another two types of inefficiencies.
First, current implementations of scratchpad memory has its own isolated address space, meaning that applications must
explicitly move data into the scratchpad memory by issuing memory instructions. These explicit memory instructions 
will pollute the cache with data that is unlikely to be reused, as most of the operations will take place on the
scratchpad memory.
Second, scratchpad memory is not cache coherent, which implies that software must issue extra load and write back
instructions to ensure the correctness of data. For example, data updates in the scratchpad memory needs to be reflected
back to the global memory by software issuing explicit data movement instructions. Similarly, if data
items is updated by the CPU, software should also check whether the version stored in the scratchpad memory is
still up-to-date. Both requirements incur extra software and runtime complexity.

Stash combines the advantage of both cache and scratchpad memory, while avoiding their shortcomings, by adding an extra
address translation layer between scratchpad memory address space and the global address space.
Stash optimizes over the case where a field of a struct, the size of which is one or a few words, in an AoS is accessed,
and the access takes place in a stride pattern within one rectangular block of a 2D tile.
The pattern can therefore be described using a few size arguments, including the field size, the object size, the 2D
tile size in total, the row size of a single block, and the number of strides per block, and offsets within the 2D
tile can be generated given these size arguments and the base address of the 2D tile, assuming that all elements of 
the 2D tile are stored compactly.
Applications need to initialize the stash hardware using two interfaces, namely, AddMap and ChangeMap, with the above
information, which is performed by the compiler.
The Stash hardware stores these map entries in a table called the stash map, which can be referred to when the 
application accesses the scratchpad memory.

We now describe the operation of Stash as follows. As in current implementations of scratchpad memory, the 
application needs to first allocate a chunk of continuous storage from the scratchpad before using it.
The application should also initialize the stash map with the access pattern, such that Stash hardware can generate
the virtual addresses using the size arguments and base virtual address information, given an offset into the 
scratchpad storage.
The stash map entry is invalidated at the end of the kernel computation to free up resources used by the entry,
such as scratchpad storage and TLB/RTLB entries (see below).
Applications still need to explicitly manage the storage of the scratchpad, and use scratchpad-local pointers for 
accessing scratchpad's private address space.
The instructions for accessing Stash storage is extended with an extra operand that specifies the pattern of the 
access by referring to a stash map entry.
Applications, however, do not need to load data from the global virtual address space to the scratchpad explicitly,
nor do they need to explicitly evict dirty data to ensure coherence. 
Instead, Stash operates similarly to a conventional on-demand cache, which loads data automatically from the 
global address space when there is an access miss, and automatically responds to coherence requests combing from
other components in the cache hierarchy. 
To accomplish this, each word in Stash hardware has an extra valid and dirty bit. The valid bit is set when a word 
is loaded from the global memory. If ths bit is not set on an access request, an access miss will be signaled, 
which triggers global memory accesses. 
The dirty bit is set if the word is written into, and is used to determine whether the word should be written back
on evictions or coherence requests.

