---
layout: paper-summary
title:  "A Scalable Architecture for Ordered Parallelism"
date:   2019-08-12 17:05:00 -0500
categories: paper
paper_title: "A Scalable Architecture for Ordered Parallelism"
paper_link: A Scalable Architecture for Ordered Parallelism
paper_keyword: Swarm; TLS; HTM; Speculation
paper_year: MICRO 2015
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes Swarm, a highly parallelized architecture supporting Thread-Level Speculation (TLS). This paper 
pointed out that some algorithms intrinsically have abundant parallelism, but most existing speculation mechanisms could 
not exploit them very well for several reasons. First, existing HTM designs are targeted at unordered execution of 
transactional regions. Optimizations such as dirty read are therefore disallowed to maintain isolation, which hinders
concurrency, because if the order of transactions can be known and tracked by hardware in advance, forwarding dirty data
from lower numbered tasks to higher numbers ones are totally legal. Second, speculative tasks are created dynamically
by earlier tasks, usually driven by the structure of the problem itself (e.g. in parallel version of Dijkstra's algorithm,
the creation of tasks are driven by the adjacency structure of nodes). This typically forces the program to be written
in a sequential manner (because there are control dependencies between tasks), which is hard to parallelize without knowing 
the specific problem. Third, unnecessary data dependencies are introduced if we maintain tasks using software structures. 
This happens not only when an explicit task scheduler is implemented, but also in data structures used by the algorithm.
For example, in Dijkstra's algorithm, a priority queue is used to track the distance of candicate nodes from the source.
Any insertion of new nodes into the queue is likely a conflict with some speculative tasks that dequeued a node from 
the queue, but this dependency can be eliminated if hardware can track the structure of task creation. The last 
reason is that existing software solutions can only provide limited performance improvement, while introducing a 
non-negligible overhead, which can offset any improvement gain from parallelization.

Swarm solves the above challenges using a task-based speculation model. Fine-grained pieces of code that can potentially
run in parallel if there is no conflict are abstracted as "tasks". The exection of tasks is expected to have only
a few data dependencies, which will cause the violating task and all its decendants, and related tasks to abort.
Tasks are assigned programmer-defined sequence numbers called timestamps, which specify the logical ordering tasks are 
executed. Swarm guarantees that it appears that tasks are executed sequentially following the partial ordering 
defined by timestmaps. If two or more tasks have the same timestamp, their relative ordering is undefined, and they can 
be in any logical total order (in practice this total order is the order they are selected for execution).

Swarm assumes a chip-multiprocessor organized as tiles. Each tile has a few number of cores, and its own private L1 and 
shared L2. LLC cache is 
shared among all tiles, and partitioned such that each tile has a slice of LLC array. Swarm assumes that the L1 cache is 
write-through. This may increase the latency of store instructions when the store buffer is at high load, but makes 
L1 flush instaneous since no write back is to be performed (we will see later how this benefits conflict detection).
Each tile has also a task unit, which consists of a task queue and a commit queue. The task queue holds pending tasks 
that are to be executed once resource is available, while the commit queue holds tasks that are completed and waiting
for lower numbered tasks to commit. These two structures are not necessarily of the same size, given that Swarm can commit
many tasks in the same cycle. The paper suggests that the commit queue should be implemented as a TCAM, while the task
queue can be implemented with two TCAMs that provide indexing capability to the structure. In the runtime, the 
task queue always selects the task with the minimum timestamp to execute.

The task queue consists of task structures, which contains context information that is necessary to start and maintain 
the task. The context information includes the starting address of the task (i.e. a function pointer), arguments to the 
task, and the task timestamp. In addition, each task structure has a finite number of entries that point to the child tasks.
A task spawns child task when it creates them. These child tasks are stored in the current task's structure, which is used
when the current task aborts (commit does not follow the child pointer). Child task pointers are a composite field of the 
tile ID and task queue index on that tile. Since a task never changes its location in the queue after it is inserted, this
uniquely identifies a task before it finishes and releases the entry.

Swarm adds two new instructions to the ISA: enqueue_task and dequeue_task. The enqueue_task instruction takes a function 
pointer, a timestamp, and function arguments as operands. A new task will be created by dispatching the context information 
and the parent task information to a randomly selected tile, at which site a new task structured will be allocated,
and these information will be filled in (the child pointer of the current task will also be updated). When dequeue_task
is executed, the processor performs a priority-based lookup, and selects the task with the minimum timestamp in the current
task queue. If the task queue is empty, this instruction will stall until a new task is added (this paper does not 
mention how a stalled processor can resume at the end of the computation; Queuing a task that indicates the end of the 
computation may do the job).

