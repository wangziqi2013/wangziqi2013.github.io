---
layout: paper-summary
title:  "Last-Level Cache Deduplication"
date:   2020-06-24 20:58:00 -0500
categories: paper
paper_title: "Last-Level Cache Deduplication"
paper_link: https://dl.acm.org/doi/10.1145/2597652.2597655
paper_keyword: Cache; LLC; Deduplication
paper_year: ICS 2014
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Highlight:**

1. Hardware assisted hash table is efficient for dedup or searching since multiple buckets could be read at the same time.
   It is essentially just a reduced form of set-associative cache.

This paper proposes deduplicated last-level cache for increasing effective cache size. Previously, researchers have been 
proposing techniques such as cache compression on block basis to reduce the size of a cache line, increasing effective
cache size. This paper adopts a different approach by identifying the potential of cache deduplication, a technique for
detecting iddentical cache lines and avoiding storing multiple physical line with the same content.
The paper begins by making the claim that in scientific computation workloads, cache lines are likely to contain duplicated
data for several reasons. First, some workloads tend to copy the same piece of data around for the purpose of initialization
or interfacing with libraries requiring input/output buffer (e.g. network protocol or file system operation).
Applications that extensively use memcpy() also creates duplicated lines on different physical locations.
The second cause for duplication is symmetry of the program input. More than often, scientific applications begin their
computation with highly regular data consisting of duplicated patterns. Such pattern can also be exploited to reduce 
cache consumption.
The paper also noted that most of these duplicated lines are not pure zeros. Simply detecting zero lines will not work
well in the majority of the cases.

The paper then identifies a few challenges of designing a cache deduplication scheme. First, the deduplication hardware 
should be carefully designed, such that duplications can be detected efficiently, without incurring high cycle penalty, 
power consumption, or area overhead. Second, The deduplication granularity should be carefully selected to reach a balance
between the probablity that duplications are detected, and the hardware overhead of fine-grained deduplication.
The last challenge is that the cache layout should be modified to allow many-to-one mapping between tags and data slots.
In addition, there shold be more tags than data slots in order to support a large effective cache size.

We next introduce the cache organization as follows. As discussed above. the deduplicated cache decouples tag array
and data array from the one-to-one static mapping scheme, adding one extra level of indirection in tag address to
allow more than one tags being mapped to one data slot. To achieve this, each tag array is extended with an extra 
"data pointer" (dptr) field, which points to the data slot that stores the content implied by the address tag.
To help bulk invalidation of tags when the shared data slot is invalidated, tags are also linked together with other 
tags that share the same data slot using a doubly linked list. Two more pointers, called "tag pointers" (tptr), are 
added to each tag for finding the successor and predecessor of nodes in the linked list. 
Conventional per-line metadata, such as coherence states and status bits, are not changed.

