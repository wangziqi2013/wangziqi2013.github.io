---
layout: paper-summary
title:  "FPTree: A Hybrid SCM-DRAM Persistent and Concurrent B-Tree for Storage Class Memory"
date:   2019-11-17 15:35:00 -0500
categories: paper
paper_title: "FPTree: A Hybrid SCM-DRAM Persistent and Concurrent B-Tree for Storage Class Memory"
paper_link: https://dl.acm.org/citation.cfm?id=2915251
paper_keyword: NVM; B+Tree
paper_year: SIGMOD 2016
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents FPTree, a B+Tree designed for byte-addressable non-volatile memory. This paper points out, at a high 
level, several challenges of implementing data structures for NVM. First, the data structure should be able to recover to
a consistent state after a crash. This is typically achieved by flushing certain data back to the NVM to enforce write
ordering between metadata (commit mark, log entry, etc.) and data using persistence barrier. Considering that NVM writes
are only atomic on 8 byte aligned words at the CPU side, and that data persistency is only atomic on cache line granularity
at the NVM side, partial writes might occur after a crash, if the crash happens during or after the write. There are three 
common patterns for ensuring consistency. The first pattern is writing data into invalid area (assumed to be initialized
to zero). This happens when inserting elements into a B+Tree node. In this case, we first acquire storage for the write, 
and then perform write. A valid mark is set only after the write completes and is flushed back to the NVM. The valid mark 
can be appended after the write as a log, or be set in a separate header structure. A second flush on the valid mark commits 
the write operation. Since the mark can be set with only 8 byte atomic writes, the commit operation is also atomic with 
regard to failures. The second pattern is writing data into invalid area, but allows data to be invalidated (deleted) before 
they can be written into again. This corresponds to insert and delete operation on a tree node. The first half (insertion)
is exactly the same as the previous pattern. The second half can be easily achieved by resetting the valid mark during 
the first half to a value indicating deleted entry, and then flushing the mark, which commits the delete operation. 
Garbage collection is required to reclaim deleted entries to avoid fragmentation. In the third pattern, an entry is first
inserted, which is handled as in the first pattern, and then updated without being deleted. If the update can be done with
8 byte atomic write, then we simply perform the update and then flush the value. Otherwise, we write a redo write-ahead 
log to describe the operation, flush the log, after which the actual content is updated in-place. The log can only be 
removed after we flush the in-place update back to the NVM. During recovery, the log entries are first processed by replaying
the operations recorded in the log.

The second challenge is data recovery. This paper assumes using direct access (DAX) provided by the file system to expose
the NVM address space to users using virtual memory. Users need to call mmap() on the NVM file, which allocates a range 
of virtual addresses that are mapped to the corresponding physical pages that are used to store the content of the file. 
DAX provides better control over access permission and storage management, since the file system only exposes the part of 
physical addresses that are used to store the file to users. Unrelated NVM storage is protected by the MMU. When users 
expand the NVM file, the file system allocates new pages from the NVM address space, and adds them to the file inode. 
Compared with conventional DAX implemented on block storage, DAX on NVM does not use damand paging and rely on page faults
to bring file contents into a memory buffer before access. Instead, the OS directly maps the requested virtual addresses
to physical pages on the underlying NVM hardware. Furthermore, fsync() on NVM DAX file no longer flushes the buffer. Instead,
we issue flush instructions on every cache line of the affected page to ensure that the page is persistent on NVM.
This process, however, does not guarantee that the same NVM file can always be mapped to the same virtual address on each
map, as the virtual address space can be occupied by libraries and/or other DAX files, reaulting in virtual address pointers
being invalidated. To preserve the semantics of pointers, this paper proposes using DAX-aware pointers, which is a 16 byte
pair storing the file ID and offset within the file. No special compiler instrumentation is needed, as the pointer
format is only used within the B+Tree. Users always observe normal virtual address pointers in the rumtime. 

