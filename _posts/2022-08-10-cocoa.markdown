---
layout: paper-summary
title:  "Cocoa: Synergistic Cache Compression and Error Correction in Capacity Sensitive Last Level Caches"
date:   2022-08-10 22:40:00 -0500
categories: paper
paper_title: "Cocoa: Synergistic Cache Compression and Error Correction in Capacity Sensitive Last Level Caches"
paper_link: https://dl.acm.org/doi/10.1145/3240302.3240304
paper_keyword: Cache Compression; BDI; ECC
paper_year: MEMSYS 2018
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Comments:**

1. The paper claims that fine-grained remapping/disabling approaches do not work well under high defect rates.
Then later on in the paper, it is shown that actually the defect rate is not that high, with most words containing
less than 3 errors.
In the case where the defect rate is really high, Cocoa would not work well as well, because Cocoa falls back to
the fine-grained disabling approach if a single word in a compressed block has more than two faulty bits.

This paper proposes Synergistic Cache Compression and Error Correction (Cocoa), a technique that enables the LLC
to operate under low voltage while maintaining low error rate.
Cocoa is motivated by the power benefit of operating caches on low voltages, at the cost of increased error rate.
Cocoa addresses the issue with extra error correction and detection code stored in a few dedicated way of the 
data array.
To counter the performance degradation caused by a smaller data array for strong data, cache compression is 
applied to the rest of the ways such that more logic blocks can be stored in compressed form.
The resulting design enables the LLC to operate at a much lower voltage with low error rate, hence harvesting
the power benefit, without hurting performance.

The main challenge of low-voltage cache design is the increased error rate, which is a natural result of 
randomness from the manufacturing process. While operating nicely on the normal voltage, small manufacturing 
variations on SRAM cells will become a bigger concern when the cache operates under a lower voltage, where some 
cells are more prone to suffer bit errors than other cells. 
To address this problem, several attempts have been made by prior works, which we describe as follows.
First, prior works have proposed bigger and more complicated SRAM cell structure, which is more tolerant to 
random variations and hence perform better in terms of error rate under low voltage. These cells, however,
generally require much more transistors per cell, which increases the area and power overhead of the SRAM
cache, partially offsetting the purpose of low voltage operation.

Second, prior works have also attempted to dynamically disable or remap faulty SRAM bits that are detected
beforehand. This task can be carried out in either coarse or fine granularity. In the former case, an entire line,
set or way can be disabled if they are known to be error-prone. This often results in severe and unnecessary 
loss of capacity, since one single bit defect can cause a large chunk of non-faulty bit to be disabled as well.
In the latter case, complicated hardware is required to remap SRAM cells at fine granularity. Besides, the paper
claims that these techniques are not really effective with high defect density, as still suffer great capacity 
loss in these situations.

Previous works also propose adding extra redundancy to the data array, such that defective blocks or sets can be 
remapped to the redundant SRAM storage.
While preserving the logical cache capacity, this approach is upper bounded the number of defects it can fix.
When the number of defective bits exceed the maximum amount of redundancy, this approach would still fall back
to the previous one, and suffer cache capacity loss.