---
layout: paper-summary
title:  "Optimizing Hash-Array Mapped Tries for Fast and Lean Immutable JVM Collections"
date:   2020-08-28 17:47:00 -0500
categories: paper
paper_title: "Optimizing Hash-Array Mapped Tries for Fast and Lean Immutable JVM Collections"
paper_link: https://dl.acm.org/doi/10.1145/2814270.2814312
paper_keyword: HAMP; CHAMP; Persistent Data Structure
paper_year: OOPSLA 2015
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Lowlights:**

1. This paper is written badly, with lots of jargons and concepts unexplained (what are "elements"? It took me a while to 
   figure out that the authors are referring to terminal level values, which is to differentiate it from next-level child
   nodes). I inferred most parts by guessing instead 
   of reading the actual text. Some terminologies are not used properly, such as "memorization", which is often used to
   refer to a programming technique that is used in top-down recursion.
   One example of bad grammar is on page 8, right below listing 6:
   "With MEMCHAMP we will refer throughout the text to the
    variant of CHAMP that adds memoized element hash codes,
    but drops incremental collection hash codes."
    Can you be more obsecure with this sentence structure?

2. I did not see how memory footprint is reduced. In the HAMT design, each node must contain 32 slots (actually, 64, since 
   full keys are also stored). In CHAMP, although empty slots are removed using `nodeMap` and `dataMap`, in the worst
   case where the node is full with all terminal values, 64 slots are still needed, unless the array can be extended
   dynamically, which is not mentioned at all in the paper.
   Cache locality is improved, though, since useful values are likely closer to each other in a sparse node.

This paper introduces Compressed Hash-Array Mapped Prefix-Trees (CHAMP), which is an improvement over the existing Hash-Array 
Mapped Tries (HAMT). The paper identifies four problems with a naive HAMT. The first problem is that tries (radix trees)
consume too much memory by maintaining a full sized node when most of the slots are empty. This both causes, excessive 
memory to be allocated for storing non-meaningful NULL values, and hurts cache performance, since the memory footprint 
of nodes become larger. The chance that a node access will hit the hardware cached copy decreases compared with a 
more compact representation.
The second problem is deletion. The original HAMT design lacks a proper deletion algorithm, such that the radix tree cannot
be restored to the canonical shape, resulting in sparse nodes and singleton paths, wasting both memory and cycle.
The third problem is bad cache locality of iteration, due to the fact that child node pointers and elements can be 
stored in an interleaved manner in a direct mapped node. The iterator will have to traverse to childen nodes recursively 
before returning to the current node and consinuing iterating on the current node, resulting in poor cache locality.
The last problem is equality checking, which involves iterating over all elements stored in one radix tree and comparing 
the element against elements stored in another tree.
Equality checking is inefficient without a canonical representation of trees with the same content, and with the poor 
cache locality of iteration.

The work of CHAMP is built on HAMT, a radix tree-based hash table implementation. Hash values of key objects are inserted 
into the radix tree, with the object itself being the mapped value. HAMT can be used as both sets and maps. If only
key objects are mapped, the HAMT instance essentially serves as a set. Membership of an object can be checked, by
first hashing the object, and then using the hash value to perform a tree lookup. Set membership is indicated by a successful
lookup. If an extra value object is stored with the key object, then the HAMT serves as a map, which returns the value
object given the key object following the same lookup protocol.

We next describe the baseline HAMT in details. The hash key is divided into 5 bit slices, from the LSB to the MSB, which 
is used as search indices at each level. Given a fixed size of hash values, the maximum depth of the tree is also constant
(upper\_bound(|H| / 5) where |H| is the number of bits in the hash value).
Each node in the baseline is a 32-slot direct mapped array. The 5-bit key slice is used as an index into this array to
fetch the element.
HAMT supports eager termination of the traversal at level L (L < maximum depth), if the remaining slices are not needed 
for disambiguation. In other words, element insertion can stop at level L, if the corresponding slot at level L
is empty, and just store the object at level L without further extending the path to the leaf level.
On future insertions, if a slot value is an element, instead of a node, we lazily expand the path by allocating a new
node, and attempt to store both the new and the existing element on the new node. If this is impossible, indicated by
the fact that their key slices for level (L + 1) have the same value, we further
extend the path by allocation another new node at level (L + 2). This process is repeated, until leaf level is reached, 
or until both elements can be stored at different locations of the newly allocated node.
In a moderately sparse HAMT, this feature greatly reduces the number of steps in the traversal, as well as the number 
of singleton nodes in the tree.

Path compression, however, is not performed during deletions. In the above example, if the second key inserted into the 
HAMT is deleted later, the structure of the tree will remain what it was before the deletion, instead of "shrinking"
to the pre-insertion state. This not only introduces unnecessary levels, but also creates difficulties in equality
checking, since two HAMTs holding the same content may not have identical tree structure. In other words, the shape of the
tree is a function of both the current content and the insert-delete sequence that has been applied.

CHAMP optimizes HAMT over node layout, deletion protocol, equality algorithm, and fast iteration. Many of these optimizations
are not standalone, but will rely on each other or share the same infrastructure. We next describe these optimizations
in details.

HAMT node layout is a 32-slot static array, to which key slices are direct mapped. This, however, always allocates 32 
slots in the array, which can be more than necessary, if the node is sparse. In addition, the locality of node traversal 
is affected by NULL values. CHAMP improves over HAMT node layout with three techniques. First, NULL values are not 
stored, which reduces the size of the array. Two 32-bit integers, used as bitmaps, encode the logical layout of the array 
as follows. A `nodeMap` encodes slots that store a next-level child node pointer. Each child node pointer only takes
one slot. A `dataMap` encodes slots that store a terminal values, which can be either a single key object for sets, or 
a key and value object for maps. In the latter case, each logical slot in the `dataMap` actually requires two physical 
slots, which are allocated as two adjacent slots in the array.
The invariant is that at most one bit in `nodeMap` and `dataMap` is set.
To avoid complicated offset computation, the array of slots in CHAMP nodes are allocated from both ends, one for 
node pointers, and another for key or key-value pairs. Elememts in the array are compactly stored regardless of the 
logical NULL pointers in-between.
The offset of a logical element in `nodeMap` at logical index X is computed by masking off bits in `nodeMap` after 
bit X, and performs a popcount of "1" bits in the resulting mask. 
The offset of elements in `dataMap` is computed similarly, but the result of popcount is further subtracted from the 
size of the current array, since the physical `dataMap` starts at the end of the array, and grows towards lower 
indices.
The size of both logical arrays are computed by counting the number of "1" bits in the masks. 
If, before an insertion, the physical array is full, indicated by the sum of bit counts from both masks equalling the 
array size, then a reallocation will take place to extend the array before the insertion could be performed.

The second improvement is the deletion protocol. HAMP deletions do not shirnk the path, resulting in unnecessary intermediate
nodes that do not contribute to disambiguation using key slices, wasting both storage and cycle.
This paper proposes n deletion protocol that "folds" singleton paths from the most recent non-singleton node to the 
bottommost node, if the deletion results in such a singleton path. 
