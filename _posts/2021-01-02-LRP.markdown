---
layout: paper-summary
title:  "Lazy Release Persistency"
date:   2021-01-02 14:06:00 -0500
categories: paper
paper_title: "Lazy Release Persistency"
paper_link: https://dl.acm.org/doi/10.1145/3373376.3378481
paper_keyword: NVM; Persistency Model; LRP; Release Persistency
paper_year: ASPLOS 2020
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Lowlight:**

1. This paper is poorly motivated, because: (1) it does not state why LFDs do not need recovery (because state changes
   are made with CAS, maintaining the invariant that the data structure is in legal states on every CAS mutation);
   (2) it does not state why ARP is insufficient for LFD (because the CAS might be made persistent after writes
   to private nodes, i.e., the CAS should be treated as a single-direction barrier, but be enforced lazily);
   (3) it does not even state why the proposed RP is critical for LFD.

2. Although not the fault of this paper, ARP should not really be called ARP, since it has nothing to do with
   acquire-release consistency model. Conventionally speaking, acquire-release means that memory operations should
   not be ordered before acquire and after release, meaning that critical sections will not "leak". The ARP
   discussed by this paper
   is simply enforcing ordering between data dependencies of different critical sections, and ARP is a very poor
   choice of name since reordering with release operation is actually allowed.

This paper proposes Lazy Release Persistency (LRP) to optimize specifically the case for log-free data structures (LFD).
The paper starts by observing that current persistency models all face similar problems. First, most previous proposals
are overly restrictive when it comes to persistence ordering barriers in the form of cache flushes and memory fences.
These proposals either fail to exploit inherent parallelism in most NVM workloads by stalling the pipeline on a 
persistence operation, which fully couples memory consistency with persistence, or they only insert full barriers 
regardless of the actual semantics level requirments, even though persistence is conducted in the background,
which is still sub-optimal since not all legal reorderings are possible.
Second, some proposals are overly relaxed, failing to enforce certain orderings, which makes it non-trivial for LFDs
to perform crash recovery. These models, although still useful to other types of tasks, require extra software 
support in order for LFDs to work properly.

The paper gives detailed overviews of three possible persistence models. The first, Epoch Persistency (EP), although 
not directly mentioned in the paper, serves as the foundation of the other two, and is the only one currently 
implemented on mainstream x86 hardware. In epoch persistency, the dynamic instruction flow is divided into continuous 
pieces, called epochs. The persistency model enforces the rule that write operations must be persisted in the order of 
epochs, while allowing arbitrary ordering of writes within the same epoch.
Application programs start a new epoch by issuing cache flushes to all dirty cache lines that are to be written into
the NVM, followed by a store fence. The store fence operation will block the store buffer until all previous cache 
line flush backs have been completed, after which time later stores can proceed to the L1 cache and become visible.
As discussed above, epoch persistency couples persistence with consistency, meaning that a memory operations must not
become visible to other cores before previous stores in an earlier epoch becomes persistent, which limits the 
parallelism of persistence despite the fact that both the device and application have abundant degree of parallelism. 

The paper then discusses Buffer Epoch Persistency (BEP), which is an improvement over epoch persistency by decoupling 
persistence from consistency. Writes in the store buffer are no longer blocked by non-persistent stores in the previous
epoch. Instead, these writes are injected into the L1 cache as soon as they are ready, and the cache hierarchy relies
on extra mechanism to track the epoch of writes, and persists them in the background while the epoch ordering is 
still being honored.
Although BEP moves the persistence operation off the critical path of stores, it is still sub-optimal, since writes 
in later epochs cannot bypass writes in previous epochs, implying that when a write from a later epoch is to be 
evicted out of the hierarchy (or, most likely, L1, since this is where the tracking mechanism is implemented), the 
eviction must be blocked until all previous epochs have been completed.

The paper next introduces Acquire-Release Persistency (ARP), which relaxes the epoch property of EP and BEP by
allowing epochs to be discontinuous in the dynamic trace, and hence can be persisted lazily. ARP delays the insertion
of a persistence barrier to the beginning of the next epoch, instead of right after the end of the current epoch, 
overlapping execution with persistence. 
In ARP, memory operations are optionally tagged as acquire and release, which roughly correspond to lock acquire and 
lock release in explicit synchronization code. 
ARP mandates that if an acquire operation synchronizes with a release by operating on the same 
data item (typically an unlock-lock), then all writes performed before the release must be persisted before all writes 
after the acquire. 
In the hardware implementation, this is achieved by lazily inserting a full persistence barrier when an acquire
sycchronizes with a previous release. The release operation itself, as well as all writes before it, are written
back to the NVM before the acquire operation takes place.

The paper then indicates that Log-Free Data Structures (LFDs) can benefit from a well-designed persistency models.
LFDs differ from conventional data structures in a way that LFDs do not require any explicit crash recovery, unlike
the latter where logging or shadowing must be applied to roll back partial changes or redo committed updates.
In LFDs, all state mutations are achieved by first performing private writes (e.g., allocate a node, and then initialize
the node), and then publishing the state change using an atomic CAS or a release write operation. 
Multi-step mutations are performed by always using CAS for state transition, and each intermediate state is well-defined
as a legal state to the data structure. On crash recovery, since the data structure's state only transits between
these legal states, no recovery is required, and the LFD is guaranteed to be consistent.
Generally speaking, the most critical write ordering of LFD is that private writes must be ordered before the
CAS, meaning that the content of the mutation must be in a recoverable state, before publishing them to other threads.
Otherwise, the mutation may only be partially persisted after the crash, rendering the LFD inconsistent.

Although one may feel tempted to just tag the CAS operation as a release, and rely on hardware to control the persist
ordering, the paper points out that ARP is insufficient for implementing LFDs.
ARP, as discussed above, only controls write ordering between two acquire-release enclosed critical sections if the 
acquire and release access the same data item. The ordering between the release operation itself and writes before the
release, however, are not enforced, which is fatal for LFD's consistency guarantee.

On the other hand, EP and BEP are sufficient in terms of correctness, but rather inefficient since they require issuing
two full barriers, one before the release, the other after the release. The second full barrier is important for
integrity of data flow after crash, since any other threads accessing the CAS'ed data item can potentially establish data dependencies with the CAS'ing thread. 
