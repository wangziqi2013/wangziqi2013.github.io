---
layout: paper-summary
title:  "Lazy Release Persistency"
date:   2021-01-02 14:06:00 -0500
categories: paper
paper_title: "Lazy Release Persistency"
paper_link: https://dl.acm.org/doi/10.1145/3373376.3378481
paper_keyword: NVM; Persistency Model; LRP; Release Persistency
paper_year: ASPLOS 2020
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Lazy Release Persistency (LRP) to optimize specifically the case for log-free data structures (LFD).
The paper starts by observing that current persistency models all face similar problems. First, most previous proposals
are overly restrictive when it comes to persistence ordering barriers in the form of cache flushes and memory fences.
These proposals either fail to exploit inherent parallelism in most NVM workloads by stalling the pipeline on a 
persistence operation, which fully couples memory consistency with persistence, or they only insert full barriers 
regardless of the actual semantics level requirments, even though persistence is conducted in the background,
which is still sub-optimal since not all legal reorderings are possible.
Second, some proposals are overly relaxed, failing to enforce certain orderings, which makes it non-trivial for LFDs
to perform crash recovery. These models, although still useful to other types of tasks, require extra software 
support in order for LFDs to work properly.

The paper gives detailed overviews of three possible persistence models. The first, epoch persistency, although not 
directly mentioned in the paper, serves as the foundation of the other two, and is the only one currently implemented
on mainstream x86 hardware. In epoch persistency, the dynamic instruction flow is divided into continuous pieces,
called epochs. The persistency model enforces the rule that write operations must be persisted in the order of epochs,
while allowing arbitrary ordering of writes within the same epoch.
Application programs start a new epoch by issuing cache flushes to all dirty cache lines that are to be written into
the NVM, followed by a store fence. The store fence operation will block the store buffer until all previous cache 
line flush backs have been completed, after which time later stores can proceed to the L1 cache and become visible.
As discussed above, epoch persistency couples persistence with consistency, meaning that a memory operations must not
become visible to other cores before previous stores in an earlier epoch becomes persistent, which limits the 
parallelism of persistence despite the fact that both the device and application have abundant degree of parallelism. 

The paper then discusses buffer epoch persistency (BEP), which is an improvement over epoch persistency by decoupling 
persistence from consistency. Writes in the store buffer are no longer blocked by non-persistent stores in the previous
epoch. Instead, these writes are injected into the L1 cache as soon as they are ready, and the cache hierarchy relies
on extra mechanism to track the epoch of writes, and persists them in the background while the epoch ordering is 
still being honored.
Although BEP moves the persistence operation off the critical path of stores, it is still sub-optimal, since writes 
in later epochs cannot bypass writes in previous epochs, implying that when a write from a later epoch is to be 
evicted out of the hierarchy (or, most likely, L1, since this is where the tracking mechanism is implemented), the 
eviction must be blocked until all previous epochs have been completed.
