---
layout: paper-summary
title:  "BCD Deduplication: Effective Memory Compression Using Partial Cache-Line Deduplication"
date:   2021-04-23 21:08:00 -0500
categories: paper
paper_title: "BCD Deduplication: Effective Memory Compression Using Partial Cache-Line Deduplication"
paper_link: https://dl.acm.org/doi/10.1145/3445814.3446722
paper_keyword: Compression; Memory Compression; Deduplication; Inter-Block Compression
paper_year: ASPLOS 2021
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents BCD deduplication, a memory compression technique using block clustering inter-block compression.
The paper points out the limitations of previous deduplication and compression proposals as follows.
First, many previous schemes rely on in-memory mapping table for address remapping, due to blocks being 
variable sized after compression. These mapping tables inevitably incur more memory accesses during both reads
and writes, which will affect performance. 
Second, previous deduplication schemes, despite the fact that they can catch a wider range of block duplications
by running on the entire address space rather than a cached subset, still underperforms stat-of-the-art compression 
due to the granularity of deduplication being too coarse, which is on cache block level.
Lastly, most current compression algorithms either seek special word patterns within a block, such as BDI, FPC, 
and BPC, or rely on a dictionary to encode frequent words using less number of bits. In the former case, 
compression ratio is sub-optimal, despite low compression and decompression latency, since the algorithm only
exploits redundancy in a cache block without considering inter-block redundancy. In the latter case, statistics must
be generated in advance, and not changed frequently thereafter, such that correctness is guaranteed.

BCD deduplication, on the other hand, combines inter-block diff compression with deduplication. Its compression
algorithm consists of two steps. In the first step, cache blocks that are likely to contain similar contents are
clustered together into the same hash table bucket, and compared with each other. The bit-level diff is taken
in a specific form such that the diff is only three-fourth of the size of an uncompressed block.

In the second step, the bit-level diff is then compressed, and hashed into another hash table to perform deduplication. 
This two-level scheme exploits both inter-line redundancy by only storing line diff, and intra-line redundancy
by compressing the diff bits and performing deduplication of these diff, which are expected to yield higher
compression ratio than a single-level scheme that only takes advantage of one of the two types of redundancy. 

We next describe the two steps as follows. The first step uses a hash table to cluster cache lines that have the
same upper bits. The clustering algorithm takes higher 16 bits in each 64-bit word, combines them into 16-bytes 
segment called the "higher bits", and then hashes it to a one-byte partial signature value. In the meantime, the full
cache block is also hashed into a full signature. Both values will be used during the first step as we will see later.

Address translation is performed by mapping the physical address, which is used by the cache hierarchy,
to a direct-mapped translation table. Each translation table entry consists of two address pointers and two bits.
The address pointers are base pointer and diff pointer, which points to the base data and compressed diff, if
exists. The two status bits indicate whether a diff exists, and whether the diff is compressed.
Reads do not access any in-memory data structures other than the translation table. 
On a read operation, both pointers are used to fetch base data and compressed delta, if any, and then the delta
is decompressed and combined with the base to generate the original block content. 
Read operations therefore require at most three DRAM accesses, upper bounding the worst case scenario.

The size of a translation table entry is 64 bits, in which each pointer uses 31 bits. Since base blocks are always 
stored in block-aligned addresses, 31-bit pointer can address as much as 128GB memory. Diff blocks are stored 
on 16-byte boundaries (reasons discussed below), and hence 31-bit diff pointer can address at most 32GB diff.
Overall, the translation table occupies a constant 1/8 of total storage, since every memory block address has a 
direct-mapped entry in the table.



