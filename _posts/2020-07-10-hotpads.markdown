---
layout: paper-summary
title:  "Rethinking the Memory Hierarchy for Modern Languages"
date:   2020-07-010 03:46:00 -0500
categories: paper
paper_title: "Rethinking the Memory Hierarchy for Modern Languages"
paper_link: Rethinking the Memory Hierarchy for Modern Languages
paper_keyword: Cache; Hotpads
paper_year: MICRO 2018
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Highlight:**

1. Creating objects directly in the cache rather than alloc it first in VA space can help reducing compulsory cache misses.
   This is also leveraged in page overlays.

2. It is good thinking to treat caches as independent devices that have their own address spaces, rather than transparent
   faster storage for the PA space. This brings more interesting use cases and more algorithms that are originally designed
   for distributed systems.

**Lowlight:**

1. This design is really just a mixture of over-thinking and ad-hoc algorithms. I understand that the author
   may obtained the initial idea from software generational GC and felt motivated to port it to hardware. But really, GC
   and memory allocation is not a thing that you should perform purely on hardware. 
   Although the authors tried their best to make the design as flawless as possible, the inelegant ad-hoc and hardwired 
   logic and implicit assumptions make at least me uncomfortable when reading the paper.

This paper proposes Hotpads, an eccentric memory hierarchy architecture that optimizes for small object allocation, 
garbage collection in managed languages, memory safety, and reducing associative lookup costs in conventional cache
hierarchy. The paper is motived by three important observations on modern programming languages. First, modern languages
are mostly memory safe with object abstraction. The memory layout of objects are opaque to application code, which cannot
be directly addressed using pointer cast or pointer arithmetic, but only accessed with pre-defined methods. This reduces 
chances that unintended wild pointers, buffer overflows or malicious attacks from corrupting the state of objects.
The architecture, however, failed to provide such protection on ISA level, forcing language runtimes to implement their 
own memory protection mechanism.
Second, most modern languages rely on background automatic garbage collection to recycle dead objects, which takes a 
software thread to periodically scan objects in the background, which also potentially moves objects around for
compaction. The usage of GC algorithms is already a feature in these languages that is so common to justify a hardware 
implemented version be embedded in the cache system.
Lastly, the paper also points out that conventional cache systems require an associative lookup of the tag array for 
each cache access, which has large power overhead. The paper seeks to reduce such overhead by using pointers that directly
point to cache locations, rather than to the underlying physical address space. Cache accesses, in most cases, are 
just to follow the pointer to the data array and access its content without an associative address tag lookup.

The paper describes a complicated memory hierarchy that operates at object granularity. The most prominent feature of 
Hotpads is that pointers do not store linear addresses in the virtual memory space, assuming a uniform address space
between DRAM and cache. Instead, caches are more similar to independent storage devices called "pads", which must be 
explicitly addressed. This is different from the conventional transparent abstraction of a faster main memory, in
which each access to the cache must involve translation between the pointer address and the cache's internal address. 
In addition, objects are no longer backed by the main memory, i.e. all objects must have a main memory address in order 
to be uniquely identified across the system. In Hotpads, each cache device has its own address space. Objects can be 
backed by any of the storage device in the hierarchy without explicitly allocating storage in other components of the 
hierarchy. Objects are accessed by creating copies from their backing store to the L1 pad. Active pointers referring to 
the objects are also rewritten to point to the L1 copy of the object for fast, direct access, without any associative lookup.
Lastly, Hotpads implement memory allocation and garbage collection in hardware. The data array of a pad is maintained as a 
heap which always allocates from the head. Object allocation is as simple as incrementing the head pointer of the pad.
In case of storage exhaustion, pads at each level will perform per-object hardware controlled garbage collection and 
object eviction automatically independently without software intervention. Objects allocated by software therefore do not 
need to be freed explicitly. In order to identify blocks to be freed, the hardware periodically runs a scan-and-mark garbage 
collection algorithm using pointer values in the register file as root pointers. Live blocks that are not frequently used 
are also evicted. The remaining blocks are then moved to form a compacted chunk, which frees storage in the data array
for future allocation.

The data flow of Hotpads is more similar to the one in a tiered distributed system than in the conventional cache.
The system is still divided into different levels as the conventional cache, with higher levels featuring smaller
but faster storage, and lower levels with larger but slower storage. Each level of the pads, including the main memory,
has a private address space that can be directly addressed by upper level requests without address translation. Pointers
may store addresses to any of these levels as long as the object to be pointed to fulfills certain properties (discussed 
later).
