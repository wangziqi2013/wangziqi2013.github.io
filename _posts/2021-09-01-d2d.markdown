---
layout: paper-summary
title:  "The Direct-to-Data (D2D) Cache: Navigating the Cache Hierarchy with a Single Lookup"
date:   2021-09-01 23:47:00 -0500
categories: paper
paper_title: "The Direct-to-Data (D2D) Cache: Navigating the Cache Hierarchy with a Single Lookup"
paper_link: https://dl.acm.org/doi/10.1145/2678373.2665694
paper_keyword: D2D Cache; TLB
paper_year: Computer Architecture News, June 2014
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Direct-to-Data (D2D) cache, a cache hierarchy architecture that gets rid of the conventional
tag array and uses centralized repository for cache block location lookup. 
This paper is based on a previous work on tag-less L1 cache, which can be found [here]({% post_url 2021-08-23-tlc%}).
The D2D cache adopts the idea of tag-less L1 cache that extends the TLB as page-sized super-block tag array, and 
applies the same design philosophy to the remaining levels of the cache hierarchy, seeking to remove the tag 
array entirely for all cache components.
To achieve this, the D2D cache adds a few extra hardware components that track not only the location of a block in the 
L1, but also the location in the hierarchy and the sharing status.

The D2D cache is developed based on Tag-Less Cache (TLC), which is motived by the fact that both tag array lookup 
and parallel data array read consumes a significant portion of energy of an L1 cache. 
This is, however, unavoidable in a tag-based cache, since the block can be stored in any of the ways within a set.
The TLC design, on the other hand, proposes that the way number and validity status be tracked by the TLB, essentially
decoupling the tag and data array, and treating the TLB as a page-sized super-block tag array.
Each TLB entry (called an eTLB entry) in TLC hence contains a vector of valid bits and an array of way numbers, with
each of them tracking the status of a block virtual address at the corresponding offset.
Cache accesses will then use the information in the TLB to determine whether the requested address if cache, and if 
it is, the way number within the set where it is stored. 
Each cache block in the data array must also be extended with a back-pointer to the eTLB entry whose virtual address
covers the block address, such that the entry can be updated to reflect a status change when the block is evicted.
When an eTLB entry is evicted, as a result of TLB replacement, all blocks whose addresses lie within the page
virtual address of the evicted entry must also be evicted, since every block in the cache should be covered
by an eTLB entry.
Due to the nature of TLB being a virtual address cache, the TLC is also virtually addressed, and hence is prone to 
homonym and synonym issues. Homonym is resolved with the existing ASID field of TLB entries, meaning that entries
mapping the same virtual address to different physical addresses can still be distinguished by the TLB with the 
additional ASID field. Homonym is not handled by the TLB itself, and TLC paper proposes that a reverse translation 
table mapping physical page addresses to virtual page addresses be added for tracking homonyms. 
When an entry is to be inserted into the eTLB, the reverse table is consulted to enforce the invariant 
that none of the existing virtual addresses already map to the same physical address. 
If synonym is detected, the invariant is enforced by copying the existing entry to the new entry, rewriting its
address, and retaining the cache blocks covered by the entry.

The D2D cache extends the above paradigm to the L2 and potentially LLC by also tracking the current holder of the block
in eTLB entries (the paper uses a two-level cache hierarchy with shared L2 as example). 
In addition, the D2D proposal adds a hardware directory called the Hub, at the L2 level, that serves 
as a central repository for tracking cache line status in the entire hierarchy. The cache location portion of L1 
eTLB is now treated as a smaller but faster "cache" for the Hub.
The Hub is organized as a set-associative Content-Addressable Memory (CAM) using physical page address as keys.
Each entry of the Hub tracks the location of the block addresses for all blocks within the page using three fields: 
A "valid" bit field indicating whether the address is actually cached anywhere in the hierarchy; A way number 
field indicating the way number of the block; A component ID field indicating the current cache component that
holds a cached copy of the block. 
Each Hub entry also has a pointer to eTLB entries, which stores the index of the entry if the same physical page 
is also in the eTLB (and set to invalid if the page is not in the eTLB).

To simplify location tracking of cache blocks, the D2D hierarchy is strictly exclusive, meaning that a block can be
cached in at most one components across the hierarchy, such that only one component ID needs to be tracked.
The D2D design also enforces two invariants. First, all blocks in the hierarchy must have an entry in the Hub
whose physical address covers the block's address. To help finding the Hub entry, a per-block pointer to Hub entries is
also added to all blocks in the hierarchy.
The second invariant is that the Hub is always inclusive to the eTLB, meaning that every entry of eTLB must also be
present in the Hub. 
In addition, if a physical page is both in the eTLB and the Hub, only information in the eTLB is considered as valid,
while the Hub copy can be stale.
This can be easily determined by checking whether the rTLB entry pointer in the Hub entry is valid or not, as a valid
pointer indicates that the eTLB entry should be used.

We next describe the operation of D2D caches as follows. In most cases, an access should hit the eTLB, and the valid
bit in the entry is checked. If the valid bit is set, then the block is directly fetched from either the L1 or the L2
(we deviate from what was described in the paper simplify it a bit by ignoring the L1 instruction cache) using the
way number stored in the eTLB entry.
Special care must be taken if the block is cached in the L2, as the L2 set index may be generated using bits from the 
physical page number. If this is the case (depending on the L2 cache configuration), the physical page number must
also be retrieved from the eTLB to compute the L2 index.
If the valid bit is not set, the block is deemed to be not cached in any cache component, and a request is directly 
sent to the main memory using the physical address derived from the conventional part of the eTLB. 
The new block, once fetched from the main memory, will be inserted into the L1 cache, and
the eTLB entry will be updated accordingly. 
The Hub pointer of the newly inserted block will also be set to the Hub entry.

If, however, that the eTLB misses, then the request is forwarded to the Hub, which stores the full set of information
of cache block status. Note that the Hub uses physical address for lookup, address translation must therefore be 
performed at L2 TLB first to retrieve the physical tag, which is then used for Hub lookup.
If the page that covers the block is in the Hub, then the block is fetched directly from the cache component indicated
by the Hub entry (the block can still be in L1 but eTLB may not have the entry for the block).
The TLB entry is also fetched from the Hub to the eTLB.

If the Hub also misses, then the block is not cached anywhere in the hierarchy, which triggers a cache miss. 
The block is then fetched from the main memory as in eTLB cache miss. In addition, a new entry is inserted into the Hub,
and the valid bit as well as the way number are also set accordingly.

On an eTLB eviction, the entry is just written back to the Hub, updating the Hub entry with potentially more up-to-date
block status.
