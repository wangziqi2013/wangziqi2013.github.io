---
layout: paper-summary
title:  "CSALT: Context Switch Aware Large TLB"
date:   2019-08-18 02:43:00 -0500
categories: paper
paper_title: "CSALT: Context Switch Aware Large TLB"
paper_link: https://ieeexplore.ieee.org/document/8686492
paper_keyword: TLB; LRU; Cache Replacement
paper_year: MICRO 2018
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes CSALT, a cache partitioning scheme for unified L3 TLB and data on lower level caches. The paper 
identifies that, on modern platform where virtualization is supported, running multiple virtual machines can overburden
the TLB with excessive misses, resulting in a massive number of page walks. A page walk on today's 2-D page table 
can take, in the worst case, 24 memory accesses (20 for accessing host page table for every guest physical address, 
and 4 for the standard 4-level guest translation), the latency of which can easily become a performance bottleneck
on a saturated system. 

Previous solutions focus on reducing the number of page walks required for a translation and reducing the latency of 
each page walk access. To reduce page walks which require a number of memory access on different levels of the page
table (typically four), previous researches propose using an in-memory L3 TLB which stores translation entries as 
a hardware TLB does in order to avoid a page walk. The L3 TLB can be as large as 16MB, a capacity that exceeds all 
hardware implementations. Some other researches also propose caching the intermediate page table entries in hardware
caches, such that the latency of accessing the entry can be reduced to as fast as a regular cache access. Using part
of the data cache to store TLB entries, however, can negatively affect performance, since the cache might be polluted
by extra TLB entries as a result of TLB misses. As we will see later, CSALT addresses the cache pollution problem 
by partitioning the cache into two parts, dedicated for data and TLB entries respectively.

In this paper, we assume that TLB entries are cached by the L2 and LLC, sharing the same storage with data accesses.
The paper also assumes that there is an underlying L3 TLB in the main memory, but also claims that this is not necessary,
and that the cache partitioning scheme works on all designs that cache page table entries in the data cache. Only translation 
entries (i.e. from VA to PA) are stored in the cache. Other intermediate entries might be cached by a dedicated cache
in the page walker.

To solve the cache pollution problem when data and TLB entries share the same cache, CSALT partitions the cache into two
parts, one for data and another for TLB entries. The partitioning parameter, N, dictates that in a way-associative cache, 
way 0 to way N - 1 of the cache is dedicated to data, while way N to the maximum way (W) is dedicated to TLB entries. 
When a memory access from upper levels misses the cache, the newly inserted entry must only be allocated from the 
data part, if the request is a regular load or store, or from the TLB entry part, if the request is to a memory region
allocated for L3 TLB (i.e. it is a hardware generated request to fetch L3 TLB entry).

CSALT is based on LRU as the cache replacemenr policy, but can also be integrated into other replacement algorithms. The 
basic idea of CSALT is that, on a set-associative cache, it is possible that 