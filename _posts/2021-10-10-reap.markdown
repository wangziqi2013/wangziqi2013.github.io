---
layout: paper-summary
title:  "Benchmarking, Analysis, and Optimization of Serverless Function Snapshots"
date:   2021-10-10 03:11:00 -0500
categories: paper
paper_title: "Benchmarking, Analysis, and Optimization of Serverless Function Snapshots"
paper_link: https://dl.acm.org/doi/10.1145/3445814.3446714
paper_keyword: Serverless; Keep-Alive; Caching Policy; REAP; Serverless Snapshot
paper_year: ASPLOS 2021
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents Record-and-Prefetch (REAP), a lightweight software mechanism for accelerating cold start from a 
VM image of serverless functions. The paper is motivated by the slowdown caused by frequent page faults and irregular
disk accesses when starting a new serverless instance from a prior snapshot on the disk. 
The paper observes that most function instances access a very stable subset of the working data that is in the snapshot,
and proposes to first track, and then prefetch those data pages in advance at VM start time to reduce the page 
fault handling and disk access overhead.

The cold start latency has become a well-known problem for serverless VMs, and it consists of three causes: The 
VMM itself, the kernel and runtime environment, and the function's own initialization.
Cold start latency complicates the management of serverless clouds for a few reasons. 
First, serverless functions are only billed for the actual time it takes to execute the function body. By spending
time on cold start for every function invocation, the cloud provider is essentially wasting hardware resource on 
computations that do not generate profit.
To address this issue, current cloud providers simply keep the VM instances alive in the main memory for tens of 
minutes before shutting it down. Future requests that hit the same function can hence reuse the VM instance, which
eliminates the unnecessary cold start.
Secondly, cloud providers tend to deploy thousands of instances on a single servers in order to achieve high tenancy 
level. The caching policy, while effective for a single function, may become a heavy burden in terms of memory, as 
each VM instance can take a few hundreds of memory, and thousands of them would require several hundreds GBs of main
memory, if cached, which is not realistic on today's platforms.
Lastly, according to a previous study conducted on Microsoft Azure, most functions (more than 90%) are only called 
sparsely, indicating that a fixed time caching policy will not work, as they are likely not being reused before 
being shut down, which offsets the purpose of caching.

More recent researches suggest that snapshotting might be another solution to the cold start latency problem without
incurring excessive memory overheads. In snapshotting, the memory image of the virtual machine is captured
after initialization has been performed, and saved to the secondary storage together with the guest virtual and physical
address layout (which can be obtained from the guest OS's page table) as a file object. The execution context is also
dumped such that execution could resume at the precise point where the snapshot is taken.
The next time the same function is requested, the VM is started with all of its guest physical addresses marked as 
invalid in the host OS's page table. The snapshot image is incrementally brought into the main memory following a 
lazy loading strategy, i.e., a physical page of the VM instance is loaded only when the corresponding virtual 
page is accessed for the first time, which triggers a page fault, allowing the VMM to install the physical page
by reading it from the snapshot file into a page frame, and updating the page table. 
While being seemingly attractive, the paper points out later, however, that snapshotting incurs non-negligible cost
on page fault handling and disk random access, which we discuss in the following.


