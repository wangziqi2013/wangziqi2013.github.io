---
layout: paper-summary
title:  "System Software for Persistent Memory"
date:   2020-06-23 21:07:00 -0500
categories: paper
paper_title: "System Software for Persistent Memory"
paper_link: https://dl.acm.org/doi/10.1145/2592798.2592814
paper_keyword: NVM; PMFS
paper_year: EuroSys 2014
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper introduces PMFS, a file system designed and optimized for NVM. Unlike previous NVM file system papers in which
a concrete problem with other designs are identified and then solved, this paper is closer to a design document covering
the high-level designs while explaining design motivations. The paper begins by identifying three different ways of extending
existing file system paradigm to work with NVM. The first is to abandon file system totally, and shift the responsibility
of resource management to the OS's virtual memory manager. The second way is to only change the block layer interface and
use the NVM as conventional block device with lower latency and higher throughput. The last is to partially abandon the 
block layer abstraction and the disk buffer cache, reducing software stack and data movement overhead, but maintain the
conventional file system interface and semantics.

The paper chose the last for three reasons. First, legacy applications relying on file system interface still work on
PMFS with reduced latency and increased bandwidth, which eases software migration. Second, by getting rid of the software 
block layer, PMFS does not suffer from abstraction and data movement overhead, since data exchange happens directly
between the application and NVM storage. The last reason is that applications can also benefit from more powerful interface
such as mmap(), which directly maps a range of virtual addresses to the NVM physical address, enabling the application 
to directly read from and write into NVM.

The paper then proceeds to discuss three different techniques for forcing write ordering on the current architecture.
The first uses non-cachable pages, which are set via page table attribute bits. Loads and stores to these pages will
bypass the cache. The problem, however, is that non-cacheable accesses incurs performance overheads for all memory
operations, while only a subset of them needs to see a certain memory ordering. Besides, all memory operations will
occur on the system bus if caching is disabled, which has a limited bandwidth. Frequent accesses to the NVM device
not only saturates NVM bandwidth quickly, but also impacts performance of other unrelated applications.
The second option is non-temporal stores, which are special store instructions whose data is not expected to be accessed
in the near future, thus bypassing the cache hierarchy. Due to the extensive usage of non-temporal stores in streaming 
workloads, the processor is also equipped with a special write combining buffer, which tries to combine multiple smaller 
stores into a full cache line as much as possible to reduce write amplification of the store. Using non-temporal
stores, however, may imply unexpected results or complicated interactions with cached loads. The implementation
should then be very careful on placing memory barriers to avoid loading stale data or severe performance loss.
The last option is to use a persistence barrier consisting of cache line flush instructions and a store fence. The 
persistence barrier is compatible with most other instructions. PMFS chooses persistence barrier to enforce 
write ordering due to its simplicity and efficiency. In order to issue flush instructions, the paper assumes that software
should track dirty data in cache line granularity, and only flushes dirty data with a barrier. It is not discussed
how dirty data tracking can be implemented, though.
The paper also mentions hardware accelerated persistence such as epoch persistence. This approach, as pointed out
by the paper, requires extensive hardware modification, such as cache line tagging and customized eviction algorithms.
It is unlikely that future hardware with adopt this due to its complexity.