---
layout: paper-summary
title:  "Bridging the Performance Gap for Copy-based Garbage Collectors atop Non-Volatile Memory"
date:   2023-01-31 03:28:00 -0500
categories: paper
paper_title: "Bridging the Performance Gap for Copy-based Garbage Collectors atop Non-Volatile Memory"
paper_link: https://dl.acm.org/doi/10.1145/3447786.3456246
paper_keyword: Java; Garbage Collection; NVM
paper_year: EuroSys 2021
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents an improved Java Garbage Collection (GC) algorithm optimized for Byte-Addressable Non-Volatile
Memory (NVM). The paper is motivated by the performance degradation of Java's default GC algorithm when deployed
on NVM due to NVM's low write bandwidth, especially under random I/O. The proposed algorithm transforms the read/write
pattern of GC, which contains excessive small writes and has bad locality, into large, sequential writes by
leveraging DRAM as an intermediate buffer. Consequently, higher performance can be achieved with the improved algorithm
as GC utilizes NVM more efficiently and hence constitute fewer cycles on the execution critical path.

The paper aims at optimizing the GC algorithm on Java virtual machine which provides a managed execution 
environment where heap allocations need not be explicitly freed by the programmer. Rather, the virtual machine
maintains internal tracking data structures such that objects living on the heap can be automatically deallocated
when they are no longer referenced by the execution context, hence becoming "dead".
While the GC algorithm, called Garbage-First GC or "G1GC", consists of several smaller subroutines to deal with
different cases, the paper focuses on the most common and frequently invoked type of routine which we describe
as follows. The Java heap allocator places objects (regardless of their sizes, unlike a general heap allocator) 
on memory blocks called regions using the simple bump pointer allocation strategy and objects are never explicitly
freed. The JVM maintains two different types of regions, one is the young spaces which contain objects that are 
allocated more recently and have not gone through any GC process. The other type of region is called the old space
which contains regions that have been GC'ed at least once. For every young region, the GC algorithm keeps track of 
a set of objects in the old space, called the remembered set, that holds references to objects in the young space.

During garbage collection, the algorithm first allocates a new region in the old space as the destination of the
object copy. Then for every young region, the algorithm traverses its remembered set and copies all objects that
are still referenced by an old space object to the newly allocated region. For each object being copied in this
process, the algorithm also adds the other young objects that it references, hence recursively marking live objects 
in the young space such that they will eventually be copied. The marking process is implemented as graph 
Depth-First Search (DFS) using a LIFO stack (for better locality). Additionally, after an object is copied from
the young space to the old space, the reference pointer that point to the object is updated to point to the new 
object. Besides, the pointer to the object in the destination is also stored in the header of the source object.
This header pointer serves as a trampoline such that if the same object is visited from another
reference in the future, the algorithm can figure out that the object has already been GC'ed, and then correctly update
the references.

To identify the performance traits of the above GC process on NVM, the paper conducts experiments that compares 
the execution latency and memory bandwidth consumption between GC running on DRAM and NVM.
The paper made three critical observations. First, a higher percentage of execution cycles are spent on GC when
running on NVM. In particular, NVM-based GC suffers a greater slowdown than the rest of the execution, which is 
also larger than the average slowdown over all benchmarks. This phenomenon suggests that GC has become a bigger 
bottleneck on NVM than on DRAM.
Second, when testing for bandwidth consumption over an execution process involving both GC and non-GC code, the 
paper observes that the bandwidth consumption drops when GC is triggered, indicating that GC saturates the NVM device
somewhere other than bandwidth. By contrast, when executing on DRAM, the bandwidth consumption increases during GC
as DRAM devices are not saturated. This phenomenon is explained by the large quantity of small and random I/O requests
generated by GC, which can easily saturate NVM's operation bandwidth.
Lastly, when the number of threads increases beyond eight, the bandwidth consumption on NVM stops scaling, while
on DRAM it keeps scaling until a higher number of threads. This result demonstrates from a different perspective that
GC will saturate NVM's bandwidth even at a low thread count, and therefore is not scalable.
