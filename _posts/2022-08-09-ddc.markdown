---
layout: paper-summary
title:  "Dual Dictionary Compression for the Last Level Cache"
date:   2022-08-09 18:28:00 -0500
categories: paper
paper_title: "Dual Dictionary Compression for the Last Level Cache"
paper_link: https://dl.acm.org/doi/10.1145/2540708.2540735
paper_keyword: Cache Compression; Dictionary Compression
paper_year: ICCD 2017
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Dual Dictionary Compression (DDC), a compressed cache and main memory architecture that
leverages two separate dictionaries for compressing the cache and memory data, respectively.
The paper is motivated by the memory bandwidth saving benefit of transferring compressed blocks on the bus,
which most previous proposals on cache compression do not focus on.
The design aims at maintaining data in compressed form both in the cache and in the main memory for maximum
compression benefit.
Data is compressed using different dictionaries located at the LLC and the main memory level, respectively, and 
compressed data is transferred on the bus in compressed form using a technique called dictionary index swap.

The paper begins by noticing that existing cache compression designs only focus on expanding the logical capacity of
the cache itself, and the reduction of memory traffic as a result of lowered miss rates. 
Meanwhile, little attention is given to the bandwidth saving aspect of compression via transferring data blocks in
compressed form, which also effectively reduces memory traffic, because less number of bits are transferred for
compressed blocks.

