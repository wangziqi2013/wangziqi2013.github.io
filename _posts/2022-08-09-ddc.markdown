---
layout: paper-summary
title:  "Dual Dictionary Compression for the Last Level Cache"
date:   2022-08-09 18:28:00 -0500
categories: paper
paper_title: "Dual Dictionary Compression for the Last Level Cache"
paper_link: https://dl.acm.org/doi/10.1145/2540708.2540735
paper_keyword: Cache Compression; Dictionary Compression
paper_year: ICCD 2017
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Dual Dictionary Compression (DDC), a compressed cache and main memory architecture that
leverages two separate dictionaries for compressing the cache and memory data, respectively.
The paper is motivated by the memory bandwidth saving benefit of transferring compressed blocks on the bus,
which most previous proposals on cache compression do not focus on.
The design aims at maintaining data in compressed form both in the cache and in the main memory for maximum
compression benefit.
Data is compressed using different dictionaries located at the LLC and the main memory level, respectively, and 
compressed data is transferred on the bus in compressed form using a technique called dictionary index swap.

The paper begins by noticing that existing cache compression designs only focus on expanding the logical capacity of
the cache itself, and the reduction of memory traffic as a result of lowered miss rates. 
Meanwhile, little attention is given to the bandwidth saving aspect of compression via transferring data blocks in
compressed form, which also effectively reduces memory traffic, because less number of bits are transferred for
compressed blocks.
In addition, cache compression may also cooperate with main memory compression to further expand the 
logical capacity of main memory storage.
The latter requires extra metadata and memory controller logic, and this paper solely focuses on leveraging the 
first opportunity, i.e., reducing memory bandwidth consumption by transferring blocks in compressed form.

DDC is based on explicit dictionary compression, in which an explicit dictionary is maintained to serve as the 
reference for compression. The explicit dictionary can either be statically or dynamically generated, and 
dictionary entries are supposed to be frequently occurring values in the working set.
The dictionary is stored in a associative lookup structure (e.g., a CAM), with each entry containing the value
and other metadata, such as the valid bit, the decay bit (which we describe later), and so on.
Compression works by comparing the value from the input stream with dictionary entries, and the value matches an
entry, or can be compressed with a small delta with the entry, then the value is stored as the index to the entry,
plus the optional delta value. Compression is achieved in this case by encoding the index and the small delta value
in less number of bits than an uncompressed value.
The algorithm also performs what the paper calls "static compression", which is essentially pattern-based compression
that matches the input value with common patterns. The value is compressed without any dictionary entry, but instead,
with the pattern ID and other necessary information for restoring the original value. 
Decompression for dictionary-compressed values require the same dictionary, and restores the original value 
by adding the dictionary entry's value with the small delta (if any).
Statically compressed values are restored based on the pattern ID and the information generated during compression.

Note that although the paper claims that they adapted C-PACK, the actual dictionary algorithm presented in the 
paper differs from C-PACK by using an explicit dictionary, rather than implicitly generated, per-block dictionary
as is the case with the original C-PACK.
On the other hand, the explicit dictionary algorithm presented in this paper resembles C-PACK by adopting both
dictionary compression and pattern-based compression, which generally leverages a wider range of value redundancy.

With an explicit dictionary compression algorithm, the paper identifies the main challenge as keeping the 
dictionary consistent for both in-cache and in-memory blocks.

