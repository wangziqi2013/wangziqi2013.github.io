---
layout: paper-summary
title:  "Scalable Logging Through Emerging Non-Volatile Memory"
date:   2019-02-01 17:27:00 -0500
categories: paper
paper_title: "Scalable Logging Through Emerging Non-Volatile Memory"
paper_link: https://dl.acm.org/citation.cfm?id=2732960
paper_keyword: ARIES; Recovery; Logging; NVM
paper_year: VLDB 2014
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---  

This paper proposes distributed logging, a mechanism that extends ARIES-stype database recovery algorithm
to provide support for scalable logging on multicore. The traditional ARIES algorithm provides a general-purpose, efficient,
and versatile solution for database recovery, which requires only simple data structures and a few extension to an existing
database system. The core of ARIES is a software maintained sequential log, in which log entries of different types
are stored. Log entries are identified by their unique Log Sequence Number (LSN), which corresponds to their logical 
offsets into the log. Although not explicitly mentioned in the paper, in order to append an entry into the log, the 
transaction should acquire both a page latch and a log latch. The former is to ensure that two different transactions
modifying the same page should append their entries in the same order as they conduct the modification. The latter is to
protect the integrity and consistency of the log itself, preventing concurrent modifications corrupting the log data 
structure. 

To reduce I/O overhead, log entries are only written back to the disk in large batch, which must follow the Write-Ahead
Logging (WAL) property. The WAL property defines two types of write ordering. First, when a dirty page is to be written
back to the disk, the log entry that wrote the page must be written back before the page. ARIES enforces this write 
ordering by forcing a log flushing till the LSN which is the most recent entry that modifies the page. The second write 
ordering is that before a transaction can write its commit record, all log entries generated by that transaction must be 
written back to the disk. ARIES enforces all log entries up to the transaction's most recent to be written back in this case.
To further amortize the overhead of frequently scheduling disk I/O, the transaction manager could choose to group commit
a batch of transactions rather than committing them individually. Instead of writing the log entries for a transaction
immediately when a transaction finishes execution, the transaction manager puts the completing transaction into a t
commit pending queue. Transactions in the pending queue are only committed if the queue is full, or there has not been
any commit for a while. With group commit, only one large I/O operation is scheduled for all transactions in the pending 
queue, which amortizes the overhead of I/O over multiple committing transactions at the cost of longer commit latency. 

Being able to write into a centralized log object in the DRAM simplifies logging logic, because all log entries have 
a unique LSN, and their logical ordering is implied by the LSN. During recovery, ARIES does not redo a log entry, 
if the log LSN is smaller than or equal to the last modified LSN recorded on the page. On the other hand, however,
keeping a centralized object in the memory which is accessed using a lock can easily become a performance bottleneck
on today's multicore architecture. The situation is only aggravated as the number of cores in the system increases
and with multi-node memory architecture such as NUMA. 

To overcome the inherent shortcoming of centralized logging, this paper proposes distributed logging which allows multiple
log objects to be maintained in the main memory following some partitioning rules. In addition, recovery can be made more 
efficient using multiple log objects by adopting concurrent recovery algorithms. The paper also takes advantage of the fact 
that with the advent of Non-Volatile Memory (NVM), even random I/O from or into the NVM will be much faster than sequential 
I/O with disks. This observation justifies multiple log objects, which will incur non-sequential I/O operation to the NVM
address space. At last, the paper also pointed out that current hardware is insufficient to implement efficient durability 
given that data accesses are cached by the processor. Future processor designs may incorporate the idea of backing the 
entire cache hierarchy with battery or super capacitors to extend persistence domain to the cache. Durability can then be
made very efficient using only ordiary memory instructions and fences. 

We next describe designs of distributed logging and focus on the chanllenges it poses to classical ARIES-style logging 
and recovery. In distributed logging, log entries can be partitioned using two keys: Page ID and Transaction ID. In the 
former case, the log manager operates like a hash table: whenever a transaction intends to append a new log entry, it 
hashes the page ID into a bucket, and then append the entry to the end of the log in the corresponding bucket. Since 
Page ID space does not overlap, buckets can be locked and maintained independent of each other, improving parallelism. 
In the other option, transaction oriented logging, every transaction have a dedicated log buffer. Transactions append only
to their local buffer, and does not communicate with each other. 

Due to the nature of redo and undo, both logging schemes are hard to deal with under certain circumstances. For page 
oriented logging, redo is simple, because the ordering of log entries for a single page still observes the logical
ordering of modifications that happen on the page. Undo, however, is hard, because undo is intrinsically transaction
oriented, which requires the recovery manager to traverse the linked list of log entries written by the loser transaction
in reverse chronilogical order. With proper notion of inter-log undo, it would be very inefficient. For transaction
oriented logging, redo is non-straightforward, because log records are only ordered with each other within a transaction.
In the classical ARIES scheme there is no notion of inter-transaction dependency, as all operations are implicitly 
serialized by the LSN. Finding an encoding scheme which describes the data dependency between transactions is hence 
the essence of solving the issue with transaction oriented logging. If such an encoding scheme can be found, the recovery 
manager then follows the dependency during redo to ensure correct ordering for log replay. Undo with transaction oriented
logging is trivial, because each log buffer only contains log entries generated by a single transaction. In the following
paragraphs we describe solutions proposed by the paper regarding both logging schemes.

To solve the easier problem of not being able to undo transactions efficiently with page-oriented logging, the paper 
proposes that each transaction can have a private DRAM-only log buffer. The log buffer must reside in the DRAM all the
time, and does not participate in the WAL. Every time a transaction appends an entry to the distributed page log, it 
must also write the same entry into its private log buffer. On partial or full rollbacks, the private log buffer is used
to undo previously generated log entries of the transaction. The log buffer is discarded on successful commit, and 
can always be reconstructed from the redo WAL entries, which are already written back to the NVM before commit.
During recovery, the recovery manager runs the classical ARIES algorithm. In the redo pass, the recovery manager 
reconstructs the private log buffer as it redoes modifications to pages. Note that in this case, even if the log record LSN
is smaller than or equal to the PageLSN which indicates that the page already contains the update, the log entry must
still be inserted into the private log buffer. At the end of the redo pass, the log buffer is recovered to the state 
right before the crash, and in the following undo pass, it can be used to roll back modifications of loser transactions 
just as in ARIES. 

Determining the correct order of modifications from different trasactions is more difficult in transaction oriented logging, 
because two ordering constraints must be satisified. First, log entries from the same transaction must be ordered according 
to the program order that these modifications are carried out. Second, log entries on the same page from different transactions
must also be ordered based on the logical ordering of modifications (e.g. if serializability is to be implemented, then the 
logical ordering the modifications is consistent with the logical ordering of transactions). Since log records are scattered
between different transaction's log objects, it would be difficult to encode LSNs in a global consistent manner without hampering
scalability. To solve the global ordering problem, the paper proposes using Lamport logical clock. With logical clock, every
entity in the system has a local clock, which represents the last time it synchronizes with another entity. Entities synchronize 
via sending messages to each other. The local clock is included in the message, and on receiving such a message, the 
receiver must set its local clock to the maximum of the local clock and the value included in the message. This way,
it is guaranteed that arbitrarily many events (in the form of message passing) can be serialized based on the value 
included in the message. If the value of event A is smaller than that of event B, then it is potentially possible that
event A happens before event B. 