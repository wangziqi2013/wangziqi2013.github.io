---
layout: paper-summary
title:  "IMP: Indirect Memory Prefetcher"
date:   2019-01-07 00:52:00 -0500
categories: paper
paper_title: "IMP: Indirect Memory Prefetcher"
paper_link: https://dl.acm.org/citation.cfm?id=2830807
paper_keyword: Cache; Prefetching
paper_year: MICRO 2015
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes Indirect Memory Prefetcher (IMP) to address the common problem of slow indirect memory operations. 
Indirect memory operations are of the form A\[B\[i\]\], where B\[i\] is an array of indices that are read and used 
with a regular pattern, and A\[i\] stores data which are often accessed without a pattern. This scenario is common in 
compressed representation of sparse data structures. In practice, both arrays are pre-computed at the beginning of
an iteration, and remain unchanged during the iteration, because the compact form is difficult to modify. Access patterns 
like this suffer low spatial locality especially when the size of A is large, because it is unclear whether two adjacent 
elements in A will be physically stored close to each other. In addition, a classical stream prefetcher which detects 
regular access patterns as access streams also cannot help in this case, because the contents of B\[i\] usually do not result 
in a regular pattern of accessing A even if B itself is accessed regularly (e.g. using linear scans), making it harder for 
hardware prefetcher to work. 

In order to also efficiently prefetch array A, IMP takes advantage of the following observation: The address of 
A\[B\[i\]\] to prefetch is computed using a simple formula: &A\[B\[i\]\] == sizeof(A\[0\]) * B\[i\] + &A\[0\]. 
Given that the size of elements in array A is a compile time constant, and the base address of A is fixed at the beginning
of the iteration, this equation only contains one variable, B\[i\], and two unknown constants, sizeof(A\[0\]) and &A\[0\].
By using a stream prefetcher we can easily prefetch the content of array B since it is accessed regularly. By
monitoring cache miss events, it is likely that we can also detect the target address (if there is no cache miss for multiple
accesses, then it is an indication that the locality of accesses is good, and prefetching is unnecessary) that should have 
been prefetched if the prefetcher works perfectly. The prefetching problem then essentially boils down to the following question: 
Given a line equation y = ax + b, where x is B\[i\] and y is &A\[B\[i\]\], how many data points do we need to fix parameters
a and b? The answer is two, and after computing a and b, for further accesses of A\[B\[i\]\], we can then use the 
value of b\[i + 1\] as an input to generate the next address to prefetch.

One simplification is made in the paper to make the hardware implementation more practical: for performance critical
part of the program, most compilers will align data items accessed in an array. It is hence very likely that sizeof(A\[0\]) 
can only have a limited set of values, e.g. 4 (C int type or float), 8 (C long type or double), 16 (vector type), or 1/8 (bit field
where B\[i\] is the offset of bits. Converted to offset of bytes by division it with 8). Tha hardware does not need to perform
multiplication or division using an expensive multiplier and divisor, because they can be achieved easily using left
and right shifts on bit level. 

The architecture of IMP is described as follows. IMP is based on existing designs of stream prefetchers. In these prefetchers,
stream information is stored in a small associative buffer called the stream table. The stream table maintains states that
are necessary to detect memory streaming access pattern. 