---
layout: paper-summary
title:  "Rebooting Virtual Memory with Midgard"
date:   2021-06-25 00:10:00 -0500
categories: paper
paper_title: "Rebooting Virtual Memory with Midgard"
paper_link: http://cs.yale.edu/homes/abhishek/sidgupta-isca21.pdf
paper_keyword: Virtual Memory; Segmentation; Midgard
paper_year: 
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Highlights:**

1. This paper absorbs several observations: (1) Large mapping granularity helps to reduce translation overhead;
   (2) Smaller granularity is good for resource management; (3) Virtual address caches do not need translation,
   but due to lack of inter-process isolation, they suffer from synonym and homonym problems.
   The paper combines these three to only use their advantages while dodging the disadvantages: (1) Large granularity
   mapping is done between VA and MA at processor side to reduce translation overhead; (2) The cache hierarchy uses
   MA which is similar to VA caches, but processes are properly isolated; 
   (3) Physical pages are still managed in small granularity by mapping MA to PA when data is transferred between the
   cache hierarchy and the main memory.

2. Decouples isolation from physical memory management. In conventional virtual memory systems, isolation is performed
   in much larger granularity, e.g., code and data segments are typically either fully shared or not shared between 
   processes. Similar argument is also true for access permissions. In one word: It is wasteful to maintain fine-grained
   info at page granularity.
   On the other hand, maintaining per-4KB page metadata is good for resource management, because it allows flexible 
   address mapping and reduces segmentation.
   This two goals should be decoupled in future virtual memory systems.

3. Addresses make no sense in a cache hierarchy. They are simply symbols for distinguishing different blocks.
   As long as these symbols do not collide (i.e., different blocks do not use the same tag), and that both upper
   level (CPU / VA space) and lower level (main memory / PA space) understand the symbol (i.e., have a way of 
   translating them from VA/to PA), the cache will work.
   
4. In fact, the cache may just have its own address space, according to the point above. 
   Midgard can be generalized by giving the cache hierarchy its own address space, which is neither VA nor PA.
   The extra address space can be designed to be semantically rich (e.g., contains type information, allows certain
   hints from the application, etc.). As long as mapping from VA to this special address space and from this
   space to PA are easy to perform, this is always doable.

**Comments:**

1. How is CoW performed in Midgard? When you fork a process, you copy its Midgard mapping table, essentially
   sharing code and data segments between the parent and child processes, and the permission of the child table
   changes to read-only.
   So what happens if a writes happens on the child?
   Do you just copy the entire segment (expensive)? Or you break down the segment (nullifies Midgard) in the
   child process such that one 4KB of them can be readable-writable?
   

This paper proposes Midgard, a novel virtual memory framework for reduced translation overhead on the critical path.
The paper is motived by the fact that memory translation has become a major performance bottleneck on today's multicore
platform, where several TBs of memory on a single node is not uncommon.
Maintaining large working sets in the main memory requires proportionally more translation entries, as modern hardware 
still performs address translation in a fixed granularity.
Unfortunately, the hardware structure for caching these entries for fast access, i.e., TLBs, cannot scale with the 
growth of working set size for various reasons. As a result, when the working set size exceeds the maximum coverage 
of the TLB, the MMU must frequently perform page walks to bring new translation entries into the TLB.
This is likely on the critical path, since memory instructions will remain in the ROB and/or various queues until
their addresses are resolved, which can potentially cause structural hazard to the following instructions. 
The paper also points out that, since TLBs are essentially caches to main memory data (PTEs), large TLBs also complicate
the coherence protocol, namely, the TLB shootdown protocol.
On modern architectures, as memory accesses become heterogeneous in terms of latency and throughput, 
it is a common optimization to migrate pages between different memory modules. This process requires updating the 
translation information both in the main memory and cached by the TLB, which frequently involves TLB shootdowns.
Large TLBs can make the performance worse due to the shootdown overhead.

The paper noted that previous proposals attempted to solve this issue from different directions. 
Virtual hierarchy uses virtual addresses, instead of physical addresses, to avoid paying the cost of translation
on the critical path. Addresses are only translated when accesses are bring made external to the virtual hierarchy.
This approach, however, suffers from synonym and homonym, which are caused by one physical address (PA) being mapped
by multiple virtual addresses (VA) (i.e., page sharing between address spaces), and one VA being mapped to different 
PAs, respectively.

Other attempts have also been made with single address space OS and huge pages. The former requires significant
changes to today's programming paradigm and OS interface, which is unrealistic. The latter, despite the fact that
it is quite mature and has been already deployed, still causes issues such as fragmentation and alignment problems.

Midgard, on the other hand, decouples semantics level process isolation with physical level resource management,
which are two independent functionalities coupled together in today's existing virtual memory system. 
There are several design highlights.
First, it adds an extra Midgard address space (MA space) between the VA space and the PA space.
Processes still have their own VA spaces. The difference is that, instead of performing page-level mapping from VA
directly to PA, which is enforced to simplify physical page management, process structures are first mapped from VA
to the MA in a segmented manner. To elaborate: modern OSes organize the address space of a process into several 
segments, i.e., the code segment, data segment, and shared libraries. Each segment is a logical entity in which every
address shares the same access permission information, and each segment occupy a consecutive range of address in the VA.
Segments from different processes are mapped to different segments in the MA space with one single mapping 
(shared segments in different processes such as the OS image or libraries are mapped to the same MA segment).
Since the number of segments remains relatively constant, which is typically not proportional to the number of pages in 
the working set, and that segments can be large, the number of translation entries from VA to MA space remains low,
e.g., several hundreds of entries can be sufficient.
Addresses within segments are mapped linearly from VA to MA space, and hence do not need any extra mapping entry.

Second, the cache hierarchy uses translated MA as tags, such that VA in programs only need to be 
translated to MA, before they can be used to access the cache hierarchy. This is similar to the virtual cache hierarchy
setup, but it gets rid of homonym and synonym, since (1) Process isolation is still enforced since non-sharing segments
are still mapped to different MA segments; and (2) Pages/segments shared by different processes have the same MA,
and therefore, could only have one copy in the hierarchy, eliminating the possibility of synonym.
