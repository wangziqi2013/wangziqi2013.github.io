---
layout: paper-summary
title:  "MOD: Minimally Ordered Durable Datastructures for Persistent Memory"
date:   2020-08-29 06:04:00 -0500
categories: paper
paper_title: "MOD: Minimally Ordered Durable Datastructures for Persistent Memory"
paper_link: https://dl.acm.org/doi/10.1145/3373376.3378472
paper_keyword: NVM; MOD; Data Structure; Shadow Paging
paper_year: ASPLOS 2020
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Lowlight:**

1. Not really a low light, but I am just thinking, is it possible to compose logging-based operations by passing a flag
   to disable log commit at the end of the operation (i.e. does not write undo commit record), and continue with the 
   next operation which is supposed to be atomic with the first one. This can continue until we finished all operations,
   at which time a commit record can be written. 
   Is there any difficulty implementing this, instead of shadow paging-based composition?

This paper introduces Minimally Ordered Durable Data Structures (MOD), a software library of persistent data structures 
that features fast persistence and composibility. The paper identifies that conventional logging-based persistence
data structures that implement failure-atomicity have two issues. The first is excessive write orderings, which is caused
by logging. For example, in undo logging, each log entry write must be persisted before the cache line is updated
in-place to avoid dirty data being accidentally evicted back, polluting the consistent image before the log entry does.
This limits the parallelism of cache line eviction on a single core to one, since the next eviction cannot start before
the current one completes, while the actual hardware is capable of parallel eviction. 
The second issue is usability. Logging-based data structure operations are hard to compose, due to the fact that the undo 
log must be committed by writing a end-of-transaction mark at the end of the operation, limiting the scope of the 
failure-atomic region. 

This paper also makes two important observations on the degree of parallelism on NVM flushing. The experiments involves
issuing flush instructions to a certain number of randomly chosen dirty cache lines, and then issue a memory fence.
Latency of the fence is measured as the overhead of write barriers of a certain write size.
The first observation is that no matter how many flushes are issued in parallel, it seems that at most 16 of them can
be overlapped without significantly increasing latency, but still at a lower cost. 
This might be an indication that the internal eviction buffer or MSHR for flushes have a maximum capacity of 16. When 
parallelism exceeds this value, the flush instruction will stall the pipeline until one of them is released.
The second observation is that approximately 82% of all flushes can be parallel, while 18% of them are serial. This 
ratio remains pretty much consistent as the parallelism of experiments change, indicating that the performance of 
flushes are mainly determined by the 18% non-parallel writes to the NVM.
Personally, I would believe that this is caused by random addresses hitting the same bank or persistent buffer within 
the NVM device, serializing accesses to these banks or buffers.
Overall, these experiments confirm that the logging-based persistence approaches under-utilize cache line flush and NVM 
parallelism, resulting in sub-optimal performance.
