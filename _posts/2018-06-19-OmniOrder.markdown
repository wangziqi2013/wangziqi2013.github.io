---
layout: paper-summary
title:  "OmniOrder: Directory-Based Conflict Serialization of Transactions"
date:   2018-06-19 22:55:00 -0500
categories: paper
paper_title: "OmniOrder: Directory-Based Conflict Serialization of Transactions"
paper_link: https://ieeexplore.ieee.org/document/6853223/
paper_keyword: HTM; OmniOrder; Sequential Consistency
paper_year: ISCA 2014
rw_set: On-chip buffer
htm_cd: Eager
htm_cr: Eager
version_mgmt: Eager (Uncommitted Read)
---

Conflict-based Hardware Transactional Memory (HTM) suffers from high abort rates when conflicts are frequent.
This is caused by the simple conflict detection mechanism which treats any cache coherence message that hits 
transactional cache lines as potential sources of violation. The only exception to this rule is bus read shared 
request on shared or exclusive lines, as reader processor cannot conflict with other readers. Processors 
will abort and restart if a conflict is detected, discarding any speculative states from its private cache, 
because there is zero information for tracking how the cache line will be used by another processor. This 
property is sub-optimal, because not all dependencies imply violations at the end of the execution.

This paper proposes OmniOrder, an HTM extension on existing commercial HTM such as Intel TSX to support more 
efficient dependency reasoning. Instead of keeping zero information about global usage of a cache line, processors 
are extended with a few structures that can track the modification history as well as dependencies of 
speculatively modified cache lines. One of the highlights in the design of OmniOrder is its native support for 
unmodified directory-based cache coherence protocol. This feature is crucial for a practical HTM design, for two
reasons. First, directory based protocol is a must in today's high performance architecture. Inability to 
support directory based protocol is a huge deficiency. In contrast, some HTM designs require broadcast 
cache coherence protocol, which makes the design non-scalable and impossible to port to large scale systems.
Second, unmodified coherence protocol implies only incremental change is needed on existing microarchitecture.
Designing and verifying a correct coherence protocol is difficult. What makes it worse is that the actual 
number of state in the state machine is far more than the steady states. Transient states that handle
race conditions must be added to ensure multiple operations can be performed in parallel. All these factors 
discourage the invention of a new coherence protocol. In the next paragraph we cover in detail the hardware 
changes required to implement OmniOrder.

In OmniOrder, each processor is extended with two buffers: One L0 cache to hold speculative values it 
has written on the cache line, and a Speculative Version Buffer (SVB) that holds the global modification
history of cache lines currently in its private cache. Both can be organized in a similar way as caches, 
using a few bits from the address to select cache set, and then use tag comparison to locate the way.
Four bit vectors are also added to each processor. The first two bit vectors are successor vector and predecessor 
vector. They record read/write dependencies into which the current processor participates, as sources and 
destinations, respectively. The third bit vector is called the squash vector, which records the Read-after-Write
dependency in which the processor is the destination. The name of the vector suggests its function: When the 
processor reads uncommitted data from another one, and the latter aborts, the current processor must also
abort to maintain isolation property. The width of the first three vectors is the number of processors 
in the system. The last vector is the directory successor vector. Its width is the number of directories.
A bit is set if speculative data generated by this processor is maintained and tracked by the directory. 
We cover more details about directories acting as "proxies" for processors that have shared their uncommitted
data. L0 and SVB must not be written back to memory, and not visible to non-transactional instructions. 
If an overflow is inevitable, the current transaction must abort. This implies that OmniOrder is not unbounded.

The directory is also enhanced with an SVB and an array of bit vectors. The SVB in the directory should be large
enough to hold all SVB entries from all processors. Each element in the bit vector array stores the successor
of a particular processor. A bit in the vector is set if the corresponding processor is a successor of 
the processor represented by the identity of the bit vector. Similar to the per-processor SVB, if the 
directory SVB overflows, the transaction must abort.

OmniOrder maintains a few invariants. First, speculative data is never stored in ordinary caches. They are always 
stored in L0 and SVB, and is not visible to non-transactional reads. Second, the coherence of SVB implicitly follows 
the coherence of its corresponding cache line. If the cache line exists in multiple caches in Shared state, then
multiple copies of the SVB also exist and they are consistent with each other. Similarly, if a cache line is in M
state, then the SVB entry of the line is also the most up-to-date, and no other copies can ever exist.

On transactional load, a cache coherence request is sent as usual. The paper only assumes MSI baseline protocol, so
exclusive state is not under consideration. If the request hits a local cache line, then data in A0 is read-forward
to the processor. Otherwise, the processor checks SVB entry for uncommitted data. If the request hits a speculative 
and modified line, with uncommitted data in both L0 and SVB, then the source processor first combines the L0 and 
SVB entry, and then writes them back to the directory. The directory stores the combined line in its own SVB, marks 
the requesting processor in responding processor's bit vector as a successor, and provides the requesting processor 
with the SVB entry and line. The responding processor also sets the directory it sends the SVB entry to in the directory 
bit vector. From then on, the directory acts as a proxy for the SVB entry and cache line. 

If the request hits a speculative and shared line, then it must be the case that those shared lines were produced
by one of the processors currently holding the line, and a read operation hit the line in M state. In this case
the directory must already have an SVB entry of the line as a result of the previous read. The directory therefore, 
as expected, provides the line as well as the SVB entry. The directory also marks the requesting processor in the 
last writer's bit vector as a successor. It infers the identity of the last writer using the modification history in SVB.
In either case, the rquesting processor marks the bit of the responding processor in its predecessor vector. If the 
processor reads uncommitted data written by another processor, it also needs to mark the processor in its squash bit
vector. This is necessary to guarantee isolation, as otherwise transactions may use data items that are written by
an aborted transaction.

