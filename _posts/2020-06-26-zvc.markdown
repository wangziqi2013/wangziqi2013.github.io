---
layout: paper-summary
title:  "Zero-Value Cache: Cancelling Load That Returns Zero"
date:   2020-06-26 20:54:00 -0500
categories: paper
paper_title: "Zero-Value Cache: Cancelling Load That Returns Zero"
paper_link: https://ieeexplore.ieee.org/document/5260542
paper_keyword: Cache; Compression; ZVC; Zero Compression
paper_year: PACT 2009
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Highlight:**

1. In a partially inclusive hierarchy as described in this paper, whether or not to probe or bypass the next level
   can be indicated by a bit vector showing whether the block is cached by the next level.

2. 

**Lowlight:**

1. The architecture in this paper seems fragile and prone to commplicated corner cases and/or coherence anomalies.
   For example, what about the cohrence of the CIB vector when L2 loads a new block?
2. Many important details are missing, i.e. in the vertical ZVC-L1d design, what if only part of the word is zero-filled, 
   but the rest are non-zero? The cache controller must perform a second read to fetch the non-zero values.

This paper proposes Zero-Value Cache (ZVC), an L1 cache extension optimized to accelerate access for zero load values. 
The paper begins by claim that latency of loads are part of the biggest factor that contribute to processor slow down
in some workloads. The paper then points out that a non-trivial portion of loads actually only read value zero, which can
easily be optimized out if these loads could be identified. Cancelling out these critical loads that are supposed to
return zero before they reach the memory hierarchy helps improve instruction throughput and overall performance.

We next describe the organization of the ZVC. ZVC is organized as a set-associative cache, with only tag arrays but no
data. Each tag consists of an address tag, a valid bit, a zero bit vector, and a cache indcator bit (CIB) vector.
The address tag stores the block address for which the entry covers. ZVC does not necessarily use the same block
granularity as L1d and the underlying L2 cache. In fact, larger blocks are preferred, in order to reduce the tag overhead 
relative to effective ZVC size. The valid bit serves the same prupose as in a conventional cache. The zero bit vector 
indicates whether the corresponding location contains zero. The granularity of the zero bit can either be byte-level
or word-level, which is a trade-off between space overhead and detection accuracy. The CIB vector is an optimization
that helps to bypass the L2 cache, if the block is known to be not cached by L2, as we will see below.

ZVC is not necessarily inclusive regarding the rest part of the hierarchy, since ZVC can potentially use a larger block
size, which will force lower level cache to use the sector cache design, if inclusion is enforced. 
In an inclusive cache design, adding ZVC to the L1 level or above may incur some significant change on coherence handling, 
since the L2 no longer serves as a coherence filter for ZVC, resulting in a design where all coherence messages are 
forwarded to the ZVC. 
To solve this problem, the paper proposes that a duplicated tag is added to the L2 coherence controller. The duplicated 
tag array is updated whenever a fetch request from the ZVC is received. The protocol that we describe below guarantees 
that the duplicated tag array will remain consistent with the actual ZVC by not inserting the entry on L1 misses. Besides, 
the VIB vector described above also serves as an optmization to the non-inclusive architecture, since it is possible that 
only a subset of the blocks in a ZVC block are stored by lower level caches.

The paper proposes two possible configurations of the ZVC cache. In the first configuration, the cache is added between
the L1d cache and the load-store queue (LSQ), which serves as a zero-value filter to load instructions. The paper 
suggests that, under this configuration, the timing of ZVC accesses is critical, which should be completed in the same 
cycle that the load instruction is dispatched. In this case, the load instruction takes no time to execute, if it hits
the ZVC. Instructions that miss the ZVC may suffer from extra latency for unknown reasons, since the paper does not
elaborate on this part. 

Two types of ZVC misses may happen on a load access. The first type is data miss, which occurs when the tag matches,
but data is non-zero. In this case, a conventional cache access is initiated to the L1, which may possibly also 
access the L2 and the rest of the memory hierarchy. The second type is entry miss, which happens when no tag is matched.
In this case, the request is also forwarded to the cache hierarchy to resolve. The difference between entry miss
and data miss is that, if an entry miss is handled by the L2 or memory, the corresponding entry is also inserted into
the ZVC, with zero bit vector and CIB initialized correspondingly. The reason that CIB is not updated on L1 hits is 
that the duplicated tag array, which serves as the coherence filter as we described above, resides at the L2 level.
The duplicated tag array must be updated in consistent with the ZVC tag array, which only occurs when the L2 processes
the request, but not L1.
When an entry miss is handled by the L2 or memory, a special zero detection logic is activated to derive the zero bit 
vector. The paper did not mention how the CIB is updated if the request hits the L2. But if the request hits memory,
then in addition to fetching the target block to fulfill the L1/L2 fill request, the memory controller is also supposed 
to stream out the larger block cached by ZVC, and runs zero detection logic on the whole block, which is then
cached by the ZVC. In this case, only the target block is set in the CIB vector.
Although this might increase memory bandwidth, since more data is streamed on the system bus, the paper claims that the
impact would be minimum, which is outweighed by the benefit of zero cancellation.
