---
layout: paper-summary
title:  "DaxVM: Stressing the Limits of Memory as a File Interface"
date:   2022-12-10 23:47:00 -0500
categories: paper
paper_title: "DaxVM: Stressing the Limits of Memory as a File Interface"
paper_link: https://ieeexplore.ieee.org/document/9923852/
paper_keyword: Virtual Memory; NVM; mmap
paper_year: MICRO 2022
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Comments:**

1. The pre-populated page table assumes that the NVM storage is always mapped at the same physical address.
This behavior, however, may not be guaranteed especially if the NVM device is installed on a different system
where existing NVM devices are already installed. Besides, it breaks compatibility of the file system as a 
page table generated on x86 system cannot work on ARM. The second issue is easy to solve -- if compatibility
is a concern then the default mmap() behavior is restored.

This paper proposes DaxVM, a virtual memory abstraction that facilitates the user scenarios of direct-mapped NVM.
DaxVM is motivated by the fact that traditional virtual memory interfaces, i.e., mmap() and munmap(), are not 
implemented properly for direct-mapped NVM due to their original purpose of supporting disk-file based mapping 
or anonymous mapping. As a result, applications may suffer issues such as paging overhead, kernel lock contention,
expensive operations on the critical path, and so on. As a solution, the paper proposes changing the implementation
of virtual memory interfaces as well as adding new interfaces in order to optimize system performance for direct-mapped 
NVM.

The paper assumes direct-mapped NVM access, in which the NVM storage is mapped into part of the physical address space.
The NVM-based file system manages NVM storage area and allocates NVM pages to files as in a regular file system.
When a file is to be accessed by user applications, instead of using the traditional file system calls such as 
open(), read() and write(), the file system enables applications to directly map the physical pages of the file 
into the virtual address space of the application via mmap(). The mapped file can then be accessed as a memory object
while the OS handles pages faults as well as the mappings between the virtual and the physical addresses.

While the direct-mapped access model reduces unnecessary data copies, i.e., from the disk to the OS page buffer and 
from the OS page buffer to the user-space buffer (e.g., passed as a parameter to the read() system call), the paper 
still observes several performance issues with the access model. One of the examples is when the applications access
many small files for small amount of data, and each file offset is only accessed once.
In this scenario, the paper suggests that the performance is much worse than that of traditional file interfaces.
The second example is when multiple threads of the same process access the file. The paper reported decreased 
throughput as the thread count increases and concluded that this phenomenon is due to lock contention in the OS kernel. 
Lastly, the paper also experimented with different file sizes. It is shown that when the access pattern leaves the 
address space fragmented, i.e., mapped with many regular 4KB pages, the performance is worse than if the file is 
backed by 2MB huge pages. As a result, 2MB files can yield far better performance as the entire file can be backed by
a single huge page (of course, it only works when the underlying physical pages are also contiguous on the NVM).

The paper then analyzes the cause of the problems and proposed the corresponding solutions. 
First, the paper suggests that paging overhead can cause suboptimal performance, since the existing implementation
of mmap() populates page table entries for the process only lazily, i.e., when the mapped virtual page is accessed
for the first time. Consequently, the application must pay the overhead of a page fault for every virtual page accessed,
which is proportional to the memory footprint of the file access. 
To address this problem, the paper proposes that the file system can pre-populate the page table entries for the file
when physical pages is allocated to the file. The pre-populated page table is stored as file metadata, and it is 
structurally identical to a subtree of the existing page table radix tree (and hence the top-level node must be 
a PUD, PMD or less likely, a PTE). With the pre-populated page table, when a file is opened for access, the 
pre-populated table is directed wired onto the page table of the OS. 
File access permissions are set up at a per-file basis (smaller granularity is disabled) on the top-level page table
tree. This new feature enables O(1) file mapping and page fault handling at the cost of higher overhead for 
MMU page walks (as they must access the page table stored on the NVM).

Secondly, the paper attempts to address the kernel lock contention problem by observing that most file accesses are 
ephemeral, i.e., most files are only accessed for less than 0.25 seconds. One implication is that a small amount 
of virtual pages can satisfy most file mapping requests, as these pages are expected to be recycled shortly when
the files are unmapped. 