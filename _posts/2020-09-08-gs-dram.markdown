---
layout: paper-summary
title:  "Gather-Scatter DRAM: In-DRAM Address Translation to Improve the Spatial Locality of Non-unit Strided Accesses"
date:   2020-09-08 23:56:00 -0500
categories: paper
paper_title: "Gather-Scatter DRAM: In-DRAM Address Translation to Improve the Spatial Locality of Non-unit Strided Accesses"
paper_link: https://dl.acm.org/doi/10.1145/2830772.2830820
paper_keyword: DRAM; GS-DRAM; 
paper_year: MICRO 2015
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Gather-Scatter DRAM, a novel DRAM architecture that enables fast gather and scatter semantics.
The paper points out that current DRAM interface only supports cache line granularity access, which causes difficulties
when accessing data in a strided pattern. This prevents several common patterns from being implemented efficiently.
For example, in matrix manipulating code, accessing multiple matrix elements on the same column often requires strided 
reads where the stride length is the size of a row, if the matrix is stored in row-major order where elements in the 
same row are stored. Second, in HTAP database applications, tuples can be accessed either transactionally,
where only a few tuple is touched, or analytically, where certain fields of a large set of tuples are scanned. In a row 
store data layout, scanning one field of all tuples also rerquires strided accesses to memory, with the stride being the 
physical size of a tuple. 
The last example is SIMD, which supports data gathering and scattering with special instructions. These instructions,
however, can be inefficient if multiple cache lines need to be fetched from the DRAM.

The paper assumes the following DRAM architecture. The DRAM storage consists of potentially multiple channels,
each supporting several DIMMs. Channels have their own control and data signals. Multiple ranks exist within a channel.
All DRAM devices in a rank share the same command and data path, which operate as a basic unit of access.
This paper assumes that cache lines are always mapped into one rank for the simplicity of discussion, but other address
mappings can also be supported.
Each rank consists of several DRAM chips, and each chip stores part of a cache line. In this paper, it is assumed that
each chip provides 8 bytes of data on an access. The cache line width is determined by the number of chips on a single 
rank. For 64-byte cache lines, eight chips are present, in which chip 0 provides byte 0 - 7, chip 1 provides byte 8 - 15,
chip 7 provides byte 57 - 64, and so on. 



