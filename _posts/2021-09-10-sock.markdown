---
layout: paper-summary
title:  "SOCK: Rapid Task Provisioning with Serverless-Optimized Containers"
date:   2021-09-10 19:39:00 -0500
categories: paper
paper_title: "SOCK: Rapid Task Provisioning with Serverless-Optimized Containers"
paper_link: https://dl.acm.org/doi/10.5555/3277355.3277362
paper_keyword: Microservice; Serverless; OS; Process Template; SOCK
paper_year: USENIX ATC 2018
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents SOCK, a customized container framework for reducing cold start latency of serverless functions.
The paper is motivated by the observation that both language runtime initialization, such as library import, and 
container initialization will incur long startup latency, which are jointly called the "cold start latency".
This paper addresses cold start latency using a series of techniques, including a customized "lean" container that
avoids long latency system calls and relaxes certain isolation requirements not needed for serverless, 
a local cache of commonly used Python libraries, and using fork() to clone already initialized Zygote containers.
The paper also presents a series of performance evaluations of Linux systems calls related to container virtualization, 
as well as various engineering details that have different performance trade-offs.

To reduce container startup time, the paper argues that container implementations for general purposes, such as 
Docker, provides full and the strongest isolation. Serverless functions, however, do not always require all the 
features provides by these containers, since serverless functions are typically small, only perform simple tasks, and
do not use many of the OS features (e.g., static port assignment). 
The paper makes three important observations on container-related system calls, which we discuss in details as follows.

First, it is sufficient to achieve file system virtualization with bind mounting and chroot(). The former is just a 
special form of mount() system call that redirects the access to the destination path to the source path.
It behaves like a mount(), because it still inserts an entry into the mount point table. 
chroot() simply moves the root directory "/" to a given path given in the argument.
On the contrary, file systems designed for sharing a static image across container instances while allowing each 
instance to make its own private changes that are stored in "layers", such as AUFS, incur significant overhead
due to the complexity and copy-on-write.

Second, containerized processes are typically allocated different namespaces, which are private (per-container) name
spaces for various system resource handlers, including PIDs, file system paths, network port numbers, and so on.
By separating the namespaces of containerized processes, each process can only observe its own resource usage, while
different processes could not see each other's resource usage. In other words, it isolates processes in containers
such that each of them would behave as if they were the only process running in the system.
New namespaces can be created by the unshare() system call, which accepts arguments indicating the resource type.
The paper observes that both namespace creation and cleanup incurs non-negligible overhead, and it is especially
bad for a few particular resource types, such as IPC and network ports, mainly because of the global lock and RCU.

Lastly, containerized processes also need to be allocated control groups, or cgroups, for managing CPU, memory, and I/O
resources. The standard procedure using cgroups within containers would be to create a new cgroup for every process,
add the process into the cgroup, and on program exit, remove the process from the cgroup, and destroy the cgroup itself.
The paper observes, however, that the first and last step are unnecessary, as cgroups can be easily cached in a pool.
It is also observed that caching cgroups is 2 times faster than creating and destroying cgroups.
