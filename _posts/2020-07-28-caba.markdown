---
layout: paper-summary
title:  "A Case for Core-Assisted Bottleneck Acceleration in GPUs: Enabling Flexible Data Compression with Assist Warps"
date:   2020-07-28 05:23:00 -0500
categories: paper
paper_title: "A Case for Core-Assisted Bottleneck Acceleration in GPUs: Enabling Flexible Data Compression with Assist Warps"
paper_link: https://dl.acm.org/doi/10.1145/2749469.2750399
paper_keyword: Compression; GPU; BDI; CABA
paper_year: ISCA 2015
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Note: I am not an expert on GPGPU architecture, and have only read very basic GPGPU architecture literatures. The following
paper summary may be inaccurate and/or incorrect when it involves GPGPU internals. I will strive to clarify as much as I can,
and put the focus on compression rather than GPGPU.**

This paper proposes Core Assisted Bottleneck Acceleration (CABA), an architecture that leverages idle cycles and resources 
on GPGPUs to perform out-of-band tasks for acceleration.
The paper points out that resources on modern GPGPUs are not fully utilized in many cases due to several reasons. 
First, the memory bandwidth and inter-component link bandwidth are often underutilized, due to the speed discrepancy between
execution units and memory modules. As a result, if most threads are stalled on memory instructions, cycles will be 
wasted since no progress can be made during the stalled cycles.
Second, on-chip resources, such as registers and local memory storage, which are allocated statically by compilers
and scheduled dynamically by hardware, are often under utilized as well. This is caused by the hardware scheduler not
being able schedule an entire thread block, which is the unit of scheduling, with partial resources on the current
processing unit. These registers and local storage will be wasted, which can be leveraged to perform background tasks
as prposed in this paper.
