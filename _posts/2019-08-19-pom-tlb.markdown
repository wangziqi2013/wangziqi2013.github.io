---
layout: paper-summary
title:  "Rethinking TLB Designs in Virtualized Environments: A Very Large Part-of-Memory TLB"
date:   2019-08-18 02:43:00 -0500
categories: paper
paper_title: "Rethinking TLB Designs in Virtualized Environments: A Very Large Part-of-Memory TLB"
paper_link: https://ieeexplore.ieee.org/document/8192494
paper_keyword: TLB; POM-TLB; 
paper_year: ISCA 2017
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes Part-of-Memory TLB (POM-TLB), a novel design that adds a L3 TLB to the existing address translation
hierarchy. The paper sets its context under virtualization in which address translation can be a major bottleneck
due to 2-D page table walk and frequent context switch between VMs. To solve this problem, previous researches proposed 
several solutions, including adding a larger L2 TLB to increase the address coverage, using multiple hardware page walkers 
to serve multiple requests from different cores concurrently (processors stall on TLB miss), and adding a cache dedicated 
to intermediate entries of page table walk. These solutions, however, either add non-negligible hardware overheads and 
verification cost, or pose new challenge and trade-offs to address. For example, by making the L2 TLB larger, it is 
expected that more entries can be cached at the same time. This, however, does not necessarily imply better performance, 
since a larger L2 TLB takes longer to access, which is on the critical path of address translation. 

This paper takes a different approach by adding an L3 TLB in the DRAM to reduce the frequency of page walks. This is 
especially beneficial for VMM, since a 2-D page walk can incur 24 cache misses (20 accessing the host page table,
and 4 accessing the guest page table). Reducing the number of page walks, therefore, can save many unnecessary memory
accesses, decreasing both the bandwidth requirement and the latency. 

The L3 TLB is organized as follows. A chunk of memory in the DRAM is statically allocated from the physical address space 
for storing translation entries. Instead of caching intermediate results of page table walk as in the MMU cache proposal, 
POM-TLB only stores TLB entries in the same format as in hardware TLB. A typical TLB entry consists of the VA, the PA,
attribute bits (permissions), and other metadata (such as ASID and virtual machine ID). The paper assumes a 16 byte TLB
entry, which means that a single 64 byte cache line can hold four entries. POM-TLB is organized as a 4-way set-associative 
cache, and also operates similarly. The lower bits of virtual page number is first used as an index to select a set from
the POM-TLB, and then the 64 byte set is read from the DRAM, and then associatively searched attempting to find a matching 
entry. 
