---
layout: paper-summary
title:  "HyComp: A Hybrid Cache Compression Method for Selection of Data-Type-Specific Compression Methods"
date:   2020-07-12 00:54:00 -0500
categories: paper
paper_title: "HyComp: A Hybrid Cache Compression Method for Selection of Data-Type-Specific Compression Methods"
paper_link: https://dl.acm.org/doi/10.1145/2830772.2830823
paper_keyword: Cache; Compression; HyComp; Hybrid Compression
paper_year: MICRO 2015
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes HyComp, a cache compression framework with high compression ratio for all data types using multiple
compression algorithms. The paper is motivated by the observation that most compression algorithms are only capable of
compressing a certain with high compression ratio, while leaving data of incompatible types less compressed, introducing
a huge bias depending on the application and the data types used. The difference between compression capabilities is 
a consequence of different assumptions on sources of redundancy. For example, FPC is based on the assumption that most
redundancies are caused by small integers whose upper bits are all ones or all zeros. It works badly for pointers, which
typically contains addresses of user space data or stack segments. BDI, on the other hand, assumes that redundancies are
introduced by dynamic value locality of nearby values. In most cases, value locality is demonstrated by small integers,
or pointers of similar sized objects allocated from the heap. BDI, on the other hand, cannot process large integers, 
hetrogeneous data types or floating point values very well, since these values differ by a large amount in their numeric
literal. 