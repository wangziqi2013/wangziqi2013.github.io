---
layout: paper-summary
title:  "Crash Consistency in Encrypted Non-Volatile Main Memory Systems"
date:   2019-08-02 04:07:00 -0500
categories: paper
paper_title: "Crash Consistency in Encrypted Non-Volatile Main Memory Systems"
paper_link: https://ieeexplore.ieee.org/document/8327018
paper_keyword: NVM; Encryption; Counter Atomicity
paper_year: HPCA 2018
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper introduces counter-atomicity, a concept used for encrypted NVM environment. The paper builds upon the fact
that data stored in NVM devices should be encrypted, because otherwise data can be accessed even after a system shutdown,
rendering memory protection meaningless. This paper levarages counter mode encryption, in which each cache line is tagged 
with a run-time generated counter. On every modification of the line, a new counter is generated by incrementing a system-wide 
hardware counter. Then a one-time padding is generated as a function of the counter. This process does not require cache 
line data, which is one of the reasons counter mode encryption can be implemented efficiently. After generating the one-time
padding, it is XOR'ed with the content of the line, which concludes the encryption process. Both the counter and the cache 
line are stored in the NVM in two different address spaces. On NVM read operation, both the counter and data are read
from their storage locations. The one-time padding is generated using the same function as in the encryption phase, and then
XOR'ed with the cache line data read from the NVM device. Since two XOR operations with the same mask will cancel out with 
each other, the original data can be recovered this way. Note that without any optimization, this process will increase 
the latency of read operations, because the generation of one-time padding and XOR operation both adds to the critical path.
To reduce latency, the paper suggests that a counter cache can be added, which is accessed on every counter read and update 
operation. Since the counter cache has lower latency, the NVM controller could partially or fully parallelize padding 
generation and data read from NVM, reducing the extra read latency to a minimum. 

One of the chanllenges of using counter mode encryption identified by the paper is about the consistency between cache line
data written back to the NVM and the counter value. On current hardware platform, only the atomicity of one single write 
is guaranteed by the hardware. By contrast, with counter mode encryption, two NVM writes are generated per store: one for 
the regular data write, another for updating the counter map on the NVM. Without proper handling, this may lead to data 
corruption which renders NVM data unreadable. The paper uses the example of inserting a new node at the head of a linked list.
In this example, if the system crashes between the head pointer cache line update and the counter update, then it is impossible
to recover the correct address of the new node, since the counter has not been updated on the NVM, which corrupts the 
pointer value. 

The paper proposes two solutions. One straightford solution is to co-locate the counter and data, such that they constitute 
an atomic pair which can be transferred on the memory bus. To accommodate this change, the width of the memory bus must 
also be extended such that 72 bits (64 + 8) are sent per transfer. This design has two severe problems. First, extending the 
memory bug width is rather impractical on today's architecture, since that implies adding more pins to the memory chip,
which is expensive and sometimes unrealistic. Second, this still does not solve the read latency problem, because in order 
to overlap cache line read and counter read, they must reside in different address spaces. Co-locating both in the 
same unit will waste too much storage.

The second proposal is to add a separate queue for counters in addition to the write queue that already exists on modern
processors. These two queues are backed by residual powers on the NVM chip, which allows them to flush volatile data into 
the NVM in case of a power failure. On eviction of a dirty cache line, the newly generated counter as well as the dirty
line are inserted into the corresponding queue. A "ready" bit is set for both entries if both are available in the queues
(i.e. the paper suggests that when a counter is inserted, the counter queue controller should check cache line queue whether 
the line on the same address has already been inserted. If positive, the "ready" bits in both entries will be set). On 
power failure, only entries with the "ready" bit on will be flushed, and the rest be discarded. Note that the hardware
does not need to insert the counter and dirty cache line at the same moment. In fact, to achieve better performance, the 
design explicitly allows some cache line and counter writes be non-atomic, as we will discuss below. 
