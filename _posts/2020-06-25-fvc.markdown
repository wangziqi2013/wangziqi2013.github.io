---
layout: paper-summary
title:  "Energy-Efficient Frequent Value Data Cache Design"
date:   2020-06-25 23:53:00 -0500
categories: paper
paper_title: "Energy-Efficient Frequent Value Data Cache Design"
paper_link: https://dl.acm.org/doi/10.5555/774861.774883
paper_keyword: Cache; Compression; FVC
paper_year: MICRO 2002
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes frequent value cache (FVC), a cache compression design aiming at reducing energy consumption. The
paper identifies in the beginning that cache systems constitute a significant part of process's energy consumption.
In a conventional cache design, each cache access must read, potentially in parallel, both the tag array and the data array.
FVC seeks to reduce the amount of storage that needs to be activated per access by taking advantage of value locality
that is frequently observed in some workloads. The paper points out that many cache and memory accesses actually only read
a small subset of frequently occurring values, rather than reading random values evenly distributed on the address space.
Several factors may contribute to this observation, such as data initialization, small counter values, or pointers to
commonly used data structures. 

To leverage such a highly localized data usage pattern, FVC adds a dictionary storing high frequency values trained from
a window of execution of the current application. The data bank of the cache is assumed to be stored in 32-bit sub-banks. 
Frequently value detection happens on a 32 bit word boundary. Each 32 bit bank is further divided into two smaller sub-banks,
each being able to be activated independently. Given N frequently used values in the dictionary, the bits to represent a 
dictionary entry takes log2(N) bits, denoted as n. The first sub-bank of the 32-bit word consists of n bits of dictionary 
code, plus an extra bit indicating whether the 32-bit word is compressed as a dictionary entry or not. The second sub-bank 
of the word has (32 - n) bits, which represent the rest of the word if it is not compressed as a frequent value.
Each of the 32-bit words can have two states in the runtime. If the "compressed" bit in the first sub-bank is on, then
the word is considered as compressed, and only the first sub-bank is accessed, reducing the number of bits activated
for each cache access. If, on the other hand, the "compressed" bit is off, meaning all 32 bits are used to represent an
uncompressed value, the second sub-bank will then be accessed one cycle later after the bit check, increasing access latency
by an extra one cycle.

To decode a compressed value represented as n bit code word, the cache controller is equipped with a hardware dictionary
for mapping n bit code words in the first sub-bank to frequently used values. The hardware dictionary is implemented as 
a multiported register file indexed by the code word. The uncompressed value is stored as an entry in the dictionary, 
which will be output when its index appears on one of the input ports. For simplicity of discussion, we assume that the
dictionary is already initialized. After initialization, the contents of the dictionary remain static. No write port
is needed to alter an individual entry, except a special input port for the bulk initialization.
