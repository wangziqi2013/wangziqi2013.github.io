---
layout: paper-summary
title:  "Lightweight Locking for Main Memory Database Systems"
date:   2018-06-29 00:35:00 -0500
categories: paper
paper_title: "Lightweight Locking for Main Memory Database Systems"
paper_link: https://dl.acm.org/citation.cfm?id=2448947
paper_keyword: Very Lighweight Locking; VLL
paper_year: VLDB 2012
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

Classical lock based transactional systems usually suffer from performance bottleneck because of the extra contention
at the lock manager. Locks are essential for old systems using locking protocols such as Two-Phase Locking (2PL) to
produce serializable schedules. In the paper it is claimed that the lock manager is implemented as a centralized 
hash table. Lock entries are hashed into one of the buckets of the table. For each lock entry, lists of transactions 
that are currently holding the lock as well as those who are blocked by the lock are maintained. To protect the consistency
of the lock table data structure itself, each bucket and lock entry has a latch, which is used to serialize insert, delete
and read operations on the lock table. On a main-memory database deployed on multicore platform, such a centralized 
lock manager is not efficient and not scalable. One or more linked list needs to be traversed in order to find the 
lock entry and the identity of threads that are related to the lock, which costs cycles. In addition, the linked structure
is not cache friendly, and is prone to incur high cache miss ratio. In terms of scalability, the hash table itself is 
a centralized structure, managed by lightweight latches. Worker threads need to acquire and release these latches everytime
the lock table is accessed. This may cause frequent cache line invalidation, and hence degrade performance.

This paper aims at solving the lock manager's efficiency and scalability problem by using per-tuple, metadata-less 
very lightweight locks (VLL). As the first step towards optimizing locks, VLL eliminates the lock manager entirely 
from the system. As an alternative, each data item, e.g. rows, tuples, etc, is extended with an extra metadata field 
that is invisible to users, which is used to maintain locks. This removes the need of traversing the linked list
for every lock request and also reduces the probabilities of expensive cache line misses. The next step is to eliminate
the presence of linked structures that record the current holder of the lock as well as threads waiting for the lock.
VLL uses two counters, one to record the number of threads currently holding the lock in shared mode, another to record
the number of threads holding the lock in exclusive mode. Note that even though exclusive mode lock can only be held by 
at most one threads at any moment, we need more than one bit, because as explained later, these two counters actually
count the number of waiting and active threads on the lock mode. In practice, the two counters could be implemented 
using a single 64 bit integer, split evenly. Threads requesting to acquire the lock in either shared or exclusive mode 
perform Compare-and-Swap (CAS) to atomically increment the corresponding counter, and read the value before the increment.
If the value before increment indicates that the lock can be acquired (i.e. no exclusive holder for shared request, and no
lock holder for exclusive request), then the thread proceeds without blocking. Otherwise, the thread blocks on the lock.

