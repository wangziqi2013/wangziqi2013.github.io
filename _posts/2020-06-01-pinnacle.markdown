---
layout: paper-summary
title:  "Pinnacle: IBM MXT in a Memory Controller Chip"
date:   2020-06-01 23:01:00 -0500
categories: paper
paper_title: "Pinnacle: IBM MXT in a Memory Controller Chip"
paper_link: https://ieeexplore.ieee.org/document/918003
paper_keyword: Compression; MXT; Pinnacle
paper_year: IEEE Micro 2001
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

The link to original MXT paper: [https://ieeexplore.ieee.org/document/5389099]()

This paper introduces Pinnacle, a memory controller module designed for Pentium and Xeon platform featuring main memory
compression. It implements IBM MXT memory compression technology, which supports upto 2x storage reduction and a
maximum of 64:1 compression on certain contents. As pointed out at the beginning of this paper, Pinnacle makes a trade-off
between access latency and greater functionality. 

Pinnacle supports a memory hierarchy consisting of multiple cores, private L1, L2 caches, and a shared Last-Level Cache 
(LLC). The memory controller sits between the LLC and the memory modules, which also participates in cache coherence by 
snooping on the system bus. Pinnacle internally distinguishes between the conventional physical address space after
MMU translation and the actual hardware address on DRAM modules. The former is called as "real address space", while the 
latter is called "physical address space". In the following discussion, we adhere to these terms and their definitions.

Cache lines are stored in compressed form on the DRAM. They are decompressed when they are fetched into a special cache 
maintained by the Pinnacle controller itself, and compressed again when evicted. The organization of the cache will
be discussed below. 
Cache lines are always compressed and decompressed in 1KB blocks, and stored as 256 byte sectors in the DRAM.
Pinnacle assumes a 2:1 compression ratio in average, although in best cases it could compress a line to 1/64-th of 
the original size.
At system startup time, after memory check passes, the BIOS configures the actual physical DRAM to be 
twice as large as the actual DRAM installed on the system. This creates an illusion to all upper level software, includng
the OS, that the actual amount of usable RAM is doubled. The OS, however, should also be slightly modified such that
the virtual memory manager does not over-commit physical memory when the average compression ratio is below 2:1, which 
is can be a fatal error which crashes the system.

This paper covers three major components of Pinnacle: The cache subsystem, memory subsystem, and the compression/decompression
circuit. We reveal the details for each of them in the following discussion.

The cache subsystem, as its name suggests, maintains an on-chip cache private to the controller. The private cache serves
two purposes. First, it accelerates access to compressed data without having to go through the decompression latency
on each access, since data blocks are stored in uncompressed, 1KB block form on-chip. Second, the cache serves as an 
interface between the system LLC and the compression logic, since the former uses a conventional cache block size of 64 
bytes, optimized for machine access and bus transfer, while the latter has significantly larger blocks of size 1KB,
which is required by the compression logic. Cache blocks can be accessed in the unit of 32 bytes from upper level
caches (I think this design decision is made irrelevant to compression, but just to comply to the bus protocol), with
the critical unit delivered first. The cache itself is of 4-way set-associative organization, with 8192 sets. It operates
similar to a set-associative cache using LRU within the way for replacements. The cache also features a directory tracking
the status of each block. In addition to conventional attributes such as tag, valid bit and dirty bit, the directory
also tracks the 256 byte sectors that are accessed by upper level caches using a bit vector. If these sectors are not 
accessed since they were brought into the cache, the controller can simply invalidate them without sending coherence 
messages to the upper level (I think they are assuming inclusive cache hierarchy here).