---
layout: paper-summary
title:  "Frequent Value Locality and Value-Centric Data Cache Design"
date:   2020-07-05 20:05:00 -0500
categories: paper
paper_title: "Frequent Value Locality and Value-Centric Data Cache Design"
paper_link: https://dl.acm.org/doi/10.1145/356989.357003
paper_keyword: Compression; FVC; Frequent Value
paper_year: ASPLOS 2000
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Frequent Value Cache, a compressed victim cache design optimized for frequently accessed values.
This paper observes that most workloads exhibit some degrees of frequent value locality, such that a majority of accesses
and values that occur in the memory are within a narrow range of values. For example, the paper points out that the 
most frequent ten values are responsible for roughly 50% of accesses and memory locations, having great potential to be 
optmized. The paper also presents three important observations with frequent value locality. First, value locality
of accesses and value locality over the address space are surprisingly similar, not only on the values themselves, but
also on the rankings of these values. The paper further discovered that frequently values are uniformly distributed 
over the address space. No matter how accesses are localized for certain memory reagions, the frequent values accessed
by instructions are usually consistent with the values that exist in active memory.
Second, the variety of individual values that may exist in the memory is less than expected, especially consider that
loop variables and temporary variables will introduce a large range of distinct values. The explanation given by the 
paper is that most loop variables and temporary variables or intermediate results are optimized out by compilers, 
which only exist in registers without being ever written back to memory. Meanwhile, those variables that cannot be easily
optimized out by compilers tend to be of less volatile types, such as permanent data structures, in-memory data sets, etc.
whose lifetime is much longer than a single function or loop. Depending on the scenario, these values may happen to 
enjoy more regularity than temporary values.
Lastly, the paper also points out that although processor value locality and memory value locality are two different 
concepts, they often share similar traits in terms of values and their frequencies. Processor's value locality focuses 
more on the distribution of values of certain instructions, while the value locality in this paper aims at the overall
value distribution in the memory hierarchy.

Based on the above observations, the paper proposes Frequent Value Cache (FVC). The paper assumes a direct-mapped L1
cache design for low-power mobile or embedded platform. The FVC is also organized as a direct-mapped cache to minimize
access time, such that access latency of the main cache is unchanged. The FVC acts as a victim cache for reducing cache
misses by buffering evicted blocks from the L1 for future reuse. The difference between a conventional victim cache 
and FVC, however, is that: (1) A conventional victim cache is organized as fully-associative cache, which is limited by
access latency and power consumption, and hence could only support a few entries. FVC, on the contrary, is direct-mapped
at the cost of higher miss rates; (2) Victim cache store evicted cache lines as-is, while FVC compresses these lines
using a static dictionary. By adopting data compression, the FVC can be implemented with less space and power budget
without significantly lowering the hit rate.

An FVC entry is similar to a conventional victim cache entry, with a valid bit, dirty bit, and address flag. FVC data
slots, however, do not store actual data values. Instead, only "partial" cache lines with frequent values are present.
This enables FVC to use short encoding for each frequently occuring value, since the size of the dictionary is small. 
As a result, FVC stores a cache line in the granularity of 32 bit words. Each 32 bit word, if it is in the dictionary, 
is represented by three-bit field representing the index into the dictionary. In addition, one of the eight three-bit 
values are dedicated to represent non-frequent values (the paper uses "111"). Non-frequent values cannot be recovered
on-chip, must be treated as a cache miss.
FVC maintains the invariant that a cache block can exist in at most one of the L1 cache and the FVC. Dirty blocks are 
also allowed, which must be written back on eviction.
Note that eviction on FVC is trivial, since it is direct-mapped.

The paper does not mention how dictionary is maintained and generated, although it is claimed that frequent values are
rather stable throughout the execution, and therefore can be pre-initialized via profiling. The paper also observes that
both values and ranks become stable at early stages of the execution. As a result, the profiling process only needs a 
small part of the execution, after which the dictionary can be generated.
