---
layout: paper-summary
title:  "Efficient Hardware-assisted Logging with Asynchronous and Direct-Update for Persistent Memory"
date:   2019-01-15 23:02:00 -0500
categories: paper
paper_title: "Efficient Hardware-assisted Logging with Asynchronous and Direct-Update for Persistent Memory"
paper_link: 
paper_keyword: Redo Logging; Durability; NVM; Redu
paper_year: HPCA 2018
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes Redu, a transaction system that supports atomic durability using redo logs. Prior designs of 
transactional systems with durability must use one of the three logging schemes: (1) undo, where the before-image of the 
data item being modified is recorded in the log; (2) redo, where the after-image of the data item being modified is 
recorded in the log. In this case, the actual data item on NVM may not actually be modified, because the log 
is sufficient for reproducing the modifications; (3) redo + undo where both before- and after-image are saved 
in the log. This scheme allows more flexible handling of cache lines, because both uncommitted and committed 
transactions can be handled by the recovery routine using the log.

This paper claims that all the above three schemes are insiffucient to build a system that has both high throughput and 
low latency. For undo logging, since only the before-image is saved to the log, two types of write ordering must be observed. 
The first type is that the log write containing the before-image must be persisted before the updated data item. Otherwise,
if a crash happens right after the data item reaches NVM (at which time the log entry has not made it), there is no way
to recover from such failure since no undo image is present to roll back the changes. The second type of write ordering is that
on commit, all dirty updates in the cache must be persisted on the NVM before the application can be notified of the commit.
Otherwise, on a power loss, those committed dirty lines will be lost. Enforcing the two write orderings can have a negative 
effect on latency of both write and commit operations. For write operation, the log entry must circumvent the cache and be
flushed to the NVM before the store could proceed. This is usually done using a cache line write back instruction and 
a store fence. Similarly, on commit, all dirty cache lines are written back to the NVM using write back instructions and 
fences, which is even worse, because this operation is on the critical path of the commit sequence. For redo logging, without 
substantially changing the memory architecture, it must be enforced that dirty cache lines must remain in the cache without 
being written back to the NVM. If this does not hold, then a power failure happening anytime before the transaction commit 
will corrupt data, because only the after-image is saved in the log (and if the log does not reach NVM at that time, it is 
even impossible for this data corruption to be detected). Log writing is usually not considered as a bottleneck for redo
logging, because persistence of log entries are only required before commit. For undo + redo scheme, neither write ordering
nor "no-steal" property is problematic, but the bandwidth requirement of writing log entries to the NVM doubles, which 
becomes a new bottleneck especially on write intensive workloads.

Prior works try to address the aforementioned problems of each scheme by adding extra components and ordering guarantees 
to the hardware. For undo logging, instead of using cache line write back instruction plus memory fences to enforce the 
ordering, it is proposed in previous work that a dedicated log entry queue be added. The log entry queue is filled 
with log entries that bypass the cache hierarchy. The observation is that the combination of write backs and fences is 
too restrictive: In fact, correctness is guaranteed as long as the log write happens before the actual update on the NVM 
side. In contrast, write backs and fences totally serialize the log write and the data item update, which can be relaxed
a little. Since cachable dirty lines must go through the entire hierarchy, while log entries can be directly sent to 
the NVM, the fence and cache flush are no longer needed if the cache controller can take advantage of the timing.
For redo logging, often people will propose to add a DRAM cache as the victim buffer. Evicted cache lines will be stored 
temporarily in the DRAM buffer. On system failure, the volatile DRAM will automatically roll back all uncommitted changes. 