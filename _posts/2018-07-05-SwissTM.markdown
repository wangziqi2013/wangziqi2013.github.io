---
layout: paper-summary
title:  "Stretching Transactional Memory"
date:   2018-07-05 22:36:00 -0500
categories: paper
paper_title: "Stretching Transactional Memory"
paper_link: https://dl.acm.org/citation.cfm?id=1542494
paper_keyword: STM; SwissTM; TL2
paper_year: PLDI 2009
rw_set: Log
htm_cd: Eager for W/W; Lazy for R/W
htm_cr: Eager for W/W; Lazy for R/W
version_mgmt: Lazy
---

Classical state-of-the-art Software Transactional Memory (STM) design, such as TL2, uses lazy conflict detection and 
resolution, and allows higher degree of parallelism where multiple transactions could pre-write a data item and 
transactions are only serialized at commit time. TL2 style STM relies on timestamps to synchronize transactional
reads and writes. A global timestamp counter, which can be implemented as either a simple integer counter or a 
more complicated per-thread counter pool, provides timestamp values at transaction begin and commit time. At transaction
begin, a begin timestamp (bt) is obtained by reading the current value of the counter. At transaction commit time, the
counter is atomically fetch-and-incremented and the after value is obtained as the commit timestamp. Data items are 
associated with timestamps and locks. The timestamp records the commit timestamp of the most recent transaction 
that wrote to the item, and the lock is a one-bit flag that indicates the item is under update. Both are stored in the 
same machine word and can hence be fetched and updated atomically. Transactions keep a read set and write set during 
read phase execution. The read set maintains addresses of read values as well as the timestamps when they are being 
feteched. The read is guaranteed to be consistent regardless of concurrent writers by sampling the write timestamp of 
the data item before and after thr read. The two samples are compared, and the read is considered as consistent if both 
samples are unlocked, and the wtite timestamps agree. If the version of the data item is greater than bt, then the transaction
aborts, because the data item is generated after the snapshot is taken at time bt. Writes are buffered in the thread-local 
write log, which contains the address of the write and the updated value of data items. At commit time, the commit 
ptotocol first locks all data items in the write set. If any lock conflict occurs, to avoid deadlock, the 
transaction must abort. After acquring all locks, the transaction performs a read validation. The validation routine
compares the most up-to-date write timestamps of data items in the read set, and aborts the transaction if any of them
has changed, which indicates Write-After-Read (WAR) anti-dependency. After successful validation, the transaction obtains 
its ct, and then enters the write phase, in which dirty items are written back. The timestamps of data items are also updated 
to the commit timestamp of the tranaction, and locks on updated data items are released. This can be done using one store 
operation.

TL2 is sub-optimal in some cases where spurious aborts can occur and degrade thruoghput. This is because TL2 fixes the begin
timestamp at transaction begin time, and sticks to it for validation. This, however, is overly restrictive. Imagine the scenario 
where a new data item is being read, and the timestamp of the new data item is greater than the bt. TL2 will abort the transaction 
because the data item is generated by a transaction that logically happens after the current transaction fixes the read 
snapshot. The abort in this case can be avoided by promoting the bt to the current logical timestamp, after a successful validation
of the read set. The reasoning behind this is that, as long as the content of the read set still matches the most up-to-date 
values of data items, it makes no difference for read operations to occur at current logical time, or to occur at their 
physical time. One extra benefit is that read-only transactions in this case does not have to perform validation after all 
read operations, if the value of bt equals current timestamp value. In some publications this technique is called "extensible
timestamps", and has been adopted by NORec and LSA-STM. By extending the begin timestamp whenever possible, the transaction
suffers from less spurious aborts and can sustain higher throughput.

This paper argues that TL2, regardless of the optimization we describe above, is still sub-optimal for a few reasons. First, 
while the lazy detection and resolution mechanism of read-write conflicts provides good degree of parallelism, the paper 
pointed out that lazy detection of write-write conflicts negatively impact the performance. The paper recognizes the fact 
that in most cases, data items in the write set are also in the read set, i.e. only few transactions blindly write a data item
without reading it first. A "pre-write"-"pre-write" conflict almost always also indicates that a future read-write conflict will happen
during the validation of the transaction that committed latter. In this case, allowing both to proceed until commit time
wastes processor cycles, because at most one of them can commit successfully. Second, the contention management scheme of TL2,
called "timid", which always aborts transactions that observe the locked item, favors short transactions. For long transactions,
the "timid" policy causes wasted work, if the transaction could actually commit if it waits for the lock. the situation can be 
aggravated if the transaction that aborted the current transaction later itself aborts. On the other end of the spectrum, the 
"Greedy" policy assigns each transaction a timestamp at transaction start, and renew the timestamp on every transaction abort.
The Greedy contention manager chooses the "younger" transaction whose timestamp is smaller as the victim. This scheme favors 
larger transaction, because the overhead of reading and incrementing the global counter can be a performance bottleneck for 
smaller ones.