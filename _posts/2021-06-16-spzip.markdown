---
layout: paper-summary
title:  "SpZip: Architectural Support for Effective Data Compression in Irregular Applications"
date:   2021-06-16 16:48:00 -0500
categories: paper
paper_title: "SpZip: Architectural Support for Effective Data Compression in Irregular Applications"
paper_link: https://conferences.computer.org/iscapub/pdfs/ISCA2021-4ghucdBnCWYB7ES2Pe4YdT/333300b069/333300b069.pdf
paper_keyword: SpZip; Compression; Data Flow Execution
paper_year: ISCA 2021
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Comments:**

1. I can be wrong, but it is not obvious how the hardware accelerated data flow architecture can support other commonly
   used data structures in addition to sparse matrix encoded in Compressed Sparse Row (CSR) format. 
   While I agree that CSR is general enough to encode sparse graphs, and is hence very useful when
   graph algorithms are being implemented, when it comes to something like a linked list or a hash table, could 
   SpZip handle them as well? My best guess is no, because there is no way to express conditions in the data flow
   architecture.
   Imagine the following scenario: I have an array of keys, and I want to fetch the values stored in the hash table
   for each key.
   On the CPU side, I can compute the hash values of several keys using SIMD instructions. 
   It would be great, if these hash values can be entered into the queues of the data flow machine, and let it
   issue memory requests to traverse the linear probing hash table and grab the value.

2. Figure 9 does not show L1 cache, which can be misleading because it may seem that SpZip entirely gets rid of L1
   (which is not a good design choice as it cripples other applications not using it).
   It turns out that L1 is still being used in the simulation, just not drawn in Figure 9.

This paper proposes SpZip, a data-flow memory access architecture with compression for better cache and memory 
efficiency on irregular data structures and algorithms.
SpZip is motivated by two important observations.
First, many real world applications use sparse data structures in which most of the elements are of value zero,
and the data structure itself is stored in a compact format. As a result, these applications demonstrate irregular
access patterns over the address space. Pure software solutions that use manually crafted, ad-hoc routines to traverse 
these structure usually suffer from high cache miss rates due to software's inability to communicate the access pattern
to hardware. The core pipeline is hence frequently stalled by data dependencies, which prevents it from issuing
memory accesses on the critical path, causing under-utilization of memory bandwidth.
Second, conventional compressed cache architecture is agnostic of the layouts of underlying data structures, and most
of them just perform compression in a granularity that is consistent with cache hierarchy's block interface. 
This does not work well for irregular accesses, since these accesses are typically scattered across the address space
due to indirections, making it difficult to group accesses that are nearby in the address space for compression 
or decompression.

The design of SpZip seems to primarily focus on a general encoding for sparse matrix, the Compressed Sparse Row (CSR) 
format, which can be used to represent the adjacency matrix of a graph.
CSR encodes a sparse matrix by only storing non-zero entries for each row using a (column id, value) tuple.
The matrix is still stored in row-major format, meaning that non-zero values on the same row are stored adjacent
to each other, and the column ids are sorted (at least in all the examples given in the paper, while in practice,
as the paper also explicitly points out, sorting columns on the same row based on some other keys other than the 
column id will not change the graph it encodes, but it may bring some locality benefit and result in performance 
improvement). 
Random access to individual rows of a CSR matrix is supported by adding another "offset" array which serves as 
the index into the body of the matrix. The offset array contains the starting offset of each row in the body, and
there is exactly one element for each row. 
Random accesses on columns are not supported. In order to read the value of a column given a row, the entire row
must be traversed, and if an entry with the column id exists, the value of the entry is read. Otherwise, the column
contains value zero and is simply not stored.

The paper then presents two of the most common access patterns that graph algorithms are likely to perform. The
first pattern, most notably seen in PageRank (push model), enumerates all nodes in the graph as the source node, 
and for each source node, enumerates its adjacent nodes as destination. The destination score is then updated 
by computing a "contrib" function on the source node.
Both the destination score and contrib of the source are stored in separate arrays for fast access.

The data flow model of the above pattern is described as follows. First, a ranged scan operator reads out values
in the offset array. This can be done in parallel since there is no data dependency. Then, for each value read from 
the offset array, an indirection operator is performed that uses the value as an index into the body of the CSR
matrix. The value in the CSR matrix is also read out using another ranged scan, the starting address of which is 
the address computed by the indirection operator, and the size of the scan is given by taking the diff between
the current offset value and the next value (or the size of the offset array, if the value is the last one in
offset array).
The output of the second scan is then sent to the CPU core for value update.
In the meantime, values in score array is also read out by a scan operator in a similar manner.
Values in contrib arrays, however, cannot be read by scans, since it is indexed by destination node ids,
which itself are produced by the second range scan, and are not guaranteed to be a range.
The paper shows that it can be accessed using a single indirection operator, the input of which is the column
ids output from the second range scan operator that reads the matrix body.
Note that the data flow model itself does not know how the contrib array is updated, since the function required
to compute the value is not programmed into the model. SpZip proposes that the model only prefetches these "terminal
values" (i.e., values that are not used as sources to data flow operators) into the cache, and let the processor
compute the functions and write the updated values.

The second pattern differs from the first pattern in a way that not all nodes are traversed as the source.
Instead, the algorithm maintains a list of "frontier nodes" which represents the current working set.
On each iteration, the frontier node list is updated by enumerating the adjacent nodes for each node from the 
current frontier list, and adding these nodes into the new frontier list. In the meantime, some properties of 
the adjacent nodes (e.g., distance, or "dist") are also updated as by computing a function on the node.

The data flow of the second pattern is then described as follows. First, we need a range scan operator on the 
current frontier list to enumerate all nodes. Then, the offset array is accessed by indirection using the node ids
from the frontier list as indices with an indirection operator.
The next step is similar to the first pattern: We use another range scan operator on the body of the matrix,
the base and size of which is given by results from the offset array. 
Here note that since the offset array is not scanned, we actually need to read two values (the current index and 
the next index) from the offset array to determine the base and size of the scan on the matrix body.
This was not required in the first pattern, since the offset array is scanned, and the next index will guaranteed to
be available.
Meanwhile, the dist array is also accessed using an indirection operator whose source are the adjacent nodes from
the second range scan operator that produces adjacent nodes given a frontier node.
Similar to the first pattern, the operator on the dist array will not compute the function. 
Instead, it only issues memory requests to prefetch these blocks into the cache hierarchy, and let the processor
determine how updates are performed.

In both access patterns, scan operators will insert a special marker into the output stream. This mark indicates
the end of a scan operation. The mark will be preserved by the next stage operators without any modification.
The CPU may need the mark in the final output in order to determine the progress of computation (e.g., use it
as loop conditions).

SpZip implements the above data flow model with two operators: range scan and indirection.
Operators in SpZip take input values from an input queue, and produces output values to an output queue. 
Both queues have configurable word size to handle different data types.
Operators themselves do not transform or modify data. Instead, they are just programmed to follow certain access
patterns, and fetch data from the hierarchy by generating addresses and then issuing memory access requests.
