---
layout: paper-summary
title:  "A Unified Compressed Memory Hierarchy"
date:   2020-07-02 21:17:00 -0500
categories: paper
paper_title: "A Unified Compressed Memory Hierarchy"
paper_link: https://ieeexplore.ieee.org/document/1385941
paper_keyword: Cache; Cache Compression; ICC; ICC-C
paper_year: HPCA 2005
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Lowlight:**

1. There is no description on memory and bus compression. Even the cache compression scheme is an low effort one that
   is based on a previous design. What is the novelty of this paper?

This paper proposes ICC-C, a unified cache, bus and memory compression scheme. The paper summarizes previous works on 
cache, bus and memory compression as follows. First, cache compression helps in reducing SRAM access overhead for less
power consumption, or increasing effective cache size for better performance. Second, data transferred on the system bus
can also be encoded with frequent patterns. The sending end and receiving end both keep a dictionary whose contents are 
pre-synchronized to be consistent. Frequent patterns such as all-ones or all-zeros are encoded using dictionary codewords
to reduce the number of bits on the bus. Since these are common patterns for both address and data, bus compression also 
helps increasing effective bandwidth and reducing latency. Memory compression, as pointed out by the paper, also increases
effective memory bandwidth by remapping memory blocks to alternative addresses for more compact storage. Memory
compression can be enabled for only a specific range or type of pages, or enabled globally for all physical pages 
transparently. Although not mentioned by this paper, memory compression schemes can also serve the purpose of saving 
bandwidth without having any capacity benefit. In this scheme, compressed lines are fetched and transferred on the bus,
which are then decompressed by the cache controller at the receiving end.

This paper claims that a unified cache, bus and memory compression scheme can help further improve performance than any
of the individual scheme. The unified scheme is designed to take all aspects of the memory hierarchy into consideration
without costly interfacing between component boundaries, such as the cache-bus boundary and bus-memory boundary.

