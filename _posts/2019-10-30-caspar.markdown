---
layout: paper-summary
title:  "CASPAR: Breaking Serialization in Lock-Free Multicore Synchronization"
date:   2019-10-30 20:19:00 -0500
categories: paper
paper_title: "CASPAR: Breaking Serialization in Lock-Free Multicore Synchronization"
paper_link: https://dl.acm.org/citation.cfm?id=2872400
paper_keyword: CAS; Cache Coherence; CASPAR; Synchronization; Lock-Free
paper_year: ASPLOS 2016
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes CASPAR, a novel cache coherence extension to support efficient serialization based on Compare-And-Swap 
(CAS) primitives. CAS is often used as the synchronization primitive in lock-free programming. Threads access an object 
using a pointer P optimistically, assuming that no interleaving thread will change the state half way during the read. 
Updates are made to the object by creating a new object, and using CAS with the old value of the pointer used to access
the object to atomically swap the new object to the pointer P. The paper identifies that lock-free programs written this
way often suffer from limited scalability for two reasons. First, when the level of contention is high, the CAS is likely
to fail by not observing another thread's intervening update. To deal with such failure, programmers typically use a 
CAS loop to retry the read and update process, which only worsens contention on the variable, since threads will likely 
to spin for multiple rounds before the CAS eventually succeeds. Second, due to the fact that CAS will cause the cache line
holding the variable to be acquired in exclusive ownership, this will essentially serialize the acquisition of the cache
line containing the variable globally. A CAS cannot complete before the previous owner of the cache line finishes CAS
and releases the line. 

This paper proposes a hardware architecture to accelerate CAS execution on directory-based multicore systems. The proposal
relies on the fact that in some commonly used lock-free data structures, such as stacks, queues, etc., the following pattern 
is used to append a new node into the structure. First, a new node is allocated and its content is initialized. The partial
state of this step is not visible to other cores, since this happens in the execution stack of the current thread. Second,
the head pointer of the structure is read into a local variable, H. Thrid, we set the "next" pointer of the newly allocated
node to the value stored in H. In the last step, a CAS is executed using H as the old value and the newly allocated object
as the new value, which (hopefully) adds the new object before the previous object in the head. If an intervening thread
executes its CAS before the current thread does, changing the value of the head pointer, the CAS of the current thread
will fail, which results in one or more retries. 

The paper optimizes the above process based on the observation that thew "new" value is in fact independent from the "old"
value of the CAS, and is available even before the old value is read from the head pointer. The second important observation
is that, if all CASs are serialized by the hardware, then the "new" value of the current CAS instance will be the "old"
value of the next CAS. On the other hand, if CASs are serialized by hardware, the next CAS will not be able to know
its "old" value before the previous CAS finishes (at which time the after-value of the previous CAS is released to the 
cache hierarchy and acquired by the next CAS).

This paper breaks the serialization effect of CAS instructions described above using two techniques. First, a special
piece of hardware is added both per-core and per-directory to serialize the execution of CAS instructions globally,
reducing the chance of CAS failures due to contending threads. Second, instead of using cache coherent memory as the 
only channel for passing values from a core to another (particularly, the after-value of CAS), a new eager forwarding 
channel is added, the purpose of which is to pass the after-value of a previous CAS to the next core executing a CAS 
before the first CAS is even executed. By doing so, the second CAS-pattern (i.e. from the reading of the head variable to
the CAS) can be executed speculatively, only to be validated later after the first CAS instruction has committed with a
non-speculative after-value, overlapping these CAS-patterns which results in increased parallelism. We describe these 
two mechanisms in details below.

The first component in CASPAR is efficient hardware detection and serialization of contending CAS instructions. To
acheive this, every core is extended with a small fully associative buffer that records operand addresses of failed CAS 
instructions. A new adddress is inserted into this buffer when the number of failed CAS instructions exceed a certain threshold
on this core during a time period. Entries are removed if they have not been accessed by CAS for a while. Then, for 
every load instruction, this buffer is searched to see whether a load accessed an address recorded in the buffer. If true,
the load is identified as the beginning of a CAS-pattern, called a triggering load (TL), and the address is identified 
as the target address of the current ongoing CAS-pattern, called Active CAS (AC), which is stored in a register. The AC 
register will be cleared after the commit of a CAS instruction on that address. There can be only one AC at any moment 
during execution. The purpose of isentifying TL is that the core will acquire the cache line accessed by the TL in
exclusive mode, expecting a CAS to later update the line. Before the AC is cleared, the TL will be held in the cache
for an extended period, and the cache controller will reject all requests for the line from othe cores. To avoid deadlock,
the cache controller only holds the line for a limited number of cycles. The line will be released after a timeout to
allow other processors proceeding with the line.