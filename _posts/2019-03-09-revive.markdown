---
layout: paper-summary
title:  "ReVive: Cost-Effective Architectural Support for Rollback Recovery in Shared-Memory Multiprocessors"
date:   2019-03-09 04:01:00 -0500
categories: paper
paper_title: "ReVive: Cost-Effective Architectural Support for Rollback Recovery in Shared-Memory Multiprocessors"
paper_link: https://ieeexplore.ieee.org/document/1003567
paper_keyword: Checkpointing
paper_year: ISCA 2002
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes ReVive, a general purpose rollback recovery mechanism for shared-memory multiprocessors. There are 
two design goals: Software rollback and crash recovery. Software rollback requires the system to preserve a consistent
snapshot of system states. On a rollback request, the state snapshot is quickly restored, and system execution resumes 
from the restoration point as if nothing has ever happened. Crash recovery focuses on the scenario where one or more 
components of the system malfunction and cause data loss. A previously saved system snapshot must be loaded from some
external sources, or rebuilt from remaining available information after the crash. In the case of ReVive, since all data i
s stored in DRAM and hence is volatile, we only consider recovery from detectable errors caused by malfunctioning memory 
modules. 

ReVive is built on Stanford DASH multiprocessor, which is a shared-memory architecture using a customized hardware coherence
protocol to maintain cache coherence. DASH consists of multiple processors and memory modules connected to a low latency 
communication network. Each processor has a memory module and a cache controller. The cache controller is responsible for 
handling cache coherence requests forwarded to that node. This paper assumes that these processor and memory modules 
could fail independently, i.e. it is possible that one of the memory modules stopped working while others remain usable.
Failures are restricted to non-power failure only, as a power failure will wipe out the content of every memory module,
and hence render the system unrecoverable. The paper also assumes a fail-safe error model: When an error happens, it is 
guaranteed that it will be detected by hradware using error-correcting bits or other techniques within a bounded amount 
of time. This bounded amount of time is known in advance, such that the system just assumes that the system will no longer
be automatically rolled back after this period of time. This is critical to I/O handling, because the system needs to buffer
I/O messages until it is certain that these non-retractable I/O operations will not be called back in the future. When 
an error is detected, the system just discards active data, and restores the global state to a previously saved, consistent
checkpoint.

ReVive protects the system from data loss by adding redundancy when one or more memory module suddenly stops working and 
loses all data it stores. Memory modules are divided into parity groups. For each page in each parity group, an extra 
parity page is stored, and if one page in a parity group is lost, this parity page is used to rebuild the missing page.
Note that parity pages are also scattered in all memory modules to lessen the risk that a few broken memory modules 
bring the system into an unrecoverable state because more than one page in the parity group is missing. On write backs
of dirty cache lines, both the old cache line and the parity should be updated. The sequence is described as follows.
First, the cache line is marked as busy by the directory such that no other processors could access the line via coherence
to preserve the atomicity of parity update. The directory controller then reads the old content of the line, computes 
the XOR with the new line, and then writes the new line. If an acknowledgement for the write back is required, it will
also be sent by the directory controller. Next, the directory controller reads the parity page, and computes the XOR
between the parity page and the result of the previous XOR. In the last step, the updated parity is written back, and then
the cache line is unlocked. The processor requesting the write back can resume execution as long as it receives the 
acknowledgement from the directory. Parity page update can be performed in the background and hence is overlapped with 
normal execution.

Note that, in the above procedure, if the two update operations, data write and log write, cannot be made atomic,
which is the case for most hardware, extra steps need to be taken to ensure that the atomicty is not violated. The paper
suggests that each parity entry is extended with a one bit marker. The marker is unset before updating data, and only
re-set when updated parity has been written. During recovery, if a parity page is found to have the marker clear, the 
parity page is corrupted, and must be diacarded, because there is no guarantee that the parity page has been updated 
after the data page.