---
layout: paper-summary
title:  "Failure-Atomic Persistent Memory Updates via JUSTDO Logging"
date:   2019-08-08 23:44:00 -0500
categories: paper
paper_title: "Failure-Atomic Persistent Memory Updates via JUSTDO Logging"
paper_link: https://dl.acm.org/citation.cfm?id=2872410
paper_keyword: Logging; JUSTDO; NVM
paper_year: ASPLOS 2016
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes JUSTDO logging, a novel logging and recovery method for non-volatile memory. In ordinary logging schemes,
such as undo logging, redo logging, and shadow logging, the amount of data (i.e. log records and metadata) is proportional
to the number of store operations. One log entry is generated for each store operation, which contains the address, data,
and other control information in order to roll back or redo the affected region. These schemes generally have three problems. 
First, they enforce write ordering at the guanularity of every store or every transaction commit. In the former case,
a log entry is generated before the store is performed, and the entry must be fllu flushed to the NVM device before the 
store could proceed to guarantee recoverability. Although with new hardware primitives and probably new architectures, the 
overhead of persisting can be overlapped by smart scheduling (e.g. hardware level write ordering enforcement), it still poses
a major overhead of logging schemes that require per-store logging, e.g. undo logging. In the latter case, the log records are 
flushed to the NVM at transaction commit point, which incurs a burst of traffic to the network and NVM. Even worse, the 
chance of overlapping this burst of memory write backs with other useful work is slim, because transaction commit always 
happens as the last action a transaction will take, which puts the persistence of log records on the critical path. This 
happens with redo logging. The second problem is that extra metadata, either on-chip or off-chip (e.g. on memory controller)
might be used to track the state of stores. These metadata themselves also require persistence for correct crash recovery, 
which introduces extra traffic, storage and complexity. The last problem is that the recovery of all except shadow-mapping 
are data-centric, which means that the time complexity of recovery depends on the amount of data the current transaction
or critical section has generated. The availbility of the system might be affected because of slow recovery. For shadow-mapping,
only simple recovery is performed, because by nature, this scheme has a "write-once" property for non-volatile data, and 
only overwrites old data when it is safe to do so. The downside, however, is that the amount of working data will be multiplied
due to multiversioning. The system generally has to stall and perform garbage collection when storage runs out to reuse
older versions of data.

Justdo logging takes advantage of two important observations. First, most datarace-free applications use locks as the basic 
synchroniation primitive. Lock acquisition and release can be interpreted as granting and giving up permission of accessing
shared states. Applications often only observe inconsistent states of shared data within critical sections (i.e. holding 
at least one lock), and leave shared data in consistent states before leaving the critical section. The crash recovery,
therefore, could only focus on these (potentially nested) critical sections called "Failure-Atomic Sections (FASE)",
and recover the system back to a state that is equivalent to a time point in normal execution where no lock is held by
any thread. The second observation is that, although data-centric recovery may simply the algorithm, because the recovery handler 
just needs to iterate over all log records, and apply the data to the address indicated by the record, the same 
sequence of stores can actually be reproduced by running the same FASE with the same input (the paper fails to identify that
if the FASE itself is non-determinstic, the sequence could not be reconstructed, in which case re-executing with the 
same input will not help), which eliminates the need of value logging. As long as the recovery process can resume the 
inerrupted execution of a FASE with the same environment (e.g. local stack frames, arguments, etc.), it is guaranteed 
that the same output be generated, and the same state as if the original FASE were not interrupted by the crash can be 
reached.

This paper also identifies an important trend in the evolution of hardware platform: In the near future, the cache system 
might also be included into the persistence domain, just as the pending queue in the memory controller. This can be done
by battery-backed caches, or using residual/backup power to flush the cache back to the NVM. No matter which technique 
is used, the illustration of persistent caches can greatly simplify persistent programming, since store instructions can be 
considered of persistent, as long as the instruction has exited the store buffer. This only takes a relatively lightweight 
store fence (which drains the store buffer, exactly as needed), instead of executing a heavyweight fence-flush-fence sequence,
which can take hundreds of cycles. 

Justdo logging overcomes the above problems using a combination of persistent cache, exeution-centric recovery, and 
FASE-based inference. Each thread maintains a small thread-local logging area, which consists of a special logging 
object (jd_obj in the paper) and other control data. The logging object consists of two log entries, a list of pending lock
descriptors, and a list of owned lock descriptors. The two log entries are used alternatively to log the most recent store
instruction in the current FASE, including the address, value, and the program counter after the store. We need two entries, 
because while writing the current log entry, the content of the entry may become temporarily inconsistent. To avoid corrupting 
the entry, we always keep the previously valid entry clean, and write to the other one (more details later). The two lists of 
locks are responsible for recoverying lock ownership after a crash. The paper assumes that all locks are mapped to NVM region,
and hence their state remains available after the crash (so the lock list only serves as a fast path - we can always find 
the owner of a lock by scanning the lock table if the lock is implemented with owner information). 

FASEs in Justdo logging is wrapped by special wrappers called justdo routines. A justdo routine consists of three parts.
The first part is a header macro, JD_ROUTINE_ON_ENTRY. This macro checks the current mode of execution (normal/recovery),
and depending on the mode, jumps to the last point (recovery mode) of interruption or does nothing (normal mode). In
the second part, the justdo routine copies local states for executing the FASE into the logging object, which will be 
mapped to persistent storage (i.e. the cache). This is necessary, since in order for the FASE to resume execution, the 
local state of the FASE must remain accessible after a crash. The third part is the FASE body
