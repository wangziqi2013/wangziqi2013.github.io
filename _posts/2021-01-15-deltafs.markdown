---
layout: paper-summary
title:  "DeltaFS: Exascale File Systems Scale Better Without Dedicated Servers"
date:   2021-01-15 20:35:00 -0500
categories: paper
paper_title: "DeltaFS: Exascale File Systems Scale Better Without Dedicated Servers"
paper_link: https://dl.acm.org/doi/10.1145/2834976.2834984
paper_keyword: File System; DeltaFS
paper_year: PDSW 2015
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Lowlight:**

1. How does the delta registry (section 2.2) maps files to their corresponding deltas? Are they per-file mapping?
   If so, the registry itself would be another metadata repo that will be updated on application commit point,
   and I did not see how this is not a scalability bottleneck, if a normal metadata registry would be.

This workshop paper introduces DeltaFS, a distributed file system design for extremely high scalability without
dedicated metadata servers. The paper observes in the beginning that existing distribuyted systems for HPC workloads
often lack scalability due to dedicated metadata servers, which must be contacted on file system operations. The
consistency of the global metadata store also requires extra protocol overhead, which is most likely unnecessary,
since most workloads running on HPC clusters either do not communicate with each other, only using the file system
as a large, persistent store of data, or only communicate with other processes using a small portion of the file system.
In either case, maintaining a globally consistent image of file system metadata and sharing them among all processes
seems to be an overly strong semantics, as it will not be needed for most of the time.

The paper uses two examples. The first example, Lustre, relies on a centralized, dedicated metadata server node to 
provide registry information. All file accesses must contact the single metadata server, which could easily become
a performance bottleneck. The second example, IndexFS, partitions metadata and distributes them to several
independent metadata servers, inproving scalability. The metadata retrieval and update cost, however, still exist
on a per-access basis, incurring extra bandwidth and protocol overheasd on these servers.

DeltaFS solves the above challenge by not maintaining a globally consistent metadata registry, and not contacting the
remote metadata server on most file accesses. Instead of updating the global metadata when file operations are being
performed, DeltaFS stores local changes to the metadata as local metadata objects. Depending on the file sharing mode,
this local metadata object is either only made visible to other processes, or shared across a small number of processes
using only local metadata servers. In other words, DeltaFS reduces communication between the application and metadata
registry by performing local writes and amortizing updates to metadata until application terminates. Compared with 
other designs, such as BatchFS, where metadata updates are always asynchronously pushed to the central registry
in batches after the application terminates, DeltaFS saves even more bandwidth by maintaining metadata updates as 
local "deltas", and letting other application to directly fetch metadata from these local delta, rather than forcing
all file operations to serialize on the central registry, further reducing contention and improving performance.

The paper assumes the following architecture. The HPC cluster consists of computing nodes and storage nodes. Computing
nodes are capable of performing certain file operations locally using the native file system. Storage nodes run the 
DeltaFS server (registry server), and the native file system is only used as a key-value object store, where objects
can be data segments or file metadata.
A central file registry maintains a global image of file metadata. The central registry, as discussed above, does not 
necessarily reflect the most up-to-date state of the current file system, since local deltas may exist which overrides
the global registry's entries.


