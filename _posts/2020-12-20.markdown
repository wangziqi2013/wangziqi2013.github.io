---
layout: paper-summary
title:  "InvisiFence: Performance-Transparent Memory Ordering in Conventional Multiprocessors"
date:   2020-12-20 23:17:00 -0500
categories: paper
paper_title: "InvisiFence: Performance-Transparent Memory Ordering in Conventional Multiprocessors"
paper_link: https://dl.acm.org/doi/10.1145/1555754.1555785
paper_keyword: Microarchitecture; Store Buffer; Memory Consistency
paper_year: ISCA 2009
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes InvisiFence, a cache and microarchitecture design for enforcing stronger memory ordering on weakly
ordered architectures. 
Previous proposals for implementing strong memory consistency models often suffer from performance overhead and/or 
design complications.
The paper gives two examples. In the first example, special hardware structures such as load queue and store buffer 
are added to the microarchitecture for tracking local memory ordering, and the pipeline is stalled when the commit of 
certain memory operations may lead to a violation of the consistency model. This approach always assumes pessimistically
that a violation will definitely occur, when the local ordering of loads and stores do not match the model's definition.
In the second example, processors are allowed to execute out-of-order memory instructions, but they continuously perform
after-retire speculation in the unit of consecutive instruction chunks. In continuous after-retire speculation, although instructions have been retired and removed from the ROB, the cache blocks accessed by these data are tracked in the private cache or by a signature, such that they are still speculative.
A snapshot of the register file is also taken when the speculation begins.
Memory instructions to different addresses can be executed in arbitrary order, as long as no external viewer (e.g.,
other processors, or bus agents) 
The speculation commits regularly if no ordering violation is observed by external viewers, which can be detected by
monitoring the read and write set of the current speculation, or proactively sending the current write set to all other
processors for invalidation.
On commit, all speculatively accessed cache blocks are "released" by clearing the speculative bit.
If, however, a speculation instance collides with another speculation, or it is violated by another processor's 
memory request, one of the two speculations must abort, and roll back to the previous checkpionted state, to avoid
any observable consistency model violation.
In practice, the above mechanism requires large amount of hardware resources, including a new coherence protocol, 
extra hardware structures for holding the speculative states, or significantly change the way a cache or an on-chip
network functions.

InvisiFence adopts the second approach. The dynamic execution flow is divided into speculative chunks in the runtime, 
which can begin and end at arbitrary boundaries, except for instructions whose effect cannot be rolled back
(e.g., I/O instructions, uncachable writes), in which case speculation must commit, and execute the instruction
non-speculatively. 
The hardware ensures that all loads and stores within a speculative chunk appear as a single, atomic unit to external
viewers, such that these viewers cannot (1) observe any intermediate state in the middle of the chunk by reading dirty
data generated in the chunk before speculation ends; (2) establish any dependency with an uncommitted chunk by writing
to its working data. 
If these two can be achieved, then speculative chunks are always committed with a global ordering, just like individual 
memory instructions in sequential consistency model, such that memory instructions between chunks are ordered by the 
real-time order the belonging chunks commit., and that instuctions to different addresses are unordered within the
same chunk. The latter does not violate the consistency model, since no other processors may observe the internal
states of a chunk.

The paper assumes the following system architecture. The base system only implements the most relaxed memory consistency
model. Loads and stores are issed when they are ready, and executed as soon as possible. No load queue is present for
tracking load ordering, meaning that loads can reorder with each other. A store queue and store buffer, however, is 
attached to the store unit for tracking store addresses and status. 

