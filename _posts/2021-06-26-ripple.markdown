---
layout: paper-summary
title:  "Ripple: Profile-Guided Instruction Cache Replacement for Data Center Applications"
date:   2021-06-26 04:51:00 -0500
categories: paper
paper_title: "Ripple: Profile-Guided Instruction Cache Replacement for Data Center Applications"
paper_link: https://conferences.computer.org/iscapub/pdfs/ISCA2021-4ghucdBnCWYB7ES2Pe4YdT/333300a734/333300a734.pdf
paper_keyword: Ripple; i-cache; Cache Replacement
paper_year: ISCA 2021
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents Ripple, a novel instruction cache replacement algorithm using off-line optimality analysis.
The paper is motivated by the fact that modern data center applications can incur a heavy burden on the instruction
cache, which is caused by numerous software stacks and many modules for different purposes within each stack.
The paper shows that a typical data application can execute up to several MBs of code in the working set.
On current platforms with tens of KBs of L1 instruction cache, this will result in 23% to 80% vacant pipeline slots.

The paper also noted that, despite best efforts from previous proposals that attempt to address the i-cache problem,
such as specialized prefetchers, these proposals often only give sub-optimal improvements, because of not being
able to understand the essential problem of high i-cache miss rates.
As a result, these prefetchers can bring many unnecessary cache blocks into the i-cache, potentially evicting
useful blocks, causing what we call "cache pollution". 
In addition, specialized hardware prefetchers need extra hardware resource on the chip, which can be expensive 
in some cases.

Hardware prefetchers, however, may actually become helpful when combined with the correct replacement algorithm.
The paper experimented with an ideal algorithm that always evicts blocks that will be used in the furthest future,
and gives priority to prefetched blocks over regular blocks (i.e., the well-known MIN replacement algorithm). 
Results show that performance can be improved with the proper replacement algorithm compared with the baseline
using LRU.

The paper makes two observations about a good replacement algorithm. 
First, the replacement algorithm should evict cache blocks that are prefetched, but not used in the future. In
MIN this can be inferred accurately from the execution history, which is assumed to be known.
Second, the algorithm should not evict blocks that are "hard to prefetch", which is defined as cache blocks
that cannot be prefetched with good accuracy, e.g., due to indirect branches (depending on the prefetcher).
Unfortunately, existing algorithms could not easily fulfill the task in these two observations, as they are 
most likely invoked on-the-fly, with information only on the current state of the system, and a limited execution 
history.

The paper then investigated a few popular eviction algorithms, and compared their performance implication with hardware 
prefetchers. Sadly, none of the existing algorithms studied by this paper performs well.
Among the many algorithms, GHRP predicts a cache block to be either dead or alive based on control flow information,
and evicts blocks that are deemed dead. The paper points out that certain implementational issues prevent GHRP
from outperforming the baseline LRU. But even after correcting the issue, GHRP only outperforms LRU by a negligible 
amount.
Hawkeye/Harmony is originally designed for data caches, and it predicts a block to be either "cache-friendly" or
"cache-averse" using the PC of the memory instruction. This will not work for i-cache evictions, since the 
i-cache is driven by changing PC values.
The paper also experimented with RRIP family, and without surprise, results are also not good. The problem with 
RRIP is that RRIP is specifically designed to address the scan pattern which will incur pathological cases with LRU.
RRIP avoids the problem by treating newly inserted blocks only as "friendly" after the first reference after insertion.
This assumption, however, does not work for i-cache, since scan is a relatively rare pattern for execution.
The paper summarizes at the end of this section that i-cache usage follows a different pattern than data caches.
Most prominently, even the same i-cache blocks will demonstrate varying re-reference intervals during different
stages of program execution. This renders conventional algorithms depending on the assumption of fixed re-use 
behavior on the same address useless.

The paper then presents Ripple. Ripple is a software implemented replacement algorithm that relies on special
i-cache flush instructions to mimic the behavior of the ideal algorithm, which has already been shown to exhibit
the best performance improvement.
The biggest advantage of Ripple is that, instead of running the algorithm on-the-fly as the binary executes,
which is limited by on-chip computing resources, decision response time (usually a few cycles), and knowledge of 
future references, Ripple collects execution profile (mainly basic block information), and analyzes the profile
off-line by simulating the ideal algorithm (i.e., MIN).
