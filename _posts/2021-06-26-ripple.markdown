---
layout: paper-summary
title:  "Ripple: Profile-Guided Instruction Cache Replacement for Data Center Applications"
date:   2021-06-26 04:51:00 -0500
categories: paper
paper_title: "Ripple: Profile-Guided Instruction Cache Replacement for Data Center Applications"
paper_link: https://conferences.computer.org/iscapub/pdfs/ISCA2021-4ghucdBnCWYB7ES2Pe4YdT/333300a734/333300a734.pdf
paper_keyword: Ripple; i-cache; Cache Replacement
paper_year: ISCA 2021
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper presents Ripple, a novel instruction cache replacement algorithm using off-line optimality analysis.
The paper is motivated by the fact that modern data center applications can incur a heavy burden on the instruction
cache, which is caused by numerous software stacks and many modules for different purposes within each stack.
The paper shows that a typical data application can execute up to several MBs of code in the working set.
On current platforms with tens of KBs of L1 instruction cache, this will result in 23% to 80% vacant pipeline slots.

The paper also noted that, despite best efforts from previous proposals that attempt to address the i-cache problem,
such as specialized prefetchers, these proposals often only give sub-optimal improvements, because of not being
able to understand the essential problem of high i-cache miss rates.
As a result, these prefetchers can bring many unnecessary cache blocks into the i-cache, potentially evicting
useful blocks, causing what we call "cache pollution". 
In addition, specialized hardware prefetchers need extra hardware resource on the chip, which can be expensive 
in some cases.

Hardware prefetchers, however, may actually become helpful when combined with the correct replacement algorithm.
The paper experimented with an ideal algorithm that always evicts blocks that will be used in the furthest future,
and gives priority to prefetched blocks over regular blocks (i.e., the well-known MIN replacement algorithm). 
Results show that performance can be improved with the proper replacement algorithm compared with the baseline
using LRU.

The paper makes two observations about a good replacement algorithm. 
First, the replacement algorithm should evict cache lines that are prefetched, but not used in the future. In
MIN this can be inferred accurately from the execution history, which is assumed to be known.
Second, the algorithm should not evict blocks that are "hard to prefetch", which is defined as cache blocks
that cannot be prefetched with good accuracy, e.g., due to indirect branches (depending on the prefetcher).

