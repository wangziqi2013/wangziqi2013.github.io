---
layout: paper-summary
title:  "(Almost) Fence-Less Persistent Ordering"
date:   2020-12-07 18:12:00 -0500
categories: paper
paper_title: "(Almost) Fence-Less Persistent Ordering"
paper_link: https://www.microarch.org/micro53/papers/738300a539.pdf
paper_keyword: NVM; Persistent Barrier; Themis
paper_year: MICRO 2020
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

This paper proposes Themis, a lightweight persistent ordering architecture for NVM applications. The paper begins by
observation that most NVM applications, if not all, uses persistence barrier to guarantee write ordering. Using undo
logging as an example, the log entry must reach the NVM before dirty data does, because otherwise, if the system
crashes before the two persistence operations, dirty data would not be able to recovery to the pre-image before
the transaction, corrupting program data.

The paper then claims that persistent barriers are detrimental to performance, mainly because: (1) They require a 
cache line flush followed by memory fence, which prevents any possible coalescing and reordering of NVM writes;
(2) The sfence will prevent instructions after it from committing in the ROB, which stalls the pipeline given the
relatively long latency of NVM writes. 

The paper also makes a few observations on common usage patterns with persistence barriers. First, non-temporal stores
(e.g., ``movnt``) bypasses the cache hierarchy, and can therefore be used to write log entries to the NVM. The advantage
of using non-temporal stores is to avoid bringing the address used for logging into the cache, causing cache pollution,
since the log buffer will never be read again during normal operation.
Second, the persistence barrier works equally for both temporal stores (i.e., regular ``mov``) and non-temporal stores,
except that the cache line flush is unnecessary for non-temporal stores.
The ``sfence`` instruction can be employed to order non-temporal and temporal stores without distinction.
Third, non-temporal stores typically reach the memory controller faster, since they are generated earlier, and they 
have shorter data paths. To elaborate: A non-temporal store will be directly sent to the memory controller after
they are generated, while a temporal store followed by cache line flushes need to go through the entire cache hierarchy,
which costs more cycles. 
Lastly, modern memory controllers are in the persistence domain, thanks to the Asynchronous DRAM Refresh (ADR) feature.
Once a memory request reaches the memory controller's queue, they are guaranteed to be persistent even on power losses.
It is, therefore, sufficient to declare that an NVM write has been persisted once the processor received the ACK
packet from the memory controller.

The paper assumes the following architecture. The non-temporal stores are handled by a write-combining buffer (WCB)
connected to the Load-Store Unit (LSU). The LSU directly puts the request into the WCB without invoking coherence
(it is unclear, however, whether the L1 cache will be updated if the block to be written is already in L1 with
sufficient permission. This does not affect the correctness of the design, though.).
Write requests in the WCB are coalesced (writes to the same cache line on different locations are combined into a 
single request), combined (writes to the same location in the same line are also combined) and reordered for better
write performance. Once the arbitrator grants bus access, and the memory controller indicates that it could accept
more requests, the WCB controller sends a request to the controller, and wait for the ACK.
The WCB maintains three pointers, a tail pointer, where new requests are added; A head pointer, where existing requests 
are removed and sent on the bus; An ACK head pointer, which lags behind the head pointer, and it points to the last
request, in the queue order, that has not been ACK'ed by the memory controller. 
The paper notes that the ACK head pointer, in fact, indicates the current progress of persistence in the WCB, since any
writes that have not been ACK'ed by the memory controller are either still in the queue, or are still being transferred
by the on-chip network.

Temporal stores are handled by the cache hierarchy and coherence protocol as usual. When a clflush instruction hits a 
line, the line is scheduled for eviction, which is sent to a write back buffer (WBB). Each level of the cache has a WBB,
but this paper focus on the WBB at L1 cache in particular. Lines in the WBB are queued until the next level cache is
able to handle the eviction.

The Themis design is based on the observation that, as long as a temporal write is evicted from the WBB after a 
non-temporal write is removed from the WCB after being ACK'ed, it is guaranteed that the former is ordered after 
the latter. In the context of undo logging, this implies that, as long as the undo log entry is persisted using 
non-temporal writes, and that data is persisted using temporal writes and clflush, the write ordering between this
two can be enforced with litter performance overhead, since (1) At this time, both writes have been committed in the 
pipeline, and therefore no pipeline stall would occur; (2) The temporal write naturally will traverse through a 
longer data path than the non-temporal write, which overlaps the the time difference with persistence delay of the 
non-temporal write.
