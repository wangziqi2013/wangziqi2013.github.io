---
layout: paper-summary
title:  "Kiln: Closing the Performance Gap Between Systems With and Without Persistence Support"
date:   2019-02-20 23:39:00 -0500
categories: paper
paper_title: "Kiln: Closing the Performance Gap Between Systems With and Without Persistence Support"
paper_link: http://www.cse.psu.edu/~juz138/files/150-zhao.pdf
paper_keyword: Kiln; NVM; Cache; LLC
paper_year: MICRO 2013
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes Kiln, a novel design that achieves atomic persistence using persistent LLC. In classical designs there
are two ways of achieving the same effect, using either Write-Ahead Logging (WAL) or Copy-On-Write (COW). WAL requires the 
programmer or hardware to generate log entries on every data modification. In addition, persistent barriers are also inserted 
on certain locations of the program to enforce the correct write ordering dependency between log entries and dirty cache 
lines. COW requires an extra level of indirection. On modification, data items are copied to a new location on the NVM, 
and then the modification is performed on the new copy. The mapping is changed to point to the new copy after the modification. 
New copies of data items must be persisted to the NVM before the transaction commits.

Neither WAL nor COW is perfect for efficient persistent atomic regions. Both schemes induce extra memory traffic. In WAL,
data items must be copied twice (one to generate the log entry, using either old or new value based on logging type, another 
to update the data item), resulting in three copies. In COW, extra NVM storage is used by multiple versions of data items 
as well as the mapping table. In addition, if WAL is to be used, the long latency of persist barriers cannot easily be removed 
from the critical path, which is another source of slowdown. 

This paper adopts a third approach, which extends the persistence domain to the last level cache (LLC) using techniques such
as battery powered SRAM. No expensive data movement or persistence berriers are needed, because in order to achieve 
persistence, it is sufficient to evict data to the LLC, which has lower latency and higher bandwidth. 

Kiln is motivated by redo logging. Generally speaking, the goal of achieving persistence can be further divided into two 
slightly different smaller goals: consistency and progress. The consistency requirement states that uncommitted changes are 
not supposed to be observed after the crash even if some uncommitted modifications may have already been conducted. Since 
the system can crash any moment during the execution, the exact state of memory is hard to know at the time of the crash. 
To solve this problem, in redo logging, no modification made by the operation is allowed to be persisted before the transaction 
commits. The data structure hence can stay consistent as if it were never modified by the application. If the system crashes 
before commit, all volatile states will be lost, including dirty data generated by the operation, which naturally rolls 
back all its changes. The progress requirement states that committed operations must not be rolled back in case of a crash. 
This is achieved by flushing all redo log entries into the NVM before the transaction commits. If the system crashes after 
this point, all valid redo log entries will be replayed as if the committed operation were executed in exact the same manner 
as it was during normal operation. Kiln follows a similar approach to guarantee consistency by not allowing dirty cache 
lines to be written back before transaction commits. In terms of progress, however, instead of relying on a sequential
redo log which is flushed back on each transaction commit, Kiln leverages a persistent LLC, and uses metadata in cache tags 
to track log entries which are stored as LLC data. There are two obvious advantages of merging redo logs with LLC data entries.
First, no redundant data is generated, since the LLC entry stores both redo log entry and data (this has limitations, as we
will see below). Second, on recovery, data is instantly available without any form of log replay. The revocery routine only
walks cache tags and makes sure that committed states are preserved while invalidating uncommitted data.

The operation of Kiln is described as follows. During normal operation, dirty cache lines written by different transactions
are recorded by caches on all levels. On transaction begin, a globally unique transaction ID is distributed such that
every transaction can be uniquelly identified using the ID. Dirty cache lines generated during the transaction are tagged 
with the transaction ID. Kiln extends tag arrays with an array of transaction IDs, which are set during a transaction when
the cache line is written for the first time. Each level of the cache is also extended with a FIFO queue, which stores the 
metadata (transaction ID, line location, etc.) of dirty cache lines. When a cache line is first written, the metadata 
of the store operation is pushed into the queue. To help identify whether a store operation is the first store during 
the transaction, three more states are added to a cache line which co-exist with ordinary coherence states: Clean, which means
that the cache line is not written by another transaction, committed or uncommitted; Pending, which means the cache is 
written by an uncommitted transaction; Persistent, which means that the cache line has been committed. Note that on all
levels of caches, the FIFO queues are volatile, and will be reset on a power failure. The design of Kiln guarantees
that the recovery routine can identify cache lines in different states using the metadata and state bits after a crash.

On transaction commit, as described above, the cache controller evicts dirty lines in higher level caches to the LLC,
after which the transaction becomes durable. The FIFO queue at each level is consulted on commit using the committing
transaction ID. Entries will be removed from the queue after the dirty lines are evicted. Note that a line does not 
have to be totally removed from higher level caches. The line can remain in higher level caches in a clean state, which
reduces future cache misses if access locality is high.