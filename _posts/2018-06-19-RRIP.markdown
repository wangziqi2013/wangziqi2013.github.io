---
layout: paper-summary
title:  "High Performance Cache Replacement Using Re-Reference Interval Prediction"
date:   2018-06-19 05:43:00 -0500
categories: paper
paper_title: "High Performance Cache Replacement Using Re-Reference Interval Prediction"
paper_link: https://dl.acm.org/citation.cfm?id=1815971
paper_keyword: RRIP; Cache Replacement; LRU
paper_year: ISCA 2010
rw_set: 
htm_cd: 
htm_cr: 
version_mgmt: 
---

This paper proposes RRIP, a machanism for determining whether a cache line should be replaced 
by predicting the interval from the current time till its next reference. The motivation for 
RRIP is locality anomaly, which is not uncommon for lower level caches, such as L2 and LLC.
The classical Least Recently Used (LRU) algorithm works pretty well, sometimes can approximate the 
optimizal Belady's OPT algorithm, for access patterns that have high locality, which is particularly 
true for L1 cache. On L2 and LLC, LRU may not work well for three reasons. First, most of the locality
has been filtered out by L1, and only those misses the L1 cache can be observed by L2 and LCC. This 
property violates the assumption of LRU that both a cache miss and cache hit imply accesses to the 
same line in the near future. Second, when the size of the working set is larger than the cache, 
*cache thrashing* can happen. The most typical example is accessing an array in a circular manner. 
All accesses will result in cache misses, because the LRU algorithm always selects array elements 
that are smaller, which are accessed earlier and hence are closer to the LRU position. The third reason
is scan pattern, which accesses non-temporal blocks. Scan pattern also violates the assumption of LRU,
because cache misses bring in data that will never be accessed in the near future. 