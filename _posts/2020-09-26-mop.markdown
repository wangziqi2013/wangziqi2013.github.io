---
layout: paper-summary
title:  "Mostly Order Preserving Dictionaries"
date:   2020-09-26 03:00:00 -0500
categories: paper
paper_title: "Mostly Order Preserving Dictionaries"
paper_link: https://ieeexplore.ieee.org/document/8731521
paper_keyword: Compression; Database Compression; MOP; Order-Preserving Dictionary
paper_year: ICDE 2019
rw_set:
htm_cd:
htm_cr:
version_mgmt:
---

**Highlight:**

1. Using multiple independent order preserving small dictionaries and a on-ordered dictionary to approximate a full,
   monolithic order preserving dictionary. The novolty lies in the design decision that a range query can be decomposed
   into several smaller queries on a subset of the table, based on the value partition implied by the dictionaries. 
   Order preserving dictionaries require very little work, while the last non-ordered dictionary requires decoding
   values stored in the table.

**Lowlight:**

1. Although easy to infer, the paper should explicitly mention that a decompression dictionary should be maintained 
   in parallel with the compression dictionary.

This paper proposes mostly order preserving dictionary (MOP), a database compression technique for fast dictionary encoding 
and mostly decoding-free range query. MOP is motived by order preserving dictionaries, which is one of the order preserving 
techniques that map large, repeated values to smaller code words, reducing the number of bits required to represent
the value. The mapping relation is stored as a seperate dictionary for further encoding or decoding. 

Before MOP, previous work has proposed order preserving dictionary designs to achieve both compression and decoding-free
query execution. An order preserving dictionary delivers the guarantee that the numeric order of encoded values is consistent
with the total ordering of unencoded values. This property optimizes range queries based on field values, since the query
does not require decoding the compressed field in order to select the correct tuples. In this case, the query engine rewrites
the condition using the encoded values whose range covers exactly what is requested by the original condition.

Full order preseving dictionaries are not always practical. There are two real-world restrictions that can hinder its 
adoption. The first is that order preserving dictionary requires knowing the entire data set, or at least the distribution
of the field values, before generating the dictionary. This poses a challenge for real-time data analytical systems, as 
they must digest information when they arrive, without too much buffering capability to gather information about the 
full data set. The second problem is that even if the full data set is available, buidling the dictionary involves 
scanning and generating an ordered set of possible values, which is resource consuming. 

MOP avoids the above two challenges by allowing unordered code word assignments to occur at the end of the code word value
domain, partially violating the ordered property that the order of code words must match those of the input value.
Such violation, however, only marginally affects query performance, as the query executor may run a several-pass scan
on the queried table, each only selecting tuples using part of the dictionary, and combine results later.

A MOP dictionary consists of multiple sections. Let the number be N, each the first (N - 1) sections contain order preserving 
codes, but the ordering between sections are not guaranteed. In other words, in each of the first (N - 1) sections,
the ordering of code words fully matches the ordering of the actual values they encode. 
In the last section, called the DIS section, however, there is zero ordering guarantee, and the ordering between code
words can be arbitrary. The sectioned design is a result of incremental dictionary generation. Since the direction 
generator can only see partial inputs at any stage of the execution, it can only make the best effort to assign code
words to input values in the current working section, leaving gaps for future insertions. When this becomes impossible,
the dictionary generator starts a new section, and use it as well as all previous sections as the current working 
section. The last section is treated as an "overflow" section, where values are simply inserted in FIFO order, being
assigned monotonically increasing code words.

The dictionary is logically organized as an array, with values stored in a slot as the input value, and the index of
the slot as the output code word for compression. Decompression is performed with an inversed dictionary, which is 
maintained in parallel with the compression dictionary. The paper does not specify the decompression dictionary, though.

The MOP dictionary is generated as follows. In the first stage, all worker threads cooperatively read a prefix of the 
input stream, and estimates the cardinality of the input based on the sampled results. Cardinality is estimated by
counting the number of distinct values in the samples. In the second stage, the cardinality estimation is reported 
to the generator, and the generator allocates the first section based on the reported number. The paper defines a 
configurable value, the "pitch", as the number of extra slots that will be reserved in the first section in order to
handle values not occuring in the samples. The actual size of the first section is the cardinality multiplied by the 
pitch (which is always greater than one). Then worker threads start process the input stream in real-time, and send the 
values to the dictionary. On receiving the value, the dictionary performs a binary search, and locates the position
that the value should be inserted. The value should be inserted to the position where the previous value is smaller 
and the next value is larger. If there are more than one free slots between the two values, the generator picks
the middle slot, assuming that the probablity that future values lying in the two resulting gaps are equal.
In fact, the paper suggests that worker threads should aggregate a batch of values before sending them to the dictionary
generator. This way, the generator inserts the values that fall into the same gap evenly over the gap, which distributes
values better than the single-value approach.

When a gap can no longer be found, the dictionary generator must allocate a new section at the end of the current dictionary.
The size of the new section is either 2x or one fifth the size of the previous one, depdending the estimated cardinality and
the actual cardinality till this point. If the former is higher, meaning that we gave a good approximation, the next
section need not be large, since not many distinct values are expected to appear. On the other hand, if the latter is
bigger, indicating that the estimation severely under-estimates the cardinality, the next section should be larger than
the previous one to absorb more values before it overflows.

When the number of sections reach an upper bound, the dictionary stops growing, and will simply have all incoming values 
appended to the end of the array, forming the last DIS section, which is not order preserving. One critical obsevation is that
the output code word of values in the DIS section is larger than all code word values in the previous sections. 
